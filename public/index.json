[
{
	"uri": "https://mndkhanh.github.io/my-fcj-doc/public/3-blogstranslated/3.1-blog1/",
	"title": "New Courses and Certification Updates from AWS Training and Certification – September 2025",
	"tags": [],
	"description": "",
	"content": "Author: Training and Certification Blog Editor\nPublished At: September 23, 2025\nCategories: Announcements, AWS Training and Certification\nWelcome to the September edition of our monthly update highlighting newly released training and certification resources—helping you and your teams stay equipped with the latest AWS skills.\nSource: AWS Blog\nIf you missed the August course updates, you can review them here.\nThis month, we launched five new digital learning products on AWS Skill Builder, including the mobile release of AWS Card Clash (available on Apple and Android), a new way to share your AWS achievements through Skills Profile, and three new digital courses. Registration is also now open for the AWS Certified CloudOps Engineer – Associate exam, along with updated exam prep materials.\nNew Skill Builder Subscription Features AWS Skill Builder subscriptions unlock advanced AWS certification preparation and hands-on cloud training, including:\nAWS Cloud Quest AWS Industry Quest AWS Builder Labs AWS Jam Challenges Explore more at AWS Skill Builder.\nAWS Skills Profile Showcase your validated AWS Certifications, learning achievements, and digital badges using the all-new Skills Profile.\nLearn more in the announcement post:\nIntroducing Your AWS Skills Profile\nAWS Builder Labs Learn cloud skills through hands-on practice directly in the AWS Management Console.\nBrowse all labs here:\nAWS Builder Labs\nLatest advanced lab:\nLab – Design and Implement Autonomous Agents with Amazon Bedrock APIs\nStart Lab Game-Based Learning Boost your AWS skills through an interactive learning environment with AWS Card Clash, a free 3D turn-based game.\nDownload for iOS (Apple):\nAWS Card Clash on App Store\nPre-register for Android:\nAWS Card Clash on Google Play\nPaid Digital Training Intermediate Level AWS Solutions Architect Learning Plan (includes Labs) AWS Security Engineer Advanced Learning Plan Advanced Level AWS CloudOps Engineer Learning Plan (includes Labs) AWS Certification Exam Preparation and Updates AWS Certified CloudOps Engineer – Associate (SOA-C03) Registration now open:\nExam Registration\nPrepare using the official exam prep plan:\nExam Prep Plan – SOA-C03\nAWS Digital Training from AWS Training Partners Foundational Level\nAWS Cloud Practitioner Essentials – Coursera AWS Cloud Practitioner Essentials – edX "
},
{
	"uri": "https://mndkhanh.github.io/my-fcj-doc/public/",
	"title": "Internship Report",
	"tags": [],
	"description": "",
	"content": "Internship Report Student Information: Full Name: Mai Nguyễn Duy Khánh\nPhone Number: 0362718422\nEmail: mndkhanh@gmail.com\nUniversity: FPT University on Campus Ho Chi Minh City\nMajor: Software Engineering\nClass: AWS092025\nInternship Company: Amazon Web Services Vietnam Co., Ltd.\nInternship Position: FCJ Cloud Intern\nInternship Duration: From 06/09/2025 to 31/12/2025\nReport Content Worklog Proposal Translated Blogs Events Participated Workshop Self-evaluation Sharing and Feedback "
},
{
	"uri": "https://mndkhanh.github.io/my-fcj-doc/public/4-eventparticipated/4.1-event1/",
	"title": "Kick-off AWS First Cloud Journey Workforce",
	"tags": [],
	"description": "",
	"content": "Event Objectives Celebrate the students who successfully joined the AWS First Cloud Journey – Training on the Job (OJT FALL 2025) program Mark the beginning of a structured learning journey and real-world cloud experience with Amazon Web Services (AWS) Equip participants with hands-on skills in Cloud, DevOps, Security, AI/ML, and Data \u0026amp; Analytics Connect students with the AWS Study Group community (47,000+ members) and AWS partner companies Build a strong bridge between knowledge – technology – career, empowering a new generation of AWS Builders in Vietnam Speakers Nguyen Tran Phuoc Bao – Head of Corporate Relations, FPT University Nguyen Gia Hung – Head of Solutions Architect, AWS Vietnam Do Huy Thang – DevOps Lead, VNG Danh Hoang Hieu Nghi – GenAI Engineer, Renova Bui Ho Linh Nhi – AI Engineer, SoftwareOne Pham Nguyen Hai Anh – Cloud Engineer, G-Asia Pacific Nguyen Dong Thanh Hiep – Principal Cloud Engineer, G-Asia Pacific Key Highlights Launching the AWS First Cloud Journey Workforce Program The first time I have seen such amazing people doing amazing activities in AWS HCMC. It\u0026rsquo;s such an amazing thing that I have ever witnessed.\nThe event marked the official kickoff for more than 150 students in the OJT Fall 2025 cohort.\nSince its inception in 2021, the AWS First Cloud Journey has supported 2,000+ students, with many alumni now working at leading technology companies in Vietnam and abroad.\nThroughout the kickoff, speakers shared insights on:\nThe future of Cloud Computing in Vietnam Career pathways in DevOps, Cloud, and AI/ML Workforce trends and market demands in the coming years Event Agenda Overview 8:30 – 9:00 | Check-in, Networking \u0026amp; Group Photos 9:00 – 9:15 | Opening remarks from FPT University 9:15 – 9:40 | AWS First Cloud Journey \u0026amp; Future Direction – Nguyen Gia Hung 9:40 – 10:05 | DevOps \u0026amp; Career Opportunities – Do Huy Thang 10:05 – 10:20 | Tea Break \u0026amp; Networking 10:20 – 10:40 | From FCJ to GenAI Engineer – Danh Hoang Hieu Nghi 10:40 – 11:00 | She in Tech – The FCJ Journey – Bui Ho Linh Nhi 11:00 – 11:20 | A Day in the Life of a Cloud Engineer – Pham Nguyen Hai Anh 11:20 – 11:40 | Becoming a Cloud Engineer – Nguyen Dong Thanh Hiep 11:40 – 12:00 | Q\u0026amp;A Session \u0026amp; Final Group Photos Key Takeaways Career Insights \u0026amp; Development Strategy Cloud and DevOps remain among the most in-demand technology fields Speakers emphasized essential skills: Cloud fundamentals (IAM, VPC, Compute, Storage…) CI/CD \u0026amp; DevOps mindset Analytical thinking and problem-solving A recommended learning path for students: Cloud Foundation → Hands-on Projects → DevOps Tools → Specialization (AI/ML, Security, Data) Industry \u0026amp; Alumni Perspectives AWS reaffirmed its mission to build the next generation of AWS Builders in Vietnam Tech companies highlighted hiring needs in: Cloud Engineering DevOps Engineering AI/ML Engineering Data Engineering Alumni shared how self-learning, hands-on practice, and community engagement shaped their success. Applying to Work Start building AWS fundamentals: IAM, EC2, S3, VPC Begin practicing with DevOps tools: Git, Docker, CI/CD (GitHub Actions) Develop mini-projects and write technical documentation Join AWS Study Group events, workshops, and mentoring sessions Gradually explore advanced topics: Serverless, Containers, IaC, AI/ML Event Experience As an intern of the AWS FCJ HCMC Team, attending the Kick-off AWS First Cloud Journey Workforce OJT FALL 2025 was an inspiring and motivating experience.\nWhat I learned from the event A clearer understanding of the Cloud \u0026amp; DevOps career landscape in Vietnam Valuable inspiration from FCJ alumni who have successfully built their careers Essential mindsets emphasized throughout the event: Self-learning Experimentation Embracing challenges The importance of networking and staying connected with peers and mentors Networking \u0026amp; Community Met mentors, speakers, AWS specialists, and engineers working in cloud, DevOps, and AI Built a strong network with teammates and fellow FCJ participants The kickoff event not only provided career insights and technical direction, but also fueled my motivation to begin my journey toward becoming an AWS Builder.\n"
},
{
	"uri": "https://mndkhanh.github.io/my-fcj-doc/public/1-worklog/1.1-week1/",
	"title": "Week 1 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 1 Objectives: Connect and get acquainted with members of First Cloud Journey. Understand basic AWS services, how to use console \u0026amp; CLI. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Get acquainted with FCJ members - Read and take note of internship unit rules and regulations 09/08/2025 09/08/2025 3 - Learn about AWS and its types of services + Compute + Storage + Networking + Database + \u0026hellip; 09/09/2025 09/12/2025 https://cloudjourney.awsstudygroup.com/ 4 - Create AWS Free Tier account - Learn about AWS Console \u0026amp; AWS CLI - Practice: + Create AWS account 09/10/2025 09/10/2025 https://cloudjourney.awsstudygroup.com/ 5 - Learn basic budget types: + Cost budget + Usage budget + Saving plans budget + Reservation budget 09/11/2025 09/11/2025 https://cloudjourney.awsstudygroup.com/ 6 - Learn and practice: + AWS support packages + Change AWS support packages + Manage support request 09/12/2025 09/12/2025 https://cloudjourney.awsstudygroup.com/ Week 1 Achievements: Understood what AWS is and mastered the basic service groups:\nCompute: Used to run applications, process data, create virtual server environments or containers. Main services: EC2 (Elastic Compute Cloud): Virtual servers running on AWS (like VPS but more flexible). Lambda: Run serverless code, no server management needed, pay per execution. ECS/EKS (Elastic Container Service / Elastic Kubernetes Service): Manage containers (Docker/K8s). Elastic Beanstalk: Automatic app deployment (like PaaS)\nStorage: Store data, from small files to Big Data. S3 (Simple Storage Service): Object storage – used for files, images, videos. EBS (Elastic Block Store): Block storage (used with EC2 like hard drives). EFS (Elastic File System): File system storage, multiple machines can access simultaneously. Glacier: Long-term storage, cheap (for backup/archive).\nNetworking: Connect services, secure and distribute applications. VPC (Virtual Private Cloud): Create private virtual network in AWS (like private data center). Route 53: DNS service, domain management. CloudFront: CDN distributes content faster to global users. ELB (Elastic Load Balancer): Load balancing between multiple servers. API Gateway: Manage and secure APIs.\nDatabase: Store and manage structured/unstructured data. RDS (Relational Database Service): Manage relational databases (MySQL, PostgreSQL, Oracle, SQL Server). Aurora: AWS-developed database, MySQL/PostgreSQL compatible, faster than RDS. DynamoDB: NoSQL Database (non-relational), high speed, auto-scaling. Redshift: Data warehouse for big data analysis. ElastiCache: Data caching (Redis/Memcached).\nSuccessfully created and configured AWS Free Tier account.\nBecame familiar with AWS Management Console and learned how to find, access, and use services via web interface.\nInstalled and configured AWS CLI on computer including:\nAccess Key Secret Key Default Region Used AWS CLI to perform basic operations such as:\nCheck account \u0026amp; configuration information Retrieve list of regions View EC2 service Create and manage key pairs Check information about running services "
},
{
	"uri": "https://mndkhanh.github.io/my-fcj-doc/public/1-worklog/",
	"title": "Worklog",
	"tags": [],
	"description": "",
	"content": "On this page, you will find my worklog documenting my AWS learning journey. I completed this program over 12 weeks (approximately 3 months), systematically learning and practicing AWS services from fundamentals to advanced topics.\nThroughout this internship period, I progressed from basic AWS concepts to designing and implementing complete cloud architectures. Each week focused on specific AWS services and hands-on practice, building upon previous knowledge to develop comprehensive cloud computing skills.\nBelow is my weekly learning progression:\nWeek 1: Getting familiar with AWS and basic AWS services\nWeek 2: Learning AWS Virtual Private Cloud (VPC)\nWeek 3: Learning Amazon EC2 and compute services\nWeek 4: Understanding AWS IAM and EC2 Instance Storage\nWeek 5: Learning High Availability, Scalability, and Database services\nWeek 6: Learning Amazon Route 53 and Classic Solutions Architecture\nWeek 7: Understanding Amazon S3 and storage features\nWeek 8: Learning CloudFront, Global Accelerator, and AWS Integration \u0026amp; Messaging\nWeek 9: Learning Containers and Serverless architectures\nWeek 10: Understanding Databases, Data \u0026amp; Analytics, and Machine Learning services\nWeek 11: Learning AWS Monitoring, Security, and Advanced Identity\nWeek 12: Learning Disaster Recovery, Migration strategies, and comprehensive review\n"
},
{
	"uri": "https://mndkhanh.github.io/my-fcj-doc/public/5-workshop/5.4-agent-core-run/5.4.2-call-agentcore/",
	"title": "Calling AgentCore",
	"tags": [],
	"description": "",
	"content": "Simple Demo with AgentCore 1. Send the first question Use the command:\nagentcore invoke \u0026#34;{\u0026#39;prompt\u0026#39;: \u0026#39;Tell me about roaming activations\u0026#39;}\u0026#34; The Agent will respond based on the data you deployed (database + logic in your code).\n2. Test memory between invocations (session) After the first question, send another related one — for example:\nagentcore invoke \u0026#34;{\u0026#39;prompt\u0026#39;: \u0026#39;Activate it for Vietnam\u0026#39;}\u0026#34; Then ask:\nagentcore invoke \u0026#34;{\u0026#39;prompt\u0026#39;: \u0026#39;which country was i referring to\u0026#39;}\u0026#34; If the Agent responds correctly and remembers the previous information → this confirms the Memory is working and AgentCore is maintaining context across invocations.\nAgentCore behaves as expected in this demo.\n"
},
{
	"uri": "https://mndkhanh.github.io/my-fcj-doc/public/5-workshop/5.4-agent-core-run/5.4.1-run-agentcore/",
	"title": "Configure &amp; Deploy AgentCore",
	"tags": [],
	"description": "",
	"content": "Getting Started with AgentCore Configure First, push your local code to AWS AgentCore using the command:\nagentcore configure -e ./{your_python_file.py} 1. Agent Name Enter a name for your Agent.\n2. Configuration File Press Enter to use the default configuration file pyproject.toml.\n3. Deployment Configuration Select 2 – Deploy using Docker, allowing AgentCore to automatically build and manage your Docker image.\n4. Execution Role Keep the default setting and let AWS create the IAM Role automatically.\n5. ECR Repository Press Enter to let AWS create the ECR repository for storing the Docker image.\n6. Authorization Configuration Choose No for OAuth. The Agent will only allow access via AWS IAM Access Key \u0026amp; Secret Key.\n7. Request Header Allowlist Press Enter to use the default allowlist configuration.\nResult Once this step is completed, your code has been successfully uploaded to AgentCore.\nLaunch the Agent Use the command below to start the Agent with your API Key (using GROQ):\nagentcore launch --env GROQ_API_KEY=your_api_key_here When the terminal shows Running, your Agent is successfully running.\n"
},
{
	"uri": "https://mndkhanh.github.io/my-fcj-doc/public/5-workshop/5.1-workshop-overview/",
	"title": "Introduction",
	"tags": [],
	"description": "",
	"content": "Introduction to the Workshop This workshop provides a step-by-step guide to setting up IAM, AWS CLI, UV, Groq API, deploying RAG source code integrated with Groq LLM into AWS AgentCore, and finally publishing the API through AWS Gateway. Workshop Objectives \u0026ldquo;How to call APIs\u0026rdquo; — understand how to call external APIs outside AWS AgentCore. \u0026ldquo;Chunking\u0026rdquo; — learn how to split data for RAG so it can retrieve information optimally. \u0026ldquo;Adding memory to RAG\u0026rdquo; — explore how the RAG Agent can remember each piece of data during interactions with users. \u0026ldquo;Deploy AWS AgentCore\u0026rdquo; — understand how to deploy AWS AgentCore. \u0026ldquo;Publish API\u0026rdquo; — learn how to call AgentCore through an API. ![overview](ảnh kiến trúc mô hìn)\n"
},
{
	"uri": "https://mndkhanh.github.io/my-fcj-doc/public/4-eventparticipated/4.2-event2/",
	"title": "Cloud Day AWS 2025 in HCMC",
	"tags": [],
	"description": "",
	"content": "Event Objectives Experience the plenary session live-streamed from Hanoi Featuring keynote speakers and breakthrough announcements that will shape Vietnam\u0026rsquo;s cloud future Generative AI: Explore the latest developments and practical applications Data Analytics: Transform your business through data-driven insights Migration \u0026amp; Modernization: Navigate your cloud transformation journey Speakers Eric Yeo – Country General Manager, Vietnam, Cambodia, Laos \u0026amp; Myanmar, AWS Jaime Valles – Vice President, Commercial Sales \u0026amp; Business Development APJ, AWS Jeff Johnson – Managing Director ASEAN, AWS Dr Jens Lottner – Chief Executive Officer, Techcombank Trang Phung – CEO, U2U Network Vu Van – Co-founder \u0026amp; CEO, ELSA Corp Nguyen Hoa Binh – Chairman, Nexttech Group Dieter Botha – CEO, Tymex Nguyen Van Hai – Director of Software Engineering, Techcombank Nguyen The Vinh – Co-Founder \u0026amp; CTO, Ninety Eight Nguyen Minh Ngan – AI Specialist, OCB Nguyen Manh Tuyen – Head of Data Application, LPBank Securities Key Highlights Vietnam Cloud Day 2025 – Hybrid Experience While the main event takes place in Hanoi, I was so excited to watch a seamless hybrid experience right here in Ho Chi Minh City.\nConnect with cloud innovators and industry leaders without leaving Ho Chi Minh City!\nExperience the plenary session live-streamed from Hanoi, featuring keynote speakers and breakthrough announcements that will shape Vietnam\u0026rsquo;s cloud future.\nFocus Areas \u0026amp; Interactive Sessions Ho Chi Minh City sessions will dive deep into three major themes:\nGenerative AI – Explore the latest developments and practical applications Data Analytics – Transform your business through data-driven insights Migration \u0026amp; Modernization – Navigate your cloud transformation journey Considerable Benefits Network locally: Meet and collaborate with Ho Chi Minh City\u0026rsquo;s vibrant tech community Learn from experts: Gain actionable knowledge from Vietnam’s top cloud leaders Stay ahead: Get firsthand updates on the future of cloud computing in Vietnam Key Takeaways Strategic Insights from Vietnam Cloud Day 2025 Cloud adoption momentum: Businesses across Vietnam are accelerating digital transformation Government collaboration: Opening remarks highlighted national cloud-first initiatives Customer success stories: Techcombank and U2U Network shared their journey to AWS adoption Executive leadership focus: Panel discussion emphasized aligning GenAI initiatives with business goals Technical Deep-Dive – Generative AI \u0026amp; Data Unified data foundation: Strategies for scalable, governed data pipelines on AWS GenAI adoption roadmap: Practical guidance on leveraging AWS services for AI-driven innovation AI-Driven Development Lifecycle (AI-DLC): Embedding AI throughout the software development process Security best practices: Protecting data, models, and apps with AWS’s layered security controls AI Agents: Moving beyond automation to intelligent, adaptive systems that multiply productivity Architecture \u0026amp; Operations Event-driven and modular design: Build resilient, loosely coupled systems Compute options: Choose between EC2, containers, and serverless based on workload requirements Scalability \u0026amp; observability: Design for growth with logging, monitoring, and cost controls Applying to Work Evaluate current workloads: Identify which applications can move to AWS for immediate ROI Build a data foundation: Start with ingestion, storage, and processing pipelines for analytics and AI Experiment with GenAI: Pilot use cases with Amazon Bedrock or SageMaker Strengthen security posture: Apply least-privilege IAM policies and secure network configurations Upskill teams: Encourage learning AWS AI/ML services to stay competitive Event Experience This is the first time I knew Eric Yeo - The AWS regional manager. He\u0026rsquo;s such a wonderful leader. Attending “Vietnam Cloud Day 2025: Ho Chi Minh City Connect Edition for Builders” was an insightful and impactful experience, providing a clear roadmap for modernizing applications and databases using cutting-edge approaches and tools. My key takeaways include:\nLearning from Industry Leaders Gained valuable insights from AWS experts and executives from leading technology companies. Real-world case studies deepened my understanding of applying Domain-Driven Design (DDD) and Event-Driven Architecture to enterprise-scale projects. Hands-On Technical Experience Participated in event storming workshops, visualizing how to translate business processes into domain events. Practiced breaking down systems into microservices with clearly defined bounded contexts to reduce complexity. Explored trade-offs between synchronous vs. asynchronous communication, and learned when to apply pub/sub, point-to-point, and streaming patterns. Exploring Modern Tools Discovered Amazon Q Developer, an AI-powered assistant that supports the full Software Development Lifecycle (SDLC). Learned to automate code refactoring and implement serverless architectures using AWS Lambda to improve agility and delivery speed. Networking \u0026amp; Collaboration Connected with AWS specialists, business leaders, and fellow builders, strengthening the ubiquitous language between technical and business teams. Engaged in discussions that highlighted the importance of a business-first mindset for technology decisions. Key Lessons Learned Applying DDD and event-driven patterns significantly improves scalability, resilience, and maintainability. Successful modernization requires a phased, well-planned approach with clear ROI measurement to mitigate risks. Leveraging AI tools like Amazon Q Developer can dramatically accelerate development and streamline team workflows. Some event photos Overall, the event provided not just technical knowledge but also reshaped my perspective on application design, system modernization, and effective cross-team collaboration.\n"
},
{
	"uri": "https://mndkhanh.github.io/my-fcj-doc/public/3-blogstranslated/3.2-blog2/",
	"title": "Minimize risk through defense in depth: Building a comprehensive AWS control framework",
	"tags": [],
	"description": "",
	"content": "Authors: Luis Pastor, Rodolfo Brenes, and George’son Tib\nPublished At: September 23, 2025\nCategories: AWS CloudFormation, AWS Config, AWS Control Tower, AWS Organizations, AWS Security Hub, Security, Identity \u0026amp; Compliance\nChallenges Faced by Security and Governance Teams Security and governance teams across all environments face a common challenge: translating abstract security and governance requirements into a concrete, integrated control framework. AWS services provide capabilities that organizations can use to implement controls across multiple architectural layers—from provisioning infrastructure to continuous operational monitoring.\nMany organizations deploy multi-account environments using AWS Control Tower or Landing Zone Accelerator as the foundational layer for governance and security architecture. Once the environment is set up, organizations typically add detective controls from services such as AWS Security Hub and AWS Config, based on security, compliance, and operational needs. While this progression is a strong starting point, there remains significant opportunity to implement defense-in-depth strategies that strengthen the overall security posture.\nHighly regulated industries such as fintech and financial services often serve as the gold standard for governance and security controls. While these sectors have developed robust frameworks, continuous improvement and cross-industry learning remain valuable for organizations seeking to enhance their control environments. However, many organizations struggle to move beyond a baseline compliance mindset. Based on our experience with customers across industries, this limited perspective often stems from factors such as:\nImmediate compliance pressure Limited resources Lack of understanding of control maturity roadmaps Overemphasis on detection vs. prevention Preference for technology-agnostic controls instead of leveraging AWS-integrated capabilities—leading to unnecessary complexity The good news:\nA more holistic approach—using AWS preventive, proactive, detective, and responsive controls—can dramatically reduce risk while enabling operational efficiency through automation.\nThis article presents a practical framework to help you develop a strong security and governance control strategy. We explore how your organization can advance from a detection-centric posture to a multilayered control framework, including real-world examples across the resource lifecycle—such as infrastructure-as-code testing and preventative controls like:\nService Control Policies (SCPs) Resource Control Policies (RCPs) Declarative Policies (DPs) Grounded in best practices from highly regulated industries and enhanced by modern cloud capabilities such as AWS Organizations and AWS Control Tower, we provide a structured approach for elevating your organization’s control environment beyond basic compliance.\nCustomer challenges in implementing controls Organizations face several significant challenges when attempting to implement a comprehensive control framework in AWS. Let’s explore the main obstacles:\n1. Resource constraints and expertise gaps Security teams often find themselves caught between limited resources and expanding responsibilities in the cloud. With constrained budgets and personnel, teams typically gravitate toward quick wins through detective controls, which appear straightforward to implement initially. While this provides immediate visibility, it can leave critical gaps in security posture. Many teams lack comprehensive expertise across all control types, particularly in implementing preventative, proactive, and responsive controls effectively. The pressure to demonstrate immediate security improvements, combined with day-to-day operational demands, frequently results in tactical solutions rather than strategic, layered security approaches.\n2. Analysis paralysis Deciding which tools to prioritize can be a challenge; the breadth of options and extensive capabilities available across AWS security services and third-party tools can feel overwhelming at times. Security teams struggle to determine the optimal mix of controls for their environment and where to begin implementation. This challenge is compounded by the complexity of mapping technical compliance requirements to cloud-focused capabilities and maintaining visibility into emerging threats as the security landscape evolves. The layers of abstraction created by proliferating security controls can further obscure clear decision-making, leading teams to delay critical security improvements while seeking perfect solutions.\n3. Misunderstanding of defense in depth Defense in depth as a concept is good, but it can be misunderstood and difficult to achieve, leading to vulnerabilities in the security architecture. A common misconception is that a single strong control—separation of duties in AWS Identity and Access Management (IAM) roles, least permission in IAM policies, and so on—provides sufficient protection. This overlooks the crucial value of implementing controls at multiple points and how different control types can be combined to create a robust security posture. Teams often miss how organizational controls like SCPs can work in harmony with workload-specific controls to achieve greater protection. The role of preventative controls in guiding technical implementations is frequently underappreciated.\nMaturity journey challenges The path to security maturity presents numerous obstacles. Many organizations remain stuck in the early stages, implementing detective controls but never progressing to preventative measures. Security controls are often implemented in isolation, without consideration for the broader security landscape. Organizations struggle to create and follow a clear roadmap for evolving their security posture, and measuring improvement over time proves challenging.\nScale and consistency issues As AWS environments grow, maintaining consistent governance and security becomes increasingly complex. Organizations face mounting challenges in managing exceptions and special cases across their expanding infrastructure. These interrelated challenges often result in controls implementations that fail to achieve their intended risk reduction goals. You need a structured approach to overcome these obstacles and implement comprehensive security controls, which we explore in the following sections.\nStrategic investment in security While implementing comprehensive controls requires an initial investment in time and resources, the long-term benefits fundamentally transform how organizations operate.\nThe foundation for this transformation begins with establishing baseline controls through proven starting points such as AWS Control Tower and its customization options. AWS Control Tower provides building blocks for secure multi-account architectures with hundreds of security capabilities and proactive controls already built in. Rather than trying to create baselines from scratch by wrangling vast amounts of account-level or resource-specific controls, you can use these accelerators to rapidly establish a strong security foundation.\nWith these baseline controls in place, this transformation extends beyond security teams to enable the entire organization to operate more efficiently. Development and operations teams can deploy faster with confidence when security guardrails are in place. Security becomes an enabler rather than a bottleneck, so that teams across the organization can innovate while maintaining a strong security posture.\nAs you mature your organization’s control framework through automation and layered defenses, a security transformation occurs. Security teams shift from constant firefighting to proactive risk management. Automated policy enforcement replaces manual reviews, and the time previously spent on routine tasks can be redirected to strategic initiatives.\nUnderstanding control types and their interplay AWS defines distinct types of controls to build a comprehensive security framework. Let’s examine each type and how they work together, using a common scenario: preventing public Amazon Simple Storage Service (Amazon S3) bucket exposure.\nPreventative controls Preventative controls establish the foundation of a secure environment by defining the policies, standards, and requirements that guide security implementations. At their core, these controls encompass corporate security policies that outline acceptable resource configurations across the organization. They work in conjunction with compliance requirements and frameworks to help maintain regulatory alignment, while architectural standards and guidelines provide technical direction for implementations. Data classification policies play a crucial role by determining specific security requirements based on data sensitivity.\nTo illustrate how preventative controls work in practice, consider a common S3 bucket security requirement:\nAll S3 buckets must be private by default, with public access granted only through an approved exception process.\nThis simple but effective policy sets clear expectations before any technical implementation begins.\nOrganization level SCPs blocking public S3 bucket creation. Resource level RCPs enforcing network access controls, such as requiring authenticated access or limiting requests to your organization’s network range. SCPs to stop malicious overwrites of S3 objects using SSE-C encryption by blocking s3:PutObject requests with customer-provided keys unless explicitly allowed, paired with AWS IAM Roles Anywhere for short-term credential enforcement. { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;DenySSECEncryption\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Deny\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:PutObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;Null\u0026#34;: { \u0026#34;s3:x-amz-server-side-encryption-customer-algorithm\u0026#34;: \u0026#34;false\u0026#34; } } } ] } Proactive controls Proactive controls act as an early warning system, identifying and addressing potential security issues before they manifest in your environment. These controls validate configurations and changes against established security requirements during development and deployment.\nExamples include:\nAmazon S3 Block Public Access settings at the account level\nPolicy-as-code checks in CI/CD pipelines (such as CFN-Nag or AWS Config proactive rules)\nAWS CloudFormation hooks for pre-deployment validation\nAWS Config rules in proactive mode\nIAM policies restricting bucket policy modifications\nCloudFormation Guard rules\n##################################### ## Gherkin ## ##################################### # Rule Identifier: # S3_BUCKET_SERVER_SIDE_ENCRYPTION_ENABLED # Description: # Checks if your Amazon S3 bucket either has the Amazon S3 default encryption enabled or that # the bucket policy explicitly denies put-object requests without SSE using AES-256 or AWS KMS. # # Reports on: # AWS::S3::Bucket # # Evaluates: # AWS CloudFormation # # Scenarios: # a) SKIP: no S3 resources present # b) PASS: BucketEncryption.SSEAlgorithm is \u0026#34;aws:kms\u0026#34; or \u0026#34;AES256\u0026#34; # c) FAIL: missing or invalid encryption settings # d) SKIP: rule suppressed # let s3_buckets_server_side_encryption = Resources.*[ Type == \u0026#39;AWS::S3::Bucket\u0026#39; Metadata.cfn_nag.rules_to_suppress not exists or Metadata.cfn_nag.rules_to_suppress.*.id != \u0026#34;W41\u0026#34; Metadata.guard.SuppressedRules not exists or Metadata.guard.SuppressedRules.* != \u0026#34;S3_BUCKET_SERVER_SIDE_ENCRYPTION_ENABLED\u0026#34; ] rule S3_BUCKET_SERVER_SIDE_ENCRYPTION_ENABLED when %s3_buckets_server_side_encryption !empty { %s3_buckets_server_side_encryption.Properties.BucketEncryption exists %s3_buckets_server_side_encryption.Properties.BucketEncryption.ServerSideEncryptionConfiguration[*].ServerSideEncryptionByDefault.SSEAlgorithm in [\u0026#34;aws:kms\u0026#34;,\u0026#34;AES256\u0026#34;] \u0026lt;\u0026lt; Violation: S3 Bucket must enable server-side encryption. Fix: Set BucketEncryption.ServerSideEncryptionConfiguration.ServerSideEncryptionByDefault.SSEAlgorithm to either \u0026#34;aws:kms\u0026#34; or \u0026#34;AES256\u0026#34; \u0026gt;\u0026gt; } Source: aws-guard-rules-registry\nDetective controls Detective controls provide continuous visibility into your security posture by monitoring for and identifying potential security violations or unauthorized changes within your environment. While preventative controls aim to stop issues before they occur, detective controls help you maintain awareness of your security state and can identify when preventative controls have been bypassed or failed. These controls form a critical layer of defense by enabling rapid identification of security issues and providing the visibility needed for effective incident response and compliance reporting. While many organizations start and stop here, detective controls are only part of the solution:\nAWS Config rules monitoring for public buckets Security Hub findings to flag non-compliant resources AWS IAM Access Analyzer evaluations Responsive controls Responsive controls complete the security lifecycle by providing automated and manual mechanisms to address security issues after they’re detected. These controls define and implement the actions taken when security violations are identified, ranging from automated remediation of common misconfigurations to coordinated incident response procedures for complex security events. By establishing clear response patterns and using automation where appropriate, responsive controls help facilitate consistent and timely handling of security issues while reducing the mean time to remediation. Responsive controls address violations when they occur:\nAutomated remediation using AWS Config rules, AWS Lambda functions, or Automated Security Response. AWS Systems Manager automation with pre-built runbooks to remediate config rules. Integration with IT service management (ITSM) systems for manual review and correction such as AWS Service Management Connector. Automated rollbacks of unauthorized changes. Amazon EventBridge rules for bucket policy changes Incident response playbooks. The power comes not from implementing these controls in isolation, but from using them together in a coordinated way. This layered approach begins with preventative controls to establish the requirements, followed by proactive controls to block most potential violations at the source. Issues that manage to slip through are caught by detective controls, while responsive controls automatically remediate identified problems. Throughout this process, comprehensive documentation tracks issues, remediation plans, and progress, such as through a plan of action and milestones (POAM), helping to make sure that compliance requirements are met and improvements can be measured over time.\nImplementation lifecycles: Ideal compared to reality You can follow one of two paths when implementing security controls: starting fresh with a comprehensive approach or evolving from an existing detective-focused implementation. Let’s examine both scenarios.\nStarting fresh: The ideal approach When starting from scratch, you have a unique opportunity to build your security and governance following an ideal approach. Your team can use this clean slate to architect controls and processes methodically, free from legacy constraints. The steps below help establish a strong foundation while maintaining flexibility as your business grows.\nRationalize controls against requirements and risk profile Choose appropriate security frameworks (for example, CIS and NIST). Map compliance, regulatory, legal, and contractual requirements to your base framework. Define clear security objectives and success criteria for your security and compliance program. Design a comprehensive control strategy Document control requirements across all four types (preventive, proactive, detective, and responsive). Use the framework to determine which controls best fit each requirement. Plan implementation phases and priorities. Define metrics for measuring effectiveness. Implement controls in layers Start with AWS Control Tower, which provides foundational controls to mature from. Add customizations as needed. Add additional preventative controls to strengthen security and compliance posture. Deploy proactive controls to stop violations at the source. Add detective controls as safeguards. Implement responsive controls for automated or manual remediation. Monitor and assess effectiveness Evaluate control performance against defined metrics. Identify gaps and opportunities for improvement. Adjust controls based on emerging threats and changing requirements. Implement a continuous improvement feedback loop. Evolution from detective controls: The common path Most organizations start with detective controls and face challenges in maturing from there.\nInitial state Baseline detective controls through Security Hub and AWS Config Manual remediation processes Limited visibility into security posture Maturation steps Analyze findings to identify patterns Implement automated remediation for common issues Add preventative and proactive controls based on recurring events Periodically refine and update policies Optimization Review control effectiveness Identify gaps in coverage Implement additional preventative, proactive, detective, and responsive measures Automate processes where possible The goal: Comprehensive and layered security controls The goal of implementing security controls across multiple layers isn’t just about compliance — it’s about creating a robust, resilient security posture that can effectively help prevent, detect, and respond to security issues.\nWhy multiple control layers matter Security controls should not exist in isolation. When implementing a security requirement, consider:\nHow can we prevent this issue from occurring? How will we detect if preventative controls fail? What should happen when a violation is detected? What policies and standards guide our decisions? Moving beyond detection While detective controls are critical, they indicate that a violation has already occurred. A mature security posture requires:\nStrong preventative controls to stop violations before they happen Detective controls as a safety net for drift or missed issues Automated remediation to minimize exposure Clear policies to guide technical implementation and decisions Measuring success You should measure the effectiveness of your control framework through several key performance indicators (KPIs):\nReduction in total security findings over time Decrease in time-to-remediation Increase in percentage of automated remediation actions Fewer recurring findings Improved audit results demonstrating control effectiveness These indicators help validate that the control framework is delivering meaningful, measurable improvements.\nPractical implementation: From theory to practice Let’s examine how to implement a comprehensive control framework using a common security requirement: preventing exposure of sensitive data through public S3 buckets. This example demonstrates how different control types work together to create defense in depth. While not every control might be necessary for every situation, each should be carefully considered and evaluated based on various factors including system criticality, data sensitivity, operational overhead, and organizational risk tolerance. The decision to implement or omit specific controls should be deliberate and documented, rather than occurring by default.\nThe architecture will have layers and components like the following.\nPreventative layer: Service control policies (SCPs) or resource control policies (RCPs) S3 Block Public Access IAM policies Detective layer: AWS Config rules Amazon GuardDuty and Security Hub findings CloudWatch alerts Responsive layer: AWS Config auto-remediation Lambda functions Systems Manager automation Building controls at each layer An effective security and compliance strategy includes all four types of security controls. While preventative controls are a first line of defense to help prevent unauthorized access or unwanted changes to your network, it’s important to make sure that you establish detective and responsive controls so that you know when an event occurs and can take immediate and appropriate action to remediate it. Using proactive controls adds another layer of security because it complements preventative controls, which are generally stricter in nature.\nBegin by defining your security objectives, then establish clear policies to meet those objectives:\nDefine organizational and business objectives: Identify data protection goals Determine acceptable risk levels Align with compliance requirements Establish clear policies: For example, document business requirements for external data sharing and access controls in security policies. These requirements will drive technical decisions around AWS storage configurations such as S3 bucket policies and public access settings. Define permitted use cases for public access. Establish exception processes. Set clear ownership and responsibilities. Deploy preventative guardrails:\nOrganization level: SCPs to block public bucket creation at the organization level Account-level S3 Block Public Access settings to enforce account-level restrictions Resource level: IAM policies restricting bucket policy modifications S3 bucket policy templates with controlled deployment RCPs to enforce rules on specific resource types across your organization Deploy proactive guardrails:\nInfrastructure as code: Implement policy-as-code checks in CI/CD pipelines using: CloudFormation Guard cfn-nag AWS Config proactive rules Integrate with pull request workflows AWS Control Tower proactive controls: Enable relevant optional AWS Control Tower guardrails Add detective controls by creating a monitoring framework:\nAWS CloudTrail for comprehensive API activity logging and auditing to enable investigation of unauthorized access attempts and configuration changes. AWS Config rules for bucket configuration. AWS Config rules or AWS Config conformance packs deployed for the entire organization can monitor S3 bucket configurations for compliance. Security Hub findings for continuous assessment by aggregating findings and flagging non-compliant resources. Amazon EventBridge rules for policy changes to detect and route S3 bucket policy modifications. IAM Access Analyzer for external access review. Regular compliance reporting, which can be automated through AWS Audit Manager. Implement responsive controls by automating remediation where possible:\nSecurity Hub and Systems Manager integration to automate incident response workflows. Custom Lambda functions for specific use cases. Integration with ITSM for human review when needed. AWS Config remediation rules For example, the AWSConfigRemediation-ConfigureS3PublicAccessBlock runbook configures an AWS account’s S3 Block Public Access settings based on the values you specify in the runbook parameters. The following table describes control types, what a basic implementation includes, and the services and methods used for advanced implementation.\nControl type Basic implementation Advanced implementation Preventative Documentation, peer reviews SCPs, RCPs, DPs, IAM policies, S3 Block Public Access Detective Security Hub, AWS Config rules Security Hub, AWS Config, CloudWatch alerts Responsive Manual remediation Auto-remediation using AWS Config, Systems Manager, EventBridge, Lambda Compliance One-time checks CIS/NIST mapping with Security Hub, automated evidence collection \u0026amp; reporting using AWS Audit Manager Automation Limited Full CI/CD integration (e.g., CloudFormation, Terraform) Cost optimization effort High (manual effort) Low (automation reduces overhead) Scaling and management considerations As your security and governance program matures, scaling these controls across a growing organization requires thoughtful management and automation. This section explores key considerations for effectively managing your security posture at scale, optimizing costs, and maintaining consistency across your AWS environment. Whether you’re expanding across multiple accounts, business units, or AWS Regions, these practices help you balance security requirements with operational efficiency and cost management.\nUse AWS services effectively: Consider deploying AWS Control Tower for consistent account setup and centrally deploying and managing controls at scale across multiple use cases and organizational units. AWS Organizations can aid hierarchical policy management and the implementation of: IAM policies for identity-based guardrails and permissions SCPs for access guardrails RCPs define permissions based on resource attributes DPs to help facilitate consistent resource configurations across your organization Tag policies for consistent resource categorization Backup policies for data protection standards AI service opt-out policies for data privacy requirements Cost allocation tag policies to standardize cost attribution Data residency policies to enforce regional restrictions Implement resource governance through policy integration For example, use Organizations tag policies to enforce a Confidential tag on S3 buckets storing personally identifiable information (PII). Combine this with SCPs that mandate AES-256 encryption for tagged buckets, overriding developer attempts to disable it. Using backup policies to enforce retention rules (for example, Retention=7 years). Use DPs to help maintain consistent security configurations across resources, such as enforcing encryption settings on Amazon Elastic Block Store (Amazon EBS) volumes or requiring specific security group rules. Centralize logging and monitoring Manage compliance exceptions: Implement clear exception processes Document and track approved exceptions Establish regular periodic reviews of exceptions Use time-bound approvals with automated expiration Optimize costs: Use periodic instead of continuous checking where appropriate Implement targeted monitoring based on resource criticality Use AWS Config recordings effectively Balance automation costs against manual effort Conclusion: Moving forward with control maturity Implementing a comprehensive control framework is a journey, not a destination. Start from your organization’s current position, whether that’s with basic detective controls or a fresh implementation, and focus on progressive improvement rather than attempting to implement everything at once. Success comes from carefully documenting decisions about control implementation, regularly reviewing them, and using automation to reduce operational overhead while improving consistency. Progress can be measured through concrete metrics: reduced findings, faster remediation times, and increased automation.\nRemember that the goal extends beyond better security—it’s about transforming security and governance from a reactive operation to a strategic enabler that provides real business value. This transformation manifests through reduced risk from systematic controls, improved operational efficiency through automation, and enhanced visibility and governance. Perhaps most importantly, it frees security teams to focus on strategic initiatives rather than routine operational tasks.\nBy following this approach, you can build a robust security and governance posture that not only protects your organization’s AWS environment but also supports business innovation and growth. The result is a security program that evolves alongside the business, enabling rather than hindering progress, while maintaining a strong approach that can scale with your organization’s needs.\nAuthors Luis Pastor\rLuis is a Senior Security Solutions Architect at AWS specializing in infrastructure security and compliance. He leads Technical Field Communities focused on security and compliance while contributing to AWS Well-Architected guidance. Before AWS, he helped clients across financial services, healthcare, and retail industries improve their security posture in hybrid environments. Outside of work, Luis enjoys staying active and culinary adventures.\rRodolfo Brenes\rRodolfo is a Principal Solutions Architect focused on Cloud Governance and Compliance. With over 18 years of experience, he currently leads a technical field community in AWS helping customers scale and improve their security and governance frameworks. Besides work, Rodolfo enjoys video games, playing with his four cats, and won’t say no to a good outdoor adventure.\rGeorge’son Tib.\rGeorge’son is a Solutions Architect focused on Infrastructure Security at AWS, working with Enterprise customers in the Auto and Manufacturing Industry. He specializes in helping organizations build robust, automated control frameworks that enhance their security posture and drive operational efficiency.\r"
},
{
	"uri": "https://mndkhanh.github.io/my-fcj-doc/public/1-worklog/1.2-week2/",
	"title": "Week 2 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 2 Objectives: Learn about AWS Virtual Private Cloud Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Go to office and meet new friends - Learn basics about Amazon VPC - Theory about subnets, Route tables, Internet Gateway, NAT gateway 09/15/2025 09/15/2025 3 - Theory about firewalls in VPC - Security groups, Network ACLs, VPC Resource map 09/16/2025 09/16/2025 https://cloudjourney.awsstudygroup.com/ 4 - Do basic practice - Create VPC, Internet Gateway, Create route table, Create security group - Enable VPC flow Logs 09/17/2025 09/17/2025 https://cloudjourney.awsstudygroup.com/ 5 - Deploy Amazon EC2 + Create EC2 server + Create NAT Gateway + Use Reachability Analyzer - SSH connection methods to EC2 - Learn about Elastic IP 09/18/2025 09/18/2025 https://cloudjourney.awsstudygroup.com/ 6 - Learn: + Configure Site to Site VPN + Clean up resources 09/19/2025 09/19/2025 https://cloudjourney.awsstudygroup.com/ Week 2 Achievements: Understood AWS and mastered the basic service groups of Amazon VPC: Subnets Route tables Internet gateway NAT gateway Firewalls in Amazon VPC Deploying Amazon EC2 Instances "
},
{
	"uri": "https://mndkhanh.github.io/my-fcj-doc/public/5-workshop/5.2-prerequiste/",
	"title": "Preparation Steps",
	"tags": [],
	"description": "",
	"content": " IAM Permissions Required Permissions AdministratorAccess AmazonBedrockFullAccess AWSCodeBuildAdminAccess AWSCodeBuildDeveloperAccess BedrockAgentCoreFullAccess Create a User and Assign Permissions Go to IAM → Users → select Create user. Add the permissions listed above. Complete the user creation and save the Access Key if you need it for the SDK. Download AWS CLI Download AWS CLI: AWS CLI Link\nThen install it following the instructions.\nUV Management Setup 1. Why use UV? UV is fast, lightweight, and manages environments better than pip.\n2. Install UV on Windows Run:\npowershell -ExecutionPolicy ByPass -c \u0026#34;irm https://astral.sh/uv/install.ps1 | iex\u0026#34; Add UV to PATH:\n$env:Path = \u0026#34;C:\\Users\\leamo\\.local\\bin;$env:Path\u0026#34; Restart your machine to apply the new PATH.\n3. Initialize a UV Environment Inside your project directory:\nuv init Then select the environment in VS Code.\nConnect Your Machine to AWS CLI Go back to IAM to create an Access Key.\nCreate Access Key and Configure AWS CLI In the user page: Security credentials → Create access key Choose Command Line Interface (CLI) Configure AWS CLI Run:\naws configure Fill in:\nAWS Access Key ID AWS Secret Access Key Default region name (example: ap-southeast-1) Default output format json Start AWS CLI AgentCore Run:\nuv run which agentcore After running, it will download all necessary libraries for AWS AgentCore.\nCreate Groq API Go to Groq and create an API key as shown. These external tools support RAG and are integrated through AWS AgentCore.\n"
},
{
	"uri": "https://mndkhanh.github.io/my-fcj-doc/public/2-proposal/",
	"title": "Proposal",
	"tags": [],
	"description": "",
	"content": "APT Magic A Serverless AI Platform for Personalized Image Generation and Social Interaction 1. Executive Summary APT Magic is a serverless AI-powered web application designed to enable users to generate, personalize, and share artistic content such as AI-generated images. The platform integrates with AI foundation models via Amazon Bedrock and provides a seamless web experience using Next.js (SSR) hosted on AWS Amplify.\nThe MVP version focuses on real-time image generation and sharing, while the Future Design aims to scale with Bedrock agentCore/SageMaker Inference, SQS/SNS, Secret Manager \u0026amp; CloudTrail and AWS MLOps pipelines for advanced model orchestration and automation.\nAPT Magic is currently developed as a modern, cost-efficient, and secure AWS-native architecture for small to medium user bases, with planned expansion into enterprise-grade AI orchestration.\n2. Problem Statement What’s the Problem? Most AI image generation platforms are costly, rely on opaque third-party APIs, and offer limited personalization.\nDevelopers and creators often face high latency, lack of transparent model management, and limited control over user data security.\nThe Solution APT Magic leverages AWS serverless architecture to deliver:\nReal-time AI image generation through Amazon Bedrock Stability AI models. Secure user authentication and content management using Amazon Cognito and DynamoDB. Scalable API handling via AWS Lambda and API Gateway. Low-latency global delivery with CloudFront CDN and WAF protection. Future upgrades will include SQS/SNS decoupling, Bedrock AgentCore/SageMaker Inference pipelines, and cost-efficient CI/CD via CloudFormation. transforming APT Magic into a fully automated MLOps platform.\n3. Solution Architecture MVP Architecture The MVP is a fully serverless architecture, focusing on scalability, maintainability, and cost-effectiveness.\nCore AWS Services:\nRoute53 + CloudFront + WAF — Secure global access and caching. Amplify (Next.js SSR) — Hosts the frontend and server-side rendering layer. API Gateway + Lambda Functions — Manage backend logic (image processing, subscription, post APIs). Amazon Cognito — User authentication and access control. Amazon S3 + DynamoDB — Data persistence and image storage. Amazon Bedrock — Integrates foundation model (Stability AI) for image generation. CloudWatch — Logging, and monitoring. Security\nWAF + IAM policies for traffic filtering and role-based access control. Future Design (Enhanced Architecture) In the next phase, APT Magic will evolve into an AI orchestration platform, introducing new layers for automation, resilience, and model lifecycle management.\nNew Services to be Added:\nAmazon SQS — For reliable message queuing between async Lambda tasks.\nAmazon SNS — For real-time event notifications to users or administrators.\nAmazon ElastiCache (Redis) — For rate limiting and caching of frequent inference requests.\nAmazon Bedrock AgentCore — For hosting custom fine-tuned models and managing model endpoints.\nCI/CD\nCloudFormation for infrastructure deployment and automation. 4. Technical Implementation Implementation Phases Phase 1 – MVP Deployment (Completed / Current)\nImplement Amplify (Next.js SSR) + API Gateway + Lambda. Integrate Bedrock Stability AI API. Deploy CI/CD via Gitlab CI/CD. Enable user authentication (Cognito) and storage (S3 + DynamoDB). Log and Monitor via Cloudwatch Phase 2 – Future Design Expansion\nIntroduce SQS/SNS to decouple. Add ElastiCache for request throttling and caching. Integrate Bedrock Agent to enhance AI Pipelines Connect GitLab Runner with CodeBuild for unified CI/CD. 5. Timeline \u0026amp; Milestones Phase Description Estimated Duration Deployment Milestone Month 1: Setup \u0026amp; Core API Deploy infrastructure (IaC), Cognito, API Gateway, DynamoDB, and foundational Lambda functions. 4 Weeks Core Backend operational, Auth/User Management completed. Month 2: AI Integration Integrate Claude Haiku 3 LLM on Amazon Bedrock (Stability AI), Replicate API, complete Image Processing functions. 4 Weeks Successful end-to-end AI image processing demo. Month 3: Front-end \u0026amp; CI/CD Develop UI/UX (Amplify/Next.js), finalize CI/CD pipelines, and configure Monitoring/Security (CloudWatch/WAF). 4 Weeks Full platform ready for user testing. Month 4: Optimization \u0026amp; Go-Live Perform performance testing (Stress Test), cost optimization, and Production deployment. 4 Weeks Go-Live (Official product launch). 6. Cost Estimate (AWS Pricing Estimate) Total Cost Monthly: $9.80 Upfront: $0.00 12 Months: $117.60 Service Overview Service Region Monthly Cost Upfront 12-Month Cost Notes Amazon Route 53 Asia Pacific (Singapore) $0.50 $0.00 $6.00 1 Hosted Zone, 1 domain, 1 linked VPC Amazon CloudFront Asia Pacific (Singapore) $0.00 $0.00 $0.00 No specific configuration AWS WAF Asia Pacific (Singapore) $6.00 $0.00 $72.00 1 Web ACL; 1 rule per ACL AWS Amplify Asia Pacific (Singapore) $0.00 $0.00 $0.00 Build instance: Standard (8GB/4vCPU); request duration 500ms AWS CloudFormation Asia Pacific (Singapore) $0.00 $0.00 $0.00 No extensions; no operations Amazon API Gateway Asia Pacific (Singapore) $0.13 $0.00 $1.59 10k requests/month; WebSocket message 1KB; request size 30KB AWS Lambda Asia Pacific (Singapore) $1.67 $0.00 $20.04 1 million invokes; x86; 512MB ephemeral storage Amazon CloudWatch Asia Pacific (Singapore) $0.85 $0.00 $10.22 1 metric; 0.5GB logs in; 0.5GB logs to S3 S3 Standard Asia Pacific (Singapore) $0.23 $0.00 $2.76 10GB storage; 20k PUT; 40k GET DynamoDB On-Demand Asia Pacific (Singapore) $0.42 $0.00 $5.04 1GB storage; 1KB item; on-demand mode Total (Estimate) — $9.80 $0.00 $117.60 Based on AWS Pricing Calculator Metadata Currency: USD Locale: en_US Created On: 12/9/2025 Share URL: AWS Calculator Link Legal Disclaimer: AWS Pricing Calculator provides estimates only; actual costs may vary based on usage. AI Model Pricing Model Resolution / Token Usage Quality Price per Request (USD) Notes Titan Image Generator v2 \u0026lt; 512×512 Standard 0.008 Fixed price per 1 image Titan Image Generator v2 \u0026lt; 512×512 Premium 0.01 Fixed price per 1 image Titan Image Generator v2 \u0026gt; 1024×1024 Standard 0.01 Fixed price per 1 image Titan Image Generator v2 \u0026gt; 1024×1024 Premium 0.012 Fixed price per 1 image Stable Diffusion 3.5 Large Any N/A 0.08 Fixed price per 1 image Claude (text + image) 40 input tokens + 1 image N/A 0.00195 Price for 1 request including text and 1 image 1024×1024 Additional Options Mode Augmentation Price (USD) text→img no augment 0.08 text→img with augment 0.08195 img→img no augment 0.012 img→img with augment 0.094 7. Risk Assessment Risk Impact Probability Mitigation AI model inference latency Medium High Use ElastiCache + SQS/SNS for async handling Cost increase from model calls High Medium Bedrock usage control, SageMaker autoscaling CI/CD misconfigurations Medium Low CloudFormation rollback policies Security vulnerabilities High Medium WAF, GuardDuty, PrivateLink, IAM least privilege Third-party API dependency Medium Medium Bedrock fallback to S3-stored inference results 8. Expected Outcomes Technical Outcomes: Complete serverless AI image generation workflow with secure CI/CD. Modular orchestration enabling rapid MLOps integration. Improved latency and reliability via caching and async workflows. Long-Term Value: A foundation for AI as a Service (AIaaS) platform expansion. Ready-to-scale MLOps framework with automated retraining. Reusable cloud infrastructure for future AI products. "
},
{
	"uri": "https://mndkhanh.github.io/my-fcj-doc/public/4-eventparticipated/4.3-event3/",
	"title": "AI-Driven Development Session with Amazon Q Developer &amp; Kiro",
	"tags": [],
	"description": "",
	"content": "Event Objectives Understand how generative AI is transforming the software development lifecycle Learn how AI tools such as Amazon Q Developer and Kiro accelerate development workflows Explore how AI integrates into architecture, coding, testing, deployment, and maintenance Experience live demonstrations of AI-assisted development in real engineering scenarios Enhance productivity by automating undifferentiated heavy lifting tasks, enabling developers to focus on creativity and innovation Speakers Toan Huynh – Instructor, AWS GenAI Builder Club My Nguyen – Instructor, AWS GenAI Builder Club Coordinators Diem My – Program Coordinator Dai Truong – Event Coordinator Dinh Nguyen – Operations Coordinator Key Highlights Toan Huynh is a guy with a fire of inspiration, he instructs will whole of his heart and intellectual knowledge.\nMy Huynh was so helpful and answered each question from audiences very deeply and knowledgably.\nTransforming Software Development with Generative AI Generative AI marks a new era in software engineering, reshaping how developers learn, plan, create, deploy, and manage applications.\nThis session highlighted how AI-driven development enables:\nAutomation of repetitive engineering tasks Rapid prototyping and faster delivery cycles Improved code quality and security through AI-assisted reviews A shift toward higher-value, design-focused work for developers AI in the Software Development Lifecycle (AI-DLC) The session introduced how AI tools integrate across the entire SDLC:\nArchitecture planning Code generation and refactoring Test case creation and validation Deployment pipelines Maintenance and monitoring Through Amazon Q Developer and Kiro, participants gained clarity on how AI elevates developer capabilities.\nAgenda 2:00 PM – 2:15 PM | Welcoming \u0026amp; Introduction 2:15 PM – 3:30 PM | AI-Driven Development Lifecycle Overview \u0026amp; Amazon Q Developer Demonstration Instructor: Toan Huynh 3:30 PM – 3:45 PM | Break 3:45 PM – 4:30 PM | Kiro Demonstration Instructor: My Nguyen Key Takeaways Strategic Insights on AI-Driven Development AI accelerates software delivery by automating repetitive tasks Development teams can redirect effort into architectural design and problem-solving AI tools reduce time spent on debugging, refactoring, and documentation Organizations adopting AI-enhanced development gain measurable productivity improvements Practical Learnings – Amazon Q Developer Generating high-quality code from natural language prompts Automatically fixing errors and optimizing functions Writing unit tests and documentation with AI Enhancing DevOps workflows through AI-assisted CI/CD automation Practical Learnings – Kiro Using Kiro’s AI capabilities for system design and development Real-time suggestions for architecture, code structure, and best practices Improved code readability, maintainability, and consistency across teams Applying to Work Adopt AI tools to streamline daily development tasks Use Amazon Q Developer to prototype ideas rapidly and improve code quality Integrate Kiro into architecture design and planning processes Encourage teams to experiment with AI to enhance efficiency and reduce repetitive workload Begin exploring an AI-augmented SDLC to modernize engineering practices Event Experience Attending this AI-Driven Development session was a refreshing and inspiring experience. It showcased how generative AI is reshaping the developer workflow and unlocking new levels of productivity.\nLearning from Experts Gained deep insights from Toan Huynh and My Nguyen on practical AI adoption Understood how AI fits not only in coding, but across architecture and DevOps pipelines Hands-On AI Demonstrations Observed live flows where Amazon Q Developer refactored code, generated documentation, and produced tests instantly Experienced how Kiro assists with system planning and engineering decisions Collaboration \u0026amp; Networking Connected with members of the AWS GenAI Builder Club, sharing ideas about AI development Discussed use cases and opportunities for integrating AI into daily engineering tasks Key Lessons Learned AI-driven development dramatically boosts speed, accuracy, and productivity Developers should evolve from code writers to system designers and solution thinkers Embracing AI early provides competitive advantages in modern engineering teams Speaker - Toan Huynh\nSpeaker - My Nguyen\nOverall, the session reinforced a powerful message: AI will not replace developers, but developers who use AI will outperform those who don’t.\n"
},
{
	"uri": "https://mndkhanh.github.io/my-fcj-doc/public/3-blogstranslated/3.3-blog3/",
	"title": "Accelerate AI agent development with the Nova Act IDE extension",
	"tags": [],
	"description": "",
	"content": "Authors: Donnie Prakoso\nPublished At: September 23, 2025\nCategories: Amazon Nova, Announcements, Developer Tools, Launch, News\nToday, I’m excited to announce the Nova Act extension — a tool that streamlines the path to build browser automation agents without leaving your IDE. The Nova Act extension integrates directly into IDEs like Visual Studio Code (VS Code), Kiro, and Cursor, helping you to create web-based automation agents using natural language with the Nova Act model.\nHere’s a quick look at the Nova Act extension in Visual Studio Code: The Nova Act extension is built on top of the Amazon Nova Act SDK (preview), our browser automation agents SDK (Software Development Kit). The Nova Act extension transforms traditional workflow development by eliminating context switching between coding and testing environments. You can now build, customize, and test production-grade agent scripts—all within your IDE—using features like natural language based generation, atomic cell-style editing, and integrated browser testing. This unified experience accelerates development velocity for tasks like form filling, QA automation, search, and complex multi-step workflows.\nYou can start with the Nova Act extension by describing your workflow in natural language to quickly generate an initial agent script. Customize it using the notebook-style builder mode to integrate APIs, data sources, and authentication, then validate it with local testing tools that simulate real-world conditions, including live step-by-step debugging of lengthy multi-step workflows.\nGetting started with the Nova Act extension\nFirst, I need to install the Nova Act extension from the extension manager in my IDE.\nI’m using Visual Studio Code, and after choosing Extensions, I enter Nova Act. Then, I select the extension and choose Install. To get started, I need to obtain an API key. To do this, I navigate to the Nova Act page and follow the instructions to get the API key. I select Set API Key by opening the Command Palette with Press Cmd+Shift+P / Ctrl+Shift+P After I’ve entered my API key, I can try Builder Mode. This is a notebook-style builder mode that breaks complex automation scripts into modular cells, allowing me to test and debug each step individually before moving to the next.\nHere, I can use the Nova Act SDK to build my agent. On the right side, I have a Live view panel to preview my agent’s actions in the browser and an Output panel to monitor execution logs, including the model’s thinking and actions. To test the Nova Act extension, I choose Run all cells. This will start a new browser instance and act based on the given prompt. I choose Fullscreen to see how browser automation works. Another useful feature in Builder Mode is that I can navigate to the Output panel and select the cell to see its logs. This helps me debug or review logs specific to the cell I’m working on. I can also select a template to get started. Besides using Builder Mode, I can also chat with Nova Act to create a script for me. To do that, I select the extension and choose Generate Nova Act Script. The Nova Act extension opens a chat dialog in the right panel and automatically creates a script for me. After I finish creating the script, I can choose Start Builder Mode, and the Nova Act extension will help me create a Python file in Builder Mode. This creates a seamless integration because I can switch between chat capability and Builder Mode. In the chat interface, I see three workflow modes available:\nAsk: Describe tasks in natural language to generate automation scripts Edit: Refine or customize generated scripts before execution Agent: Run, monitor, and interact with the AI agent performing the workflow I can also add Context to provide relevant information about my active documents, instructions, problems, or additional Model Context Protocol (MCP) resources the agent can use, plus a screenshot of the current window. Providing this information helps the agent understand any specific requirements for the automation task. The Nova Act extension also provides a set of predefined templates that I can access by entering / in the chat. These templates are predefined automation scenarios designed to help quickly generate scripts for common web tasks. I can use these templates (for example, @novaAct /shopping [my requirements]) to get tailored Python scripts for my workflow. At launch, Nova Act extension provides the following templates:\n/shopping: Automates online shopping tasks (searching, comparing, purchasing) /extract: Handles data extraction /search: Performs search and information gathering /qa: Automates quality assurance and testing workflows /formfilling: Completes forms and data entry tasks This extension transforms my agent development workflow by positioning Nova Act extension as a full-stack agent builder tool—a complete agent IDE for the entire development lifecycle. I can prototype with natural language, customize with modular scripting, and validate with local testing—all without leaving my IDE—ensuring production-grade scripts.\nThings to know\nHere are key points to note:\nSupported IDEs: At launch, the Nova Act extension is available for Visual Studio Code, Cursor, and Kiro, with additional IDE support planned Open source: The Nova Act extension is available under the Apache 2.0 license, allowing for community contributions and customization Pricing: The Nova Act extension is available at no charge. Get started with Nova Act extension by installing it from your IDE’s extension marketplace or visiting the GitHub repository for documentation and examples.\nAuthors Donnie Prakoso\rDonnie Prakoso is a software engineer, self-proclaimed barista, and Principal Developer Advocate at AWS. With more than 17 years of experience in the technology industry, from telecommunications, banking to startups. He is now focusing on helping the developers to understand varieties of technology to transform their ideas into execution. He loves coffee and any discussion of any topics from microservices to AI / ML.\r"
},
{
	"uri": "https://mndkhanh.github.io/my-fcj-doc/public/3-blogstranslated/",
	"title": "Translated Blogs",
	"tags": [],
	"description": "",
	"content": "Blog 1 - New Courses and Certification Updates from AWS Training and Certification – September 2025 The September 2025 AWS Training \u0026amp; Certification update introduces new ways to learn cloud skills, including the AWS Card Clash mobile app, a Skills Profile to showcase credentials, new digital training courses, an advanced Bedrock autonomous-agents lab, updated learning plans for key roles, and the newly opened registration and prep materials for the AWS Certified CloudOps Engineer – Associate exam.\nBlog 2 - Minimize risk through defense in depth: Building a comprehensive AWS control framework The blog explains how organizations can strengthen their AWS security posture by using a defense-in-depth approach that layers preventative, proactive, detective, and responsive controls. It highlights common challenges security teams face, shows how AWS services like Control Tower, Organizations, Config, and Security Hub can form a comprehensive control framework, and uses S3 public-access prevention as an example of how multi-layered controls work together to reduce risk and improve operational consistency.\nBlog 3 - Accelerate AI agent development with the Nova Act IDE extension The post introduces Nova Act’s new IDE extension — a tool that lets developers build, test, and debug browser-automation AI agents directly inside popular editors (like VS Code, Kiro, Cursor), without switching between tools. With this extension you can describe workflows in natural language, auto-generate a working agent script, refine it via a notebook-style builder, and run live browser tests — which greatly speeds up creation of multi-step automation tasks (e.g. form filling, QA automation, web workflows).\n"
},
{
	"uri": "https://mndkhanh.github.io/my-fcj-doc/public/1-worklog/1.3-week3/",
	"title": "Week 3 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 3 Objectives: Master Amazon EC2 and its basic features. Understand EC2 instance types, AMI, and pricing models. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Learn Amazon EC2 Fundamentals + EC2 instance types (General Purpose, Compute Optimized, Memory Optimized) + AMI (Amazon Machine Images) + Key pairs and Security Groups 09/22/2025 09/22/2025 https://cloudjourney.awsstudygroup.com/ 3 - EC2 Hands-on: + Launch EC2 instances (Linux and Windows) + Connect via SSH/RDP + Configure Security Groups + Use User Data scripts 09/23/2025 09/23/2025 https://cloudjourney.awsstudygroup.com/ 4 - Learn EC2 Advanced Features + Launch Templates + Create custom AMI + EC2 Instance Metadata + Placement Groups 09/24/2025 09/24/2025 https://cloudjourney.awsstudygroup.com/ 5 - Deploy applications on EC2 + Deploy web application on Amazon Linux + Deploy application on Windows Server 2022 + Configure basic Load Balancer 09/25/2025 09/25/2025 https://cloudjourney.awsstudygroup.com/ 6 - Learn EC2 Pricing Models + On-Demand, Reserved, Spot Instances + Savings Plans + Cost optimization strategies + Clean up resources 09/26/2025 09/26/2025 https://cloudjourney.awsstudygroup.com/ Week 3 Achievements: Mastered Amazon EC2:\nEC2 instance types and use cases AMI (Amazon Machine Images) and how to create custom AMI Key pairs and Security Groups EC2 User Data for bootstrapping instances EC2 Instance Metadata service Understood EC2 Advanced Features:\nLaunch Templates for standardizing deployments Placement Groups (Cluster, Spread, Partition) EC2 Instance Connect Elastic IP addresses Successfully practiced:\nLaunch and connect to EC2 instances (Linux and Windows) Configure Security Groups and Network ACLs Create custom AMI from running instance Deploy web applications on EC2 Use User Data scripts to automate setup Understood EC2 Pricing Models:\nOn-Demand Instances (pay as you go) Reserved Instances (1 or 3 years) Spot Instances (cheap but can be terminated) Savings Plans Cost optimization best practices "
},
{
	"uri": "https://mndkhanh.github.io/my-fcj-doc/public/5-workshop/5.3-architecture/5.3.4-agent-core/",
	"title": "5.3.2. Chunking &amp; Embedding",
	"tags": [],
	"description": "",
	"content": " Why Chunking Matters Documents and FAQs are often long; to generate embeddings effectively and optimize similarity search, large text needs to be split into smaller segments (chunks).\nBenefits Reduce loss of context during embedding More accurate retrieval using vector similarity Better performance during search Avoid token limit issues of embedding models Chunking Strategy The code uses RecursiveCharacterTextSplitter:\nsplitter = RecursiveCharacterTextSplitter( chunk_size=500, chunk_overlap=0 ) chunks = splitter.split_documents(docs) Chunking Parameters Parameter Value Meaning chunk_size 500 Size of each chunk (characters) chunk_overlap 0 No overlap between chunks Optimization Suggestions Recommended chunk size: 500–1000 tokens (depends on the embedding model)\nChunk overlap: If you need continuous context, set overlap to 50–100 characters\nTrade-off:\nSmall chunks → higher accuracy but more vectors Large chunks → fewer vectors but potential context loss Creating Embeddings \u0026amp; Vector Store Initialize the Embedding Model emb = HuggingFaceEmbeddings( model_name=\u0026#34;sentence-transformers/all-MiniLM-L6-v2\u0026#34; ) Chosen model: all-MiniLM-L6-v2\nLightweight and fast Good for English Embedding size: 384 dimensions Create FAISS Vector Store faq_store = FAISS.from_documents(chunks, emb) FAISS (Facebook AI Similarity Search) provides:\nFast vector search Efficient for large datasets Supports multiple index algorithms Querying the Vector Store results = faq_store.similarity_search(query, k=3) Parameters:\nquery: User question k=3: Returns top 3 most similar chunks Important Notes Data Updates If your data changes (add/update documents), you need to:\nRe-embed all documents, or Incrementally update the vector store Choosing an Embedding Model Criteria Lightweight Model Heavy Model Speed Fast Slow Accuracy Good Excellent Cost Low High Use cases FAQ, chatbot Research, legal, complex RAG Vietnamese Models If you need better Vietnamese support:\nkeepitreal/vietnamese-sbert sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2 Full Code Example from langchain_text_splitters import RecursiveCharacterTextSplitter from langchain_huggingface import HuggingFaceEmbeddings from langchain_community.vectorstores import FAISS # Load documents docs = load_faq_csv() # Chunking splitter = RecursiveCharacterTextSplitter( chunk_size=500, chunk_overlap=0 ) chunks = splitter.split_documents(docs) # Embedding emb = HuggingFaceEmbeddings( model_name=\u0026#34;sentence-transformers/all-MiniLM-L6-v2\u0026#34; ) # Vector Store faq_store = FAISS.from_documents(chunks, emb) # Query query = \u0026#34;How do I change my password?\u0026#34; results = faq_store.similarity_search(query, k=3) Implementation Checklist Prepare documents (CSV, JSON, text files) Choose chunk_size (test 500, 750, 1000) Select embedding model (English or multilingual) Build and save FAISS index Test retrieval with sample queries Monitor and adjust k value "
},
{
	"uri": "https://mndkhanh.github.io/my-fcj-doc/public/5-workshop/5.3-architecture/5.3.1-agentcore-memory/",
	"title": "AgentCore Memory",
	"tags": [],
	"description": "",
	"content": "Configuring Memory in AgentCore To enable memory for AgentCore, follow the steps below.\n1. Create Memory in Bedrock Go to Bedrock → select AgentCore. Switch to the Memory tab. Click Create memory. In the memory creation interface, you will see the following sections:\nMemory name Set the name for the memory that AgentCore will use.\nShort-term memory (raw event) expiration The number of days detailed conversation history is stored. For this demo, you can keep the default 90 days.\n2. Types of Memory in AgentCore 1. Summarization – Conversation Summaries Function: Summarizes the conversation after it ends or periodically. Purpose: Keeps long-term context while using minimal storage.\nExample: You have 100 messages about AWS CLI errors → later the Agent remembers:\n“The user was experiencing AWS CLI connection issues.”\n2. Semantic Memory Function: Stores key facts or knowledge independent of context. Purpose: Used to answer questions based on previously mentioned information.\nExample:\n“Project A uses Python 3.9.” Ask again later → Agent responds with Python 3.9 immediately.\n3. User Preferences Function: Learns user habits and communication style. Purpose: Personalizes responses.\nExample: If you often say:\n“Keep the answer short.” The Agent will consistently respond concisely.\n4. Episodes Function: Stores sequences of events and analyzes success/failure through Reflections. Purpose: Helps the Agent learn from past experiences.\nExample: A previous flight booking failed due to missing dates → the Agent remembers. Next time, it asks for the date first.\n3. Memory Type Used in the Demo For the demo, you only need:\nSummarization Choose Summarization and click Create to complete the setup.\n4. Update Memory ID in Python After creating a Memory, you will receive a Memory ID.\nAdd it to your Python file:\n# AgentCore Memory Configuration REGION = \u0026#34;ap-southeast-1\u0026#34; MEMORY_ID = \u0026#34;memory_j98zj-4LFDxqB2o1\u0026#34; GROQ_API_KEY = os.getenv(\u0026#34;GROQ_API_KEY\u0026#34;) Be sure to update the Memory ID and Region to match your configuration.\n"
},
{
	"uri": "https://mndkhanh.github.io/my-fcj-doc/public/5-workshop/5.3-architecture/5.3.2-groq-api/",
	"title": "Calling Groq API",
	"tags": [],
	"description": "",
	"content": " Objective Use the Groq library (ChatGroq / init_chat_model with model_provider=\u0026quot;groq\u0026quot;) to call an OpenAI-compatible model hosted on Groq.\nConfiguration in Code In the demo code:\nRetrieve API Key from Environment GROQ_API_KEY = os.getenv(\u0026#34;GROQ_API_KEY\u0026#34;) The variable GROQ_API_KEY loads the API key from the environment variable.\nInitialize the Model llm = init_chat_model( model=\u0026#34;openai/gpt-oss-20b\u0026#34;, model_provider=\u0026#34;groq\u0026#34;, api_key=GROQ_API_KEY ) Integrate with Agent The Agent calls the LLM through create_agent(...) using the model=llm parameter:\nagent = create_agent( model=llm, tools=tools, checkpointer=checkpointer, store=store, middleware=[MemoryMiddleware()], system_prompt=system_prompt, ) Processing Flow Agent → Groq API → Model Inference → Response "
},
{
	"uri": "https://mndkhanh.github.io/my-fcj-doc/public/5-workshop/5.3-architecture/5.3.3-chunking/",
	"title": "Chunking &amp; Embedding",
	"tags": [],
	"description": "",
	"content": " Why Chunking Is Needed Documents or FAQs are often long; to compute embeddings effectively and optimize similarity search, large text must be split into smaller segments (chunks).\nBenefits Reduces context loss during embedding More accurate retrieval with vector similarity Better performance for search Compatible with token limits of embedding models Chunking Strategy The code uses RecursiveCharacterTextSplitter:\nsplitter = RecursiveCharacterTextSplitter( chunk_size=500, chunk_overlap=0 ) chunks = splitter.split_documents(docs) Chunking Parameters Parameter Value Meaning chunk_size 500 Size of each chunk (characters) chunk_overlap 0 No overlap between chunks Optimization Tips Recommended chunk size: 500–1000 tokens (depends on embedding model)\nChunk overlap: Use 50–100 characters if continuous context is needed\nTrade-off:\nSmaller chunks → higher accuracy but more vectors Larger chunks → fewer vectors but may lose context Creating Embeddings and Vector Store Initialize Embedding Model emb = HuggingFaceEmbeddings( model_name=\u0026#34;sentence-transformers/all-MiniLM-L6-v2\u0026#34; ) Selected model: all-MiniLM-L6-v2\nLightweight and fast Good for English Embedding dimension: 384 Create FAISS Vector Store faq_store = FAISS.from_documents(chunks, emb) FAISS (Facebook AI Similarity Search) provides:\nHigh-speed vector search Efficient handling of large datasets Multiple index algorithms Query the Vector Store results = faq_store.similarity_search(query, k=3) Parameters:\nquery: User question k=3: Returns top 3 most relevant chunks Important Notes Updating Data If documents change (add/update):\nRe-embed all data, or Apply incremental updates to the vector store Choosing an Embedding Model Trade-off comparison:\nCriteria Lightweight Model Heavy Model Speed Fast Slow Accuracy Good Very good Cost Low High Use cases FAQ, chatbot Research, legal Vietnamese Models For better Vietnamese performance:\nkeepitreal/vietnamese-sbert sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2 Full Code Example from langchain_text_splitters import RecursiveCharacterTextSplitter from langchain_huggingface import HuggingFaceEmbeddings from langchain_community.vectorstores import FAISS # Load documents docs = load_faq_csv() # Chunking splitter = RecursiveCharacterTextSplitter( chunk_size=500, chunk_overlap=0 ) chunks = splitter.split_documents(docs) # Embedding emb = HuggingFaceEmbeddings( model_name=\u0026#34;sentence-transformers/all-MiniLM-L6-v2\u0026#34; ) # Vector Store faq_store = FAISS.from_documents(chunks, emb) # Query query = \u0026#34;How do I change my password?\u0026#34; results = faq_store.similarity_search(query, k=3) Deployment Checklist Prepare documents (CSV, JSON, text files) Select appropriate chunk_size (test 500, 750, 1000) Choose embedding model (English or multilingual) Build and save FAISS index Test retrieval with sample queries Monitor and tune the k value for similarity search "
},
{
	"uri": "https://mndkhanh.github.io/my-fcj-doc/public/5-workshop/5.3-architecture/",
	"title": "RAG Architecture Deployed on AWS AgentCore",
	"tags": [],
	"description": "",
	"content": " Using the Gateway Endpoint In this section, we will explore how to integrate Groq to call OpenAI-compatible models and how to perform data chunking for RAG.\n"
},
{
	"uri": "https://mndkhanh.github.io/my-fcj-doc/public/4-eventparticipated/4.4-event4/",
	"title": "CMC Global TechTalk Series – Cloud &amp; Digital Transformation",
	"tags": [],
	"description": "",
	"content": "Event Objectives Explore leading technologies applied across CMC Global’s digital transformation ecosystem Learn practical Cloud Engineering and Architecture insights from experienced industry professionals Understand real-world implementation of cloud migration, modernization, and enterprise solutions Provide students and developers with direct exposure to modern cloud practices and engineering workflows Strengthen community connection between CMC Global experts and future cloud builders Speakers Lê Thanh Đức – Cloud Delivery Manager, CMC Global Dư Quốc Thành – Technical Leader, CMC Global Văn Hoàng Kha – Cloud Engineer, AWS Community Builder Key Highlights Leading Technology Insights from CMC Global The TechTalk Series introduced participants to some of the most impactful technologies used in CMC Global’s comprehensive digital transformation solutions, covering:\nCloud-native deployment strategies Enterprise-level system modernization Cloud migration best practices Infrastructure automation and operational excellence Real-world case studies delivered to large-scale customers Each speaker shared unique perspectives based on years of hands-on experience in cloud delivery, technical leadership, and AWS community building.\nExpertise and Guidance from Industry Leaders Anh Lê Thanh Đức provided insights into cloud delivery management, customer engagement, and scaling cloud teams. Anh Dư Quốc Thành shared deep technical knowledge on solution design and solving enterprise engineering challenges. Anh Văn Hoàng Kha, as an AWS Community Builder, inspired attendees with cloud best practices and the mindset required to thrive in cloud engineering. Key Takeaways Many questions were given at the end of the meeting, which makes everyone very excited. At the time, I asked Mr. Duc for \u0026ldquo;How did he start his carear as a DevOps Engineer\u0026rdquo; and now I can know more how to be a DevOps Engineer.\nStrategic Insights on Cloud \u0026amp; Modernization Cloud transformation succeeds through strong architecture, planning, and team collaboration Organizations rely heavily on automation to ensure reliability, scalability, and operational efficiency Cloud governance, cost optimization, and security must be integrated from day one Becoming a cloud engineer requires continuous learning, hands-on experimentation, and community involvement Practical Learnings from the TechTalk Understanding how large enterprises structure cloud migration projects How CMC Global applies cloud-native patterns to deliver end-to-end digital solutions The importance of Infrastructure as Code (IaC), monitoring, and DevOps pipelines Real examples of solving performance bottlenecks and reliability issues in production systems Applying to Work Start with cloud fundamentals while practicing through real projects and hands-on labs Apply cloud-native principles such as microservices, serverless, and automation Use IaC tools like Terraform or AWS CDK to manage scalable infrastructure Develop skills in observability, cost control, and secure-by-design architectures Engage with cloud communities such as AWS User Groups and AWS Community Builder programs Event Experience Attending this CMC Global TechTalk Series was an inspiring experience, offering a clearer understanding of how cloud technologies are applied in real enterprises and how engineers solve complex problems in digital transformation projects.\nLearning from Industry Professionals Gained valuable knowledge from cloud managers, technical leaders, and AWS community builders Appreciated the transparency in sharing real challenges and lessons from actual customer projects Understood the mindset required to grow as a cloud engineer in modern tech environments Hands-On Perspectives Learned practical examples of cloud deployment, automation, and system modernization Understood how teams at CMC Global collaborate to deliver high-quality cloud solutions Collaboration \u0026amp; Networking Engaged with speakers and fellow participants to discuss cloud career paths Learned about opportunities within CMC Global’s engineering and delivery teams Key Lessons Learned Cloud engineering is a continuous journey of learning and experimentation Modern enterprises rely on scalable, secure, and automated infrastructure Community involvement accelerates growth and creates opportunities Event Banner\nOverall, the session provided valuable insights into enterprise cloud engineering, modern system design, and the importance of continuous learning in the digital transformation era.\n"
},
{
	"uri": "https://mndkhanh.github.io/my-fcj-doc/public/4-eventparticipated/",
	"title": "Events Participated",
	"tags": [],
	"description": "",
	"content": "I have been an active organizer or an event maker at my uni for recent time. But AWS in HCMC makes me so impressed due to its professional and meaningful activities. The events given below are just some of them that I have hands on with. Watch more here:\nEvent 1 Event Name: Kick-off AWS FCJ Workforce - FPTU OJT FALL 2025\nDate \u0026amp; Time: 8:30 - 12:00, September 6, 2025\nLocation: 26th Floor, Bitexco Tower, 02 Hai Trieu Street, Saigon Ward, Ho Chi Minh City\nRole: Attendee\nEvent 2 Event Name: Cloud Day AWS 2025 in HCMC\nDate \u0026amp; Time: September 18, 2025\nLocation: 26th-36th Floor, Bitexco Tower, 02 Hai Trieu Street, Saigon Ward, Ho Chi Minh City\nRole: Attendee\nEvent 3 Event Name: AI-Driven Development Life Cycle: Reimagining Software Engineering.\nDate \u0026amp; Time: October 3, 2025\nLocation: 26th Floor, Bitexco Tower, 02 Hai Trieu Street, Saigon Ward, Ho Chi Minh City\nRole: Attendee\nEvent 4 Event Name: Reinventing DevSecOps with AWS Generative AI.\nDate \u0026amp; Time: October 16, 2025\nLocation: Online Meeting\nRole: Attendee\nEvent 5 Event Name: AWS Cloud Mastery Series #1: AI/ML/GenAI on AWS\nDate \u0026amp; Time: November 15, 2025\nLocation: AWS Vietnam Office\nRole: Attendee\nEvent 6 Event Name: AWS Cloud Mastery Series #2: DevOps on AWS\nDate \u0026amp; Time: November 17, 2025\nLocation: AWS Vietnam Office\nRole: Attendee\nEvent 7 Event Name: CloundFront as Your Foundation And AWS WAF \u0026amp; Application Protection\nDate \u0026amp; Time: November 19, 2025\nLocation: AWS Vietnam Office\nRole: Attendee\nEvent 8 Event Name: Game Day - Secret Agent(ic) Unicorns\nDate \u0026amp; Time: 2pm, November 21, 2025\nLocation: 26th Floor, AWS Vietnam Office\nRole: Attendee\nEvent 9 Event Name: AWS Cloud Mastery Series #3: AWS Well-Architected Security Pillar\nDate \u0026amp; Time: 8:30 - 12:00, November 29, 2025\nLocation: 26th Floor, AWS Vietnam Office\nRole: Attendee\n"
},
{
	"uri": "https://mndkhanh.github.io/my-fcj-doc/public/1-worklog/1.4-week4/",
	"title": "Week 4 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 4 Objectives: Master AWS IAM for access management and security. Understand EC2 Instance Storage and storage types. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Learn AWS IAM + Users, Groups, Roles + Policies and Permissions + IAM best practices 09/22/2025 09/22/2025 https://cloudjourney.awsstudygroup.com/ 3 - Practice IAM: + Create users and groups + Assign policies + Create and use IAM roles 09/23/2025 09/23/2025 https://cloudjourney.awsstudygroup.com/ 4 - Learn EC2 Instance Storage + Amazon EBS (Elastic Block Store) + EC2 Instance Store + Amazon EFS (Elastic File System) 09/24/2025 09/24/2025 https://cloudjourney.awsstudygroup.com/ 5 - Practice Storage: + Create and attach EBS volumes + Create snapshots + Use EFS for shared storage 09/25/2025 09/25/2025 https://cloudjourney.awsstudygroup.com/ 6 - Learn about backup and disaster recovery + EBS snapshots + AMI creation + Cross-region backup 09/26/2025 09/26/2025 https://cloudjourney.awsstudygroup.com/ Week 4 Achievements: Mastered AWS IAM concepts:\nUsers, Groups, Roles Policies and permission assignment MFA (Multi-Factor Authentication) IAM security best practices Understood EC2 Instance Storage:\nEBS volumes and types (gp3, io2, st1, sc1) EC2 Instance Store (ephemeral storage) EFS for shared file systems Comparison between storage types Successfully practiced:\nCreating and managing IAM users, groups, roles Creating, attaching and managing EBS volumes Creating snapshots and restoring Setting up EFS and mounting to EC2 Understood backup strategies and disaster recovery for EC2 and storage.\n"
},
{
	"uri": "https://mndkhanh.github.io/my-fcj-doc/public/5-workshop/5.4-agent-core-run/",
	"title": "Access S3 from on-premises",
	"tags": [],
	"description": "",
	"content": "Overview In this section, you will create an Interface endpoint to access Amazon S3 from a simulated on-premises environment. The Interface endpoint will allow you to route to Amazon S3 over a VPN connection from your simulated on-premises environment.\nWhy using Interface endpoint:\nGateway endpoints only work with resources running in the VPC where they are created. Interface endpoints work with resources running in VPC, and also resources running in on-premises environments. Connectivty from your on-premises environment to the cloud can be provided by AWS Site-to-Site VPN or AWS Direct Connect. Interface endpoints allow you to connect to services powered by AWS PrivateLink. These services include some AWS services, services hosted by other AWS customers and partners in their own VPCs (referred to as PrivateLink Endpoint Services), and supported AWS Marketplace Partner services. For this workshop, we will focus on connecting to Amazon S3. "
},
{
	"uri": "https://mndkhanh.github.io/my-fcj-doc/public/4-eventparticipated/4.5-event5/",
	"title": "AWS Cloud Mastery Series #1: AI/ML/GenAI on AWS",
	"tags": [],
	"description": "",
	"content": "Event Objectives Introduce participants to the fundamentals and practical applications of AWS AI/ML services Provide hands-on understanding of Amazon SageMaker for end-to-end machine learning workflows Explore the capabilities of Amazon Bedrock for building and deploying Generative AI applications Strengthen participants’ knowledge of prompt engineering, RAG architecture, and model selection Enable developers to understand industry-standard MLOps practices using AWS tools Create an opportunity for networking and collaboration among AI/ML enthusiasts Speakers AWS Vietnam AI/ML Specialist Team Guest Facilitators from AWS Training \u0026amp; Certification Key Highlights Understanding the AI/ML Landscape The workshop opened with an overview of the rapidly evolving AI and ML ecosystem in Vietnam, highlighting the increasing adoption of cloud-based AI platforms, enterprise demand for ML solutions, and the role of foundational models in modern applications.\nParticipants gained clarity on:\nThe accelerating growth of AI talent and industry needs Real-world use cases across finance, e-commerce, and digital transformation The importance of cloud platforms in scaling ML workloads Hands-On Deep Dive into AWS AI Services The workshop delivered a detailed walkthrough of the tools, frameworks, and best practices that AWS provides to accelerate ML development—from data preparation to deployment and monitoring.\nAgenda 8:30 AM – 9:00 AM | Welcome \u0026amp; Introduction\nParticipant registration and networking Workshop overview and learning objectives Ice-breaker activity Overview of Vietnam’s AI/ML landscape 9:00 AM – 10:30 AM | AWS AI/ML Services Overview\nAmazon SageMaker: End-to-end ML platform Data preparation and labeling workflows Model training, tuning, and deployment Integrated MLOps capabilities Live Demo: SageMaker Studio walkthrough 10:30 AM – 10:45 AM | Coffee Break\n10:45 AM – 12:00 PM | Generative AI with Amazon Bedrock\nFoundation Models: Claude, Llama, Titan – comparison \u0026amp; selection guide Prompt engineering: Chain-of-thought, few-shot prompting Retrieval-Augmented Generation (RAG) architecture \u0026amp; knowledge base design Bedrock Agents for multi-step workflows and tool integrations Guardrails configuration for safe and controlled AI output Live Demo: Building a Generative AI chatbot using Bedrock 12:00 PM | Lunch Break (Self-arranged)\nKey Takeaways Strategic Insights into AI/ML on AWS End-to-end ML pipelines become significantly faster with managed services like SageMaker Model deployment and monitoring require strong MLOps foundations to ensure reliability Choosing the right foundation model depends on accuracy, latency, and domain constraints Generative AI workloads demand strong governance and safety controls Practical Learnings from SageMaker Efficient data preparation through integrated labeling and processing tools Automated model optimization through hyperparameter tuning jobs Streamlined deployment with real-time endpoints and model monitoring The importance of versioning, lineage tracking, and reproducibility Practical Learnings from Bedrock How to apply prompt engineering patterns for optimal responses Understanding when to use Claude, Llama, or Titan based on workload Implementing Retrieval-Augmented Generation (RAG) to enhance model accuracy Using Bedrock Agents to orchestrate multi-step reasoning tasks Enforcing safety standards through Guardrails and output filtering Applying to Work Start experimenting with SageMaker Studio notebooks for ML model development Use Bedrock to rapidly prototype chatbots, assistants, and domain-specific AI tools Integrate RAG pipelines where accuracy and up-to-date information are critical Adopt MLOps best practices to improve reliability and scalability Continue developing AI/ML skills through workshops, labs, and AWS certifications Event Experience Attending this workshop at the AWS Vietnam Office was a highly inspiring experience. It provided a practical, hands-on view of how machine learning and generative AI systems are built and deployed at scale.\nLearning from AWS Experts Gained clear guidance on how SageMaker simplifies the ML lifecycle Learned how enterprises use Bedrock to accelerate GenAI adoption Understood how global best practices can be applied to real projects in Vietnam Hands-On Demonstrations Saw real examples of training and deploying ML models Experienced how Bedrock can build a functional chatbot in minutes Understood how RAG boosts model accuracy and practical usefulness Collaboration \u0026amp; Networking Connected with other developers, students, and cloud practitioners Exchanged insights on AI career paths and AWS learning opportunities Expanded my network within the AI/ML and cloud community in HCMC Key Lessons Learned ML and GenAI are most powerful when combined with strong engineering principles Productivity dramatically increases with managed AI services and automation Continuous experimentation is essential to mastering modern AI workloads Speaker - Presenter\nSpeaker - Hoang Anh\nSpeaker - Hieu Nghi\nOverall, the workshop provided deep insights into building real-world ML and GenAI applications, empowering participants with the knowledge and confidence to apply AWS AI services effectively in future projects.\n"
},
{
	"uri": "https://mndkhanh.github.io/my-fcj-doc/public/1-worklog/1.5-week5/",
	"title": "Week 5 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 5 Objectives: Understand High Availability and Scalability in AWS. Master database services: RDS, Aurora, ElastiCache. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Learn High Availability \u0026amp; Scalability + Multi-AZ deployments + Auto Scaling Groups + Elastic Load Balancer (ALB, NLB, CLB) 09/29/2025 09/29/2025 https://cloudjourney.awsstudygroup.com/ 3 - Practice HA \u0026amp; Scalability: + Create Auto Scaling Group + Configure Load Balancer + Test scaling policies 09/30/2025 09/30/2025 https://cloudjourney.awsstudygroup.com/ 4 - Learn Amazon RDS + RDS engines (MySQL, PostgreSQL, Oracle, SQL Server) + Multi-AZ and Read Replicas + Backup and restore 10/01/2025 10/01/2025 https://cloudjourney.awsstudygroup.com/ 5 - Learn Amazon Aurora \u0026amp; ElastiCache + Aurora MySQL/PostgreSQL + Aurora Serverless + ElastiCache (Redis, Memcached) 10/02/2025 10/02/2025 https://cloudjourney.awsstudygroup.com/ 6 - Practice Database: + Create RDS instance + Configure Multi-AZ + Create Read Replica + Use ElastiCache 10/03/2025 10/03/2025 https://cloudjourney.awsstudygroup.com/ Week 5 Achievements: Mastered High Availability and Scalability concepts:\nMulti-AZ deployments Auto Scaling Groups and scaling policies Load Balancing (ALB, NLB, CLB) Health checks and monitoring Understood AWS database services:\nAmazon RDS and database engines Multi-AZ for high availability Read Replicas for read scalability Amazon Aurora and Aurora Serverless ElastiCache for caching (Redis, Memcached) Successfully practiced:\nSetting up Auto Scaling Group with Launch Template Configuring Application Load Balancer Creating and managing RDS instances Configuring Multi-AZ and Read Replicas Using ElastiCache to improve performance Understood database backup, restore and disaster recovery strategies.\n"
},
{
	"uri": "https://mndkhanh.github.io/my-fcj-doc/public/5-workshop/",
	"title": "Workshop",
	"tags": [],
	"description": "",
	"content": "Building a RAG Agent with Groq API and AgentCore Memory Overview In this workshop, we will build a complete RAG (Retrieval-Augmented Generation) Agent with the following capabilities:\nCalling the Groq API to use high-performance LLM models Chunking \u0026amp; Embedding documents for optimized vector search AgentCore Memory to maintain long-term context across chat sessions Tool Integration so the agent can automatically search FAQs and reformulate queries AgentCore provides a framework for building AI agents with memory persistence, middleware hooks, and tool orchestration — enabling the agent to “remember” conversation history and personalize responses.\nContents Workshop Overview\nPrerequisites\nArchitecture\n5.3.1. Calling Groq API 5.3.2. Chunking \u0026amp; Embedding 5.3.3. AgentCore Code Handler Running AgentCore\nResource Cleanup\nTech Stack Component Technology LLM Provider Groq API (OpenAI models) Embedding Model HuggingFace (all-MiniLM-L6-v2) Vector Store FAISS Agent Framework LangChain + AgentCore Memory Backend AgentCore Memory Store Text Splitting RecursiveCharacterTextSplitter Prerequisites Python 3.8+ Groq API Key Basic understanding of RAG and LLMs Familiarity with vector embeddings Expected Outcome By the end of the workshop, you will have:\nAn agent capable of answering FAQs via vector search A memory system that remembers user preferences and context Tool orchestration allowing the agent to decide when to use tools Production-ready code with logging and error handling Get Started: 5.1. Workshop Overview\n"
},
{
	"uri": "https://mndkhanh.github.io/my-fcj-doc/public/4-eventparticipated/4.6-event6/",
	"title": "AWS Cloud Mastery Series #2: DevOps on AWS",
	"tags": [],
	"description": "",
	"content": "Event Objectives Introduce participants to modern DevOps principles and culture Provide practical knowledge of AWS DevOps tools across CI/CD, infrastructure, and operations Demonstrate how DevOps accelerates delivery through automation, observability, and continuous improvement Equip developers with hands-on insights into containerization, monitoring, and deployment strategies Strengthen understanding of reliability, scalability, and operational excellence on AWS Support participants in exploring DevOps career development and AWS certification pathways Speakers AWS Vietnam DevOps Specialist Team Guest Trainers from AWS Training \u0026amp; Certification Key Highlights Embracing the DevOps Mindset The workshop began with a discussion about the evolving shift toward a DevOps-centric culture. Participants were introduced to:\nThe principles of DevOps collaboration Key performance metrics (DORA metrics: Deployment Frequency, MTTR, Change Failure Rate) The importance of automation and continuous improvement How DevOps complements AI/ML workflows from previous sessions This session emphasized how a strong DevOps culture leads to faster delivery, higher reliability, and stronger engineering ownership.\nA Deep Dive into AWS DevOps Tooling Throughout the full-day workshop, participants explored AWS-native tools for CI/CD, Infrastructure as Code, container orchestration, and observability—gaining a solid understanding of how modern engineering teams build and deliver applications at scale.\nAgenda Morning Session (8:30 AM – 12:00 PM) 8:30 – 9:00 AM | Welcome \u0026amp; DevOps Mindset\nRecap of the previous AI/ML session DevOps culture and principles Benefits and key metrics (DORA, MTTR, deployment frequency) 9:00 – 10:30 AM | AWS DevOps Services – CI/CD Pipeline\nSource Control: AWS CodeCommit, GitFlow, Trunk-based development Build \u0026amp; Test: CodeBuild configuration, automated testing Deployment: CodeDeploy with Blue/Green, Canary, Rolling updates Orchestration: CodePipeline automation and workflow design Demo: Full CI/CD pipeline walkthrough 10:30 – 10:45 AM | Break\n10:45 AM – 12:00 PM | Infrastructure as Code (IaC)\nAWS CloudFormation: Templates, stacks, drift detection AWS CDK: Constructs, reusable patterns, multi-language support Demo: Deploying infrastructure using CloudFormation and CDK Discussion: How to choose between IaC tools 12:00 – 1:00 PM | Lunch Break (Self-arranged)\nAfternoon Session (1:00 PM – 5:00 PM) 1:00 – 2:30 PM | Container Services on AWS\nDocker fundamentals: Microservices and containerization Amazon ECR: Image storage, scanning, lifecycle policies Amazon ECS \u0026amp; EKS: Deployment strategies, scaling, orchestration AWS App Runner: Simplified container deployment Demo \u0026amp; Case Study: Microservices deployment comparison 2:30 – 2:45 PM | Break\n2:45 – 4:00 PM | Monitoring \u0026amp; Observability\nCloudWatch: Metrics, logs, alarms, dashboards AWS X-Ray: Distributed tracing \u0026amp; performance insights Demo: Full-stack observability setup Best practices: Alerting, dashboards, on-call processes 4:00 – 4:45 PM | DevOps Best Practices \u0026amp; Case Studies\nDeployment patterns: Feature flags, A/B testing Automated testing \u0026amp; CI/CD integration Incident management and postmortems Case studies from startups \u0026amp; large enterprises 4:45 – 5:00 PM | Q\u0026amp;A \u0026amp; Wrap-up\nDevOps career pathways AWS certification roadmap Key Takeaways Strategic Insights into DevOps on AWS DevOps accelerates delivery and enhances team collaboration through automation CI/CD pipelines reduce deployment risks and increase release frequency IaC ensures reliable, repeatable, and scalable infrastructure provisioning Containers and orchestration platforms standardize deployment environments Observability is essential for maintaining high availability and performance Practical Learnings from CI/CD AWS CodeCommit, CodeBuild, CodeDeploy, and CodePipeline work together to form fully automated pipelines Deployment strategies like Canary and Blue/Green reduce downtime and risk Git strategies such as Trunk-based development improve delivery speed Practical Learnings from IaC CloudFormation provides controlled, declarative infrastructure management CDK enables flexible, code-driven infrastructure modeling Understanding how to combine both tools effectively is key for enterprise adoption Practical Learnings from Containers \u0026amp; Observability ECS and EKS offer powerful orchestration for microservice workloads App Runner simplifies deployment for containerized applications CloudWatch + X-Ray provides unified observability across the stack Applying to Work Build CI/CD pipelines to automate code builds, testing, and deployments Use IaC tools to maintain consistent infrastructure environments Adopt containers for scalable and portable application delivery Implement observability practices to improve reliability and reduce MTTR Continue learning DevOps tools and pursue AWS certifications Event Experience This DevOps on AWS workshop provided a comprehensive and practical view of modern DevOps workflows, giving participants a strong foundation for real-world engineering challenges.\nLearning from AWS DevOps Experts Gained valuable insights into AWS-native DevOps tooling Learned how enterprise DevOps transformations are executed Understood the real role of automation and observability in production environments Hands-On Demonstrations Observed a full CI/CD pipeline in action Saw how IaC simplifies provisioning and maintenance Compared multiple container deployment strategies Built monitoring dashboards and explored distributed tracing Collaboration \u0026amp; Networking Met engineers and developers passionate about DevOps Shared career insights, resources, and certification plans Expanded professional connections within the AWS DevOps community Key Lessons Learned DevOps is a combination of culture, tools, and operational discipline Automation is the path to speed, reliability, and efficiency Observability must be built in from the start—not added later Continuous learning is essential in fast-evolving DevOps environments Overall, this session strengthened my understanding of DevOps foundations, AWS tooling, and best practices—providing me with the confidence to design, automate, and operate modern cloud-native systems.\n"
},
{
	"uri": "https://mndkhanh.github.io/my-fcj-doc/public/6-self-evaluation/",
	"title": "Self-Assessment",
	"tags": [],
	"description": "",
	"content": "During my internship at AWS FCJ from 06/09/2025 to 31/12/2025, I had the opportunity to learn, practice, and apply the knowledge from AWS platform into my carear skills.\nIn terms of work ethic, I always strived to complete tasks well, complied with workplace regulations, and actively engaged with colleagues to improve work efficiency.\nTo objectively reflect on my internship period, I would like to evaluate myself based on the following criteria:\nNo. Criteria Description Good Fair Average 1 Professional knowledge \u0026amp; skills Understanding of the field, applying knowledge in practice, proficiency with tools, work quality ☐ ✅ ☐ 2 Ability to learn Ability to absorb new knowledge and learn quickly ☐ ✅ ☐ 3 Proactiveness Taking initiative, seeking out tasks without waiting for instructions ✅ ☐ ☐ 4 Sense of responsibility Completing tasks on time and ensuring quality ☐ ✅ ☐ 5 Discipline Adhering to schedules, rules, and work processes ✅ ☐ ☐ 6 Progressive mindset Willingness to receive feedback and improve oneself ☐ ✅ ☐ 7 Communication Presenting ideas and reporting work clearly ☐ ✅ ☐ 8 Teamwork Working effectively with colleagues and participating in teams ✅ ☐ ☐ 9 Professional conduct Respecting colleagues, partners, and the work environment ✅ ☐ ☐ 10 Problem-solving skills Identifying problems, proposing solutions, and showing creativity ☐ ✅ ☐ 11 Contribution to project/team Work effectiveness, innovative ideas, recognition from the team ✅ ☐ ☐ 12 Overall General evaluation of the entire internship period ✅ ☐ ☐ Needs Improvement Needs to learn more and actively Get acquainted to the project management skill more Enhance communication skills in both daily interactions and professional contexts, including handling situations effectively "
},
{
	"uri": "https://mndkhanh.github.io/my-fcj-doc/public/1-worklog/1.6-week6/",
	"title": "Week 6 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 6 Objectives: Master Amazon Route 53 and DNS routing. Understand Classic Solutions Architecture and design patterns. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Learn Amazon Route 53 + DNS fundamentals + Hosted zones + Routing policies (Simple, Weighted, Latency, Failover, Geolocation) 10/06/2025 10/06/2025 https://cloudjourney.awsstudygroup.com/ 3 - Practice Route 53: + Register domain or use existing domain + Configure routing policies + Health checks 10/07/2025 10/07/2025 https://cloudjourney.awsstudygroup.com/ 4 - Learn Classic Solutions Architecture + 3-tier architecture + Stateless web tier + Stateful application tier 10/08/2025 10/08/2025 https://cloudjourney.awsstudygroup.com/ 5 - Design sample architectures + WordPress on AWS + E-commerce platform + Microservices architecture 10/09/2025 10/09/2025 https://cloudjourney.awsstudygroup.com/ 6 - Practice: + Draw architecture with draw.io + Deploy a simple 3-tier architecture + Document architecture decisions 10/10/2025 10/10/2025 https://cloudjourney.awsstudygroup.com/ Week 6 Achievements: Mastered Amazon Route 53:\nDNS fundamentals and how it works Hosted zones (public and private) Routing policies and use cases Health checks and DNS failover Domain registration Understood Classic Solutions Architecture:\n3-tier architecture (Web, App, Database) Stateless vs Stateful design Horizontal vs Vertical scaling Best practices for high availability Cost optimization strategies Successfully practiced:\nConfiguring Route 53 with routing policies Setting up health checks and failover Drawing AWS architecture with draw.io Deploying a simple 3-tier architecture Documenting and presenting architecture decisions Able to design and deploy basic architectures on AWS.\n"
},
{
	"uri": "https://mndkhanh.github.io/my-fcj-doc/public/4-eventparticipated/4.7-event7/",
	"title": "CloundFront as Your Foundation And AWS WAF &amp; Application Protection",
	"tags": [],
	"description": "",
	"content": "Event Objectives Introduce participants to the foundational concepts of Amazon CloudFront as a global CDN Provide practical understanding of how CloudFront improves performance, reliability, and cost efficiency Explore AWS WAF, Shield, and Bot Control for Layer 7 application protection Demonstrate modern security architectures for defending web applications and APIs Reinforce learning through an interactive Fun Quiz session Strengthen participants’ knowledge in building secure, scalable, and cost-optimized cloud applications Speakers Mr. Hung Gia for the CloudFront Session Mr. Julian for the WAF session Key Highlights Accelerating Applications with Amazon CloudFront The session began with an introduction to the challenges organizations face with web performance, cost unpredictability, and traffic spikes. Participants learned how Amazon CloudFront addresses these issues through:\nGlobal Edge Network with worldwide Points of Presence Multi-layer caching and Origin Shield Advanced performance techniques (HTTP/3, persistent connections, multiplexing) Origin protection via VPC Origins and Origin Access Control Built-in cost optimization features Real-world examples highlighted how CloudFront reduces latency, origin load, and operational costs while improving user experience at scale.\nStrengthening Security with AWS WAF \u0026amp; Shield The second part of the workshop focused on application security in the modern threat landscape, introducing:\nCommon attack vectors: OWASP Top 10, DDoS, bots, CVEs AWS WAF components (WebACLs, rules, rule groups, COUNT mode, rate-based rules) AWS Managed Rules for rapid protection Bot Control features and client interrogation techniques AWS Shield and the multi-layer DDoS defense system Security architectures using CloudFront + WAF + Shield for robust L7 protection Participants gained a deeper understanding of how to build secure and resilient applications using AWS edge services.\nAgenda Morning Session (CloudFront) 8:30 – 9:00 AM | Welcome \u0026amp; Introduction\nOverview of performance challenges in modern web applications Understanding CDN roles in global delivery 9:00 – 10:30 AM | Amazon CloudFront Deep Dive\nCDN caching behavior and optimization Global Edge Network overview Performance enhancements (HTTP/3, compression, persistent TCP) Origin protection strategies Multi-origin failover and routing Demo: CloudFront distribution setup and behavior analysis 10:30 – 10:45 AM | Break\nMidday Session (WAF \u0026amp; Shield) 10:45 AM – 12:00 PM | AWS WAF \u0026amp; Application Protection\nWAF rule types and best practices Rate-based rules for HTTP flood mitigation AWS Managed Rules overview Bot Control and client interrogation Shield Advanced capabilities Demo: Building a WAF WebACL for CloudFront 12:00 – 1:00 PM | Lunch Break (Self-arranged)\nAfternoon Session (Security Architecture \u0026amp; Fun Quiz) 1:00 – 2:30 PM | Security Architecture at the Edge\nCloudFront + WAF + Shield integration Origin cloaking and private VPC Origins Applying security layers for APIs \u0026amp; web apps Observability tools for security monitoring 2:30 – 2:45 PM | Break\n2:45 – 3:30 PM | Fun Quiz – CloudFront \u0026amp; WAF Challenge\nReal-world scenario questions Knowledge checks on caching, rules, and protection layers Interactive team-based quiz session 3:30 – 4:00 PM | Wrap-up \u0026amp; Q\u0026amp;A\nCareer path for AWS Edge \u0026amp; Security Specialists Learning roadmap for CloudFront, WAF, and AWS Security Key Takeaways I witness a technical guy with the humbled age at almost 60 - Mr. Julian and our amazing sifu - Mr. Hung Gia.\nStrategic Insights into Edge Performance \u0026amp; Security CloudFront significantly improves global performance through caching and optimized networking Origins can be shielded from direct public traffic using VPC Origins and OAC WAF enables precise, rule-based protection against L7 attacks Bot Control enhances detection of evasive bots through telemetry and behavioral tokens Shield provides automated DDoS mitigation with global edge protection Practical Learnings from CloudFront Multi-layer caching reduces origin cost and improves latency Failover and routing strategies enhance application resilience HTTP/3 and advanced compression deliver measurable speed improvements Practical Learnings from WAF COUNT mode is essential before enforcing blocking rules Rate-based rules effectively mitigate traffic floods Managed Rules accelerate security deployment Client interrogation helps identify sophisticated bot behavior Applying to Work Use CloudFront to minimize latency and offload origin infrastructure Protect web applications and APIs with WAF + Managed Rules Implement Shield for enhanced DDoS protection Adopt defense-in-depth strategies for edge and application layers Continuously observe user behavior and adapt rulesets proactively Event Experience This CloudFront, WAF \u0026amp; Security Essentials workshop delivered both theoretical depth and hands-on practical insights. It provided a clearer understanding of how enterprises build secure, performant, and cost-efficient applications at global scale.\nLearning from AWS Edge \u0026amp; Security Experts Understood how CloudFront optimizes performance for millions of users Learned how WAF and Shield mitigate complex real-world attacks Observed multiple architectural patterns used by enterprise customers Hands-On Demonstrations Configured CloudFront distribution behaviors Created and tested WAF rules in real scenarios Explored bot detection and telemetry-based defenses Collaboration \u0026amp; Networking Engaged with peers interested in cloud security and performance Discussed real use cases and career paths in AWS security domains Key Lessons Learned Performance and security must be designed together at the edge Proper caching strategy reduces both latency and cost Defense-in-depth with CloudFront + WAF + Shield provides strong protection Continuous learning is essential in the evolving security landscape Overall, this workshop strengthened my understanding of edge networking, security best practices, and AWS application protection tools—giving me the confidence to design secure, scalable systems with CloudFront and AWS WAF.\n"
},
{
	"uri": "https://mndkhanh.github.io/my-fcj-doc/public/7-feedback/",
	"title": "Sharing and Feedback",
	"tags": [],
	"description": "",
	"content": "Overall Evaluation 1. Working Environment\nAbsolutely Cinema.\n2. Support from Mentor / Team Admin\nGreat leaders, great mentors.\n3. Relevance of Work to Academic Major\nHelped me a lot.\n4. Learning \u0026amp; Skill Development Opportunities\nDuring the internship, I learned many new skills such as teamwork skills, and professional communication in a corporate environment. The mentor also shared valuable real-world experiences that helped me better plan my career path.\n5. Company Culture \u0026amp; Team Spirit\nPositive, Heartful.\n6. Internship Policies / Benefits\nThe policies sometimes make me confused a little bit, and usually cannot catch up with notifications due to a mono chat group.\nAdditional Questions The most interesting thing impresses a lot is the bonding between people here Definitely, I would recommend my friend to join the internship here. Suggestions \u0026amp; Expectations No suggestion or expectation, absolutely cinema. "
},
{
	"uri": "https://mndkhanh.github.io/my-fcj-doc/public/1-worklog/1.7-week7/",
	"title": "Week 7 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 7 Objectives: Master Amazon S3 and storage features. Understand S3 security and advanced features. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Learn Amazon S3 Basics + Buckets and Objects + Storage classes (Standard, IA, Glacier) + Versioning 10/13/2025 10/13/2025 https://cloudjourney.awsstudygroup.com/ 3 - Learn S3 Advanced Features + Lifecycle policies + Cross-region replication + S3 Transfer Acceleration + S3 Select 10/14/2025 10/14/2025 https://cloudjourney.awsstudygroup.com/ 4 - Learn S3 Security + Bucket policies + IAM policies for S3 + Encryption (SSE-S3, SSE-KMS, SSE-C) + Access Control Lists (ACLs) 10/15/2025 10/15/2025 https://cloudjourney.awsstudygroup.com/ 5 - Practice S3: + Create buckets and upload objects + Configure versioning + Set up lifecycle policies 10/16/2025 10/16/2025 https://cloudjourney.awsstudygroup.com/ 6 - Practice S3 Security: + Configure bucket policies + Enable encryption + Setup cross-region replication 10/17/2025 10/17/2025 https://cloudjourney.awsstudygroup.com/ Week 7 Achievements: Mastered Amazon S3:\nBuckets, objects and S3 fundamentals Storage classes and cost optimization Versioning and object lifecycle S3 performance optimization Understood S3 Advanced Features:\nLifecycle policies to automatically transition storage classes Cross-region replication for disaster recovery S3 Transfer Acceleration S3 Select and Glacier Select Mastered S3 Security:\nBucket policies and IAM policies Encryption options (SSE-S3, SSE-KMS, SSE-C) Access Control Lists (ACLs) S3 Block Public Access Pre-signed URLs Successfully practiced:\nCreating and managing S3 buckets Configuring versioning and lifecycle policies Setting up encryption and bucket policies Setting up cross-region replication Hosting static website on S3 "
},
{
	"uri": "https://mndkhanh.github.io/my-fcj-doc/public/4-eventparticipated/4.8-event8/",
	"title": "Game Day – Secret Agent(ic) Unicorns",
	"tags": [],
	"description": "",
	"content": "Event Objectives Introduce participants to GenAI-powered problem-solving through an interactive GameDay experience Provide hands-on exposure to Amazon Bedrock, AgentCore, Knowledge Bases, Guardrails, and MCP Help players understand how AI agents collaborate with AWS services in real-world workflows Encourage teamwork across mixed skill levels to strengthen learning and problem-solving strategies Demonstrate how serverless, database, and search services integrate with GenAI applications Create a fun and engaging environment where participants earn points through missions, puzzles, and challenges AWS Services Used Amazon Bedrock (Foundation Models, Knowledge Bases, Guardrails) Amazon Bedrock AgentCore (Runtime, Memory, Code Interpreter, Observability) Strands Agents Model Context Protocol (MCP) Amazon DynamoDB Amazon OpenSearch Serverless Amazon Q Developer for CLI Target Audience Secret Agent(ic) AI GameDay is designed for a broad range of roles—including data scientists, ML practitioners, architects, developers, and operations engineers.\nParticipants should:\nBe familiar with navigating the AWS Console Benefit from teamwork across different skill levels Not require programming expertise (helpful but optional) Be encouraged to form teams mixing Beginners, Intermediates, and Experts for maximum collaboration Difficulty Each team should ideally contain 3–5 members with varied skills:\n1–2 Experts 1–2 Intermediate participants 1–2 Beginners This ensures balanced collaboration and allows players to learn from each other.\nKey Highlights GenAI-Powered Adventure The event transforms GenAI learning into an interactive mission where teams operate as Secret Agents tasked with solving challenges using AI agents, databases, knowledge retrieval, and observability tools.\nInstead of traditional lectures, participants progress through:\nMissions Time-limited puzzles Evidence analysis Incremental point-based challenges This unique format enhances both technical learning and team dynamics.\nHands-On Experience with Bedrock \u0026amp; AgentCore Players interact with several cutting-edge GenAI services:\nUsing Foundation Models for natural-language reasoning Retrieving facts and evidence with Knowledge Bases Ensuring safety and correctness with Guardrails Running multi-step agents using AgentCore Runtime \u0026amp; Memory Observing agent behavior, debugging, and tracing Storing mission data in DynamoDB Using OpenSearch Serverless for advanced retrieval These concepts mirror real-world AI workloads but are presented in a fun, gamified environment.\nTeam Collaboration \u0026amp; Strategy Success requires:\nClear communication Division of roles Shared note-taking and knowledge tracking Fast troubleshooting Adaptability Teams earn points not only for completing missions but also for efficiency, creativity, and technical accuracy.\nAgenda Intro Presentation \u0026amp; AWS Account Setup – 30 minutes\nGameDay rules and scoring Logging in to AWS accounts Overview of Bedrock, AgentCore, and supporting services Game Playtime – 120 minutes\nMissions and challenges begin Breaks included Evidence puzzles, agent tasks, and time-based scoring Teams race to accumulate the highest number of points Closing – 30 minutes\nSurvey distribution Announcing the Top 3 Winning Teams Group photo session Recap of key learning outcomes Key Takeaways Although I did not get any award, but this is a memorable event that makes me and my team be stronger and achieve more knowledge supporting for the next car\nGenAI Learning Hands-on experience using Bedrock Foundation Models Understanding how AgentCore manages memory, reasoning, and operations Observability techniques for tracing multi-step AI agent workflows Technical Skills Using Knowledge Bases and OpenSearch Serverless for retrieval Applying Guardrails for controlled and safe outputs Leveraging DynamoDB for storing mission artifacts Using Amazon Q Developer CLI for rapid development Team \u0026amp; Strategy Insights Collaboration across diverse skill levels accelerates learning Effective communication and planning improve mission success Time pressure helps simulate real-world problem-solving environments Applying to Work Apply GenAI agents to automate workplace tasks and workflows Use retrieval strategies (Knowledge Bases / OpenSearch) in real projects Adopt safe AI development practices with Guardrails Experiment with Bedrock Agents \u0026amp; AgentCore for building multi-step assistants Use Q Developer CLI to accelerate prototyping and engineering tasks Event Experience Participating in the Secret Agent(ic) Unicorns GameDay was both exciting and intellectually stimulating.\nThis wasn’t a typical workshop—it was an AI investigation adventure that required quick thinking, creative problem solving, and teamwork.\nLearning Through Play The gamified format made complex GenAI concepts easier to understand and apply.\nBy solving scenario-based missions, we learned how to:\nChain multiple AI agent steps Debug reasoning paths using observability tools Store, retrieve, and validate information Use MCP integrations and Bedrock Agents to complete challenges Collaboration \u0026amp; Team Spirit Each team member brought a unique strength—some focused on debugging, others on logic, others on navigating AWS services.\nThis diversity made the experience more engaging and productive.\nMemorable Closing Session Seeing the leaderboard, celebrating the top teams, and taking group photos made the event fun and rewarding.\nIt was a perfect blend of learning, competition, and community building.\nOverall, the GameDay was an unforgettable experience, combining GenAI learning with interactive missions that strengthened both my technical skills and collaborative mindset.\n"
},
{
	"uri": "https://mndkhanh.github.io/my-fcj-doc/public/1-worklog/1.8-week8/",
	"title": "Week 8 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 8 Objectives: Understand CloudFront, Global Accelerator and AWS Storage Extras. Master AWS Integration \u0026amp; Messaging services. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Learn CloudFront \u0026amp; Global Accelerator + CloudFront distributions + Origins and behaviors + Global Accelerator use cases 10/20/2025 10/20/2025 https://cloudjourney.awsstudygroup.com/ 3 - Practice CloudFront: + Create CloudFront distribution + Configure S3 origin + Custom domain with SSL/TLS 10/21/2025 10/21/2025 https://cloudjourney.awsstudygroup.com/ 4 - Learn AWS Storage Extras + AWS Storage Gateway + FSx for Windows File Server + FSx for Lustre + AWS Backup 10/22/2025 10/22/2025 https://cloudjourney.awsstudygroup.com/ 5 - Learn AWS Integration \u0026amp; Messaging + Amazon SQS (Standard, FIFO) + Amazon SNS + Amazon Kinesis + AWS Step Functions 10/23/2025 10/23/2025 https://cloudjourney.awsstudygroup.com/ 6 - Practice Messaging: + Create SQS queues + Create SNS topics + Connect SQS with SNS + Create Step Functions workflow 10/24/2025 10/24/2025 https://cloudjourney.awsstudygroup.com/ Week 8 Achievements: Mastered CloudFront and Global Accelerator:\nCloudFront distributions and caching strategies Origins (S3, EC2, ALB, custom origins) Cache behaviors and TTL Global Accelerator for low latency Comparison: CloudFront vs Global Accelerator Understood AWS Storage Extras:\nAWS Storage Gateway (File, Volume, Tape) FSx for Windows File Server FSx for Lustre for HPC workloads AWS Backup for centralized backup Mastered AWS Integration \u0026amp; Messaging:\nAmazon SQS (Standard vs FIFO queues) Amazon SNS (pub/sub messaging) Amazon Kinesis (Data Streams, Firehose, Analytics) AWS Step Functions (workflow orchestration) EventBridge for event-driven architecture Successfully practiced:\nCreating and configuring CloudFront distribution Setting up custom domain with SSL/TLS Creating SQS queues and SNS topics Connecting messaging services Creating Step Functions state machine "
},
{
	"uri": "https://mndkhanh.github.io/my-fcj-doc/public/4-eventparticipated/4.9-event9/",
	"title": "AWS Cloud Mastery Series #3: Security Pillar – AWS Well-Architected",
	"tags": [],
	"description": "",
	"content": "Event Objectives Introduce participants to the AWS Well-Architected Security Pillar Provide practical understanding of identity, detection, infrastructure protection, data protection, and incident response Strengthen awareness of real-world cloud security threats in Vietnam Explore modern IAM patterns, network segmentation, encryption strategies, and automated incident response Help participants understand how to apply Zero Trust principles and Defense-in-Depth in AWS environments Build foundational knowledge for pursuing AWS Security Specialty certification Target Audience This workshop is designed for:\nCloud engineers, security engineers, architects, DevOps engineers IT administrators and operations teams managing workloads on AWS Developers interested in security best practices Anyone who wants to strengthen their cloud security fundamentals Technical expertise is not strictly required, but familiarity with AWS Console is recommended.\nKey Highlights Security Foundation – Setting the Stage The session opened with an introduction to:\nThe role of the Security Pillar in the Well-Architected Framework Core security principles: Least Privilege, Zero Trust, Defense in Depth The Shared Responsibility Model and how responsibilities shift in managed services Real cloud security threats commonly observed in Vietnam This foundation helped participants understand why security must be built-in, not bolted on.\nDeep Dive into the 5 Security Pillars The workshop was structured around the five pillars of AWS Security, each with practical guidance, demos, and real examples.\nModern IAM architecture with SSO, SCPs, and permission boundaries Detection and continuous monitoring covering CloudTrail, GuardDuty, VPC Flow Logs, EventBridge Infrastructure protection using VPC segmentation, WAF, Shield, Network Firewall Data protection using encryption (KMS), secrets lifecycle management, and guardrails Incident response automation using Lambda and Step Functions Agenda Opening Session 8:30 – 8:50 AM | Opening \u0026amp; Security Foundation Role of Security Pillar in Well-Architected Core principles: Least Privilege, Zero Trust, Defense in Depth Shared Responsibility Model Top cloud threats in Vietnam ⭐ Pillar 1 — Identity \u0026amp; Access Management 8:50 – 9:30 AM | Modern IAM Architecture IAM users, roles, policies — avoiding long-term credentials IAM Identity Center: SSO and permission sets SCPs \u0026amp; permission boundaries for multi-account setups MFA, credential rotation, Access Analyzer Mini Demo: Validate IAM policies \u0026amp; simulate access ⭐ Pillar 2 — Detection 9:30 – 9:55 AM | Detection \u0026amp; Continuous Monitoring\nCloudTrail (organization-level) GuardDuty \u0026amp; Security Hub Logging across all layers: VPC Flow Logs, ALB logs, S3 access logs Automation using EventBridge Detection-as-Code patterns 9:55 – 10:10 AM | Coffee Break\n⭐ Pillar 3 — Infrastructure Protection 10:10 – 10:40 AM | Network \u0026amp; Workload Security VPC segmentation: private vs public workloads Security Groups vs NACLs: when to use which WAF + Shield + Network Firewall Workload protection basics: EC2, ECS/EKS ⭐ Pillar 4 — Data Protection 10:40 – 11:10 AM | Encryption, Keys \u0026amp; Secrets KMS: key policies, grants, rotation best practices Encryption at rest \u0026amp; in transit: S3, EBS, RDS, DynamoDB Secrets Manager \u0026amp; Parameter Store — rotation patterns Data classification \u0026amp; access guardrails ⭐ Pillar 5 — Incident Response 11:10 – 11:40 AM | IR Playbook \u0026amp; Automation AWS Incident Response lifecycle Playbooks for: Compromised IAM credentials S3 public data exposure EC2 malware detection Isolation, snapshots, evidence collection Auto-response with Lambda / Step Functions Wrap-Up Session 11:40 – 12:00 PM | Wrap-Up \u0026amp; Q\u0026amp;A Summary of 5 Security Pillars Common pitfalls in Vietnamese enterprises Security learning roadmap (Security Specialty, SA Pro) Key Takeaways Security Mindset Security must be continuous and proactive, not reactive Least privilege, Zero Trust, and Defense in Depth are foundational Understanding shared responsibility is essential for building secure systems IAM \u0026amp; Detection SSO + permission sets simplify multi-account access management SCPs enforce organization-level guardrails Continuous monitoring is critical with CloudTrail, GuardDuty, and Flow Logs Infrastructure \u0026amp; Data Protection Proper VPC segmentation reduces blast radius Encryption should be applied everywhere—at rest, in transit, across services Secrets lifecycle management is essential for preventing breaches Incident Response Automation dramatically speeds up containment and recovery Prepared playbooks are essential for real-world scenarios Evidence collection must be done securely and systematically Applying to Work Adopt IAM Identity Center and SCPs for secure multi-account operations Enable org-level CloudTrail and GuardDuty for unified monitoring Apply encryption and secrets rotation across all workloads Use WAF and Shield to protect applications from common L7 attacks Build automated IR flows using Lambda or Step Functions Event Experience Attending the AWS Well-Architected Security Pillar Workshop gave me a deeper understanding of how security should be designed, implemented, and automated across AWS environments.\nLearning from AWS Security Experts Gained practical insights into IAM hygiene, threat detection, and incident response Understood how modern organizations structure multi-account security Learned common pitfalls and how to avoid them in real customer environments Hands-On Guidance IAM policy validation exercises helped reinforce least-privilege concepts Seeing detection pipelines with EventBridge \u0026amp; GuardDuty made monitoring clearer Walkthroughs of IR playbooks demonstrated how automation accelerates recovery Community \u0026amp; Engagement Participants shared real-world security challenges Discussions highlighted industry trends and common misconfigurations The workshop reinforced the importance of continuous learning in cloud security Overall, this workshop strengthened my understanding of cloud security foundations, giving me the confidence to design secure, resilient systems aligned with the AWS Well-Architected Framework.\n"
},
{
	"uri": "https://mndkhanh.github.io/my-fcj-doc/public/1-worklog/1.9-week9/",
	"title": "Week 9 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 9 Objectives: Master Containers and Serverless on AWS. Understand serverless architectures and best practices. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Learn Containers on AWS + Docker fundamentals + Amazon ECS (Elastic Container Service) + Amazon EKS (Elastic Kubernetes Service) 10/27/2025 10/27/2025 https://cloudjourney.awsstudygroup.com/ 3 - Practice Containers: + Create Docker image + Push image to ECR + Deploy container on ECS + Fargate vs EC2 launch types 10/28/2025 10/28/2025 https://cloudjourney.awsstudygroup.com/ 4 - Learn Serverless Overview + AWS Lambda fundamentals + API Gateway + DynamoDB + Lambda triggers and integrations 10/29/2025 10/29/2025 https://cloudjourney.awsstudygroup.com/ 5 - Learn Serverless Architectures + Serverless web application + Event-driven architecture + Lambda best practices + SAM (Serverless Application Model) 10/30/2025 10/30/2025 https://cloudjourney.awsstudygroup.com/ 6 - Practice Serverless: + Create Lambda functions + Configure API Gateway + Connect with DynamoDB + Deploy serverless app 10/31/2025 10/31/2025 https://cloudjourney.awsstudygroup.com/ Week 9 Achievements: Mastered Containers on AWS:\nDocker fundamentals and containerization Amazon ECS (Fargate and EC2 launch types) Amazon EKS for Kubernetes workloads Amazon ECR (Elastic Container Registry) Task definitions and services Understood Serverless:\nAWS Lambda and event-driven computing Lambda triggers (S3, DynamoDB, API Gateway, etc.) Lambda layers and environment variables API Gateway (REST and HTTP APIs) DynamoDB for serverless databases Mastered Serverless Architectures:\nServerless web applications Event-driven architectures Lambda best practices (cold starts, memory, timeout) AWS SAM (Serverless Application Model) Serverless Framework Successfully practiced:\nBuilding and deploying Docker containers on ECS Creating and deploying Lambda functions Configuring API Gateway with Lambda Creating serverless CRUD application with DynamoDB Deploying serverless app with SAM/CloudFormation "
},
{
	"uri": "https://mndkhanh.github.io/my-fcj-doc/public/1-worklog/1.10-week10/",
	"title": "Week 10 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 10 Objectives: Master Databases, Data \u0026amp; Analytics services. Understand Machine Learning services on AWS. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Learn Databases in AWS + DynamoDB (NoSQL) + Amazon Redshift (Data Warehouse) + Neptune, DocumentDB, Timestream 11/03/2025 11/03/2025 https://cloudjourney.awsstudygroup.com/ 3 - Practice Databases: + Create DynamoDB table + Query and scan operations + DynamoDB Streams + Global Tables 11/04/2025 11/04/2025 https://cloudjourney.awsstudygroup.com/ 4 - Learn Data \u0026amp; Analytics + Amazon Athena + AWS Glue + Amazon EMR + Amazon Kinesis + QuickSight 11/05/2025 11/05/2025 https://cloudjourney.awsstudygroup.com/ 5 - Practice Data \u0026amp; Analytics: + Query S3 data with Athena + Create Glue crawler + Setup Kinesis stream 11/06/2025 11/06/2025 https://cloudjourney.awsstudygroup.com/ 6 - Learn Machine Learning + Amazon SageMaker + Rekognition, Comprehend + Translate, Polly, Transcribe + Amazon Lex 11/07/2025 11/07/2025 https://cloudjourney.awsstudygroup.com/ Week 10 Achievements: Mastered Databases in AWS:\nDynamoDB (NoSQL database) DynamoDB Streams and Global Tables Amazon Redshift (Data Warehouse) Amazon Neptune (Graph Database) Amazon DocumentDB (MongoDB compatible) Amazon Timestream (Time series database) Understood Data \u0026amp; Analytics:\nAmazon Athena (serverless query service) AWS Glue (ETL service) Amazon EMR (Elastic MapReduce) Amazon Kinesis (real-time data streaming) AWS Data Pipeline Amazon QuickSight (BI service) Mastered Machine Learning services:\nAmazon SageMaker (build, train, deploy ML models) Amazon Rekognition (image and video analysis) Amazon Comprehend (NLP service) Amazon Translate, Polly, Transcribe Amazon Lex (chatbots) Successfully practiced:\nCreating and querying DynamoDB tables Using Athena to query S3 data Setting up Glue crawler and ETL jobs Creating Kinesis stream for real-time data Using SageMaker and Rekognition "
},
{
	"uri": "https://mndkhanh.github.io/my-fcj-doc/public/1-worklog/1.11-week11/",
	"title": "Week 11 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 11 Objectives: Master AWS Monitoring, Security and Advanced Identity. Understand AWS VPC and networking. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Learn AWS Monitoring \u0026amp; Performance + Amazon CloudWatch (metrics, logs, alarms) + AWS CloudTrail + AWS Config + AWS Trusted Advisor 11/10/2025 11/10/2025 https://cloudjourney.awsstudygroup.com/ 3 - Practice Monitoring: + Create CloudWatch dashboards + Setup alarms and notifications + Enable CloudTrail + Review Trusted Advisor 11/11/2025 11/11/2025 https://cloudjourney.awsstudygroup.com/ 4 - Learn Advanced Identity \u0026amp; Security + AWS Organizations + AWS SSO + AWS KMS (Key Management Service) + CloudHSM, Secrets Manager 11/12/2025 11/12/2025 https://cloudjourney.awsstudygroup.com/ 5 - Learn AWS Security Services + AWS Shield \u0026amp; WAF + Amazon GuardDuty + Amazon Inspector + AWS Security Hub 11/13/2025 11/13/2025 https://cloudjourney.awsstudygroup.com/ 6 - Learn Amazon VPC + Subnets, Route Tables, Internet Gateway + NAT Gateway, VPN + VPC Peering, Transit Gateway + VPC Endpoints 11/14/2025 11/14/2025 https://cloudjourney.awsstudygroup.com/ Week 11 Achievements: Mastered AWS Monitoring \u0026amp; Performance:\nAmazon CloudWatch (metrics, logs, alarms, dashboards) AWS CloudTrail (audit and compliance) AWS Config (resource inventory and compliance) AWS Trusted Advisor (best practices recommendations) AWS X-Ray (distributed tracing) Understood Advanced Identity \u0026amp; Security:\nAWS Organizations (multi-account management) AWS SSO (Single Sign-On) AWS KMS (Key Management Service) AWS CloudHSM AWS Secrets Manager and Parameter Store AWS Certificate Manager Mastered AWS Security Services:\nAWS Shield (DDoS protection) AWS WAF (Web Application Firewall) Amazon GuardDuty (threat detection) Amazon Inspector (vulnerability assessment) AWS Security Hub (centralized security) Understood Amazon VPC:\nVPC components (subnets, route tables, IGW, NAT) Security Groups and NACLs VPC Peering and Transit Gateway VPN and Direct Connect VPC Endpoints (Gateway and Interface) Successfully practiced:\nSetting up CloudWatch monitoring and alarms Enabling CloudTrail and Config Configuring KMS encryption Creating and managing VPC with public/private subnets Setting up VPN connection "
},
{
	"uri": "https://mndkhanh.github.io/my-fcj-doc/public/1-worklog/1.12-week12/",
	"title": "Week 12 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 12 Objectives: Master Disaster Recovery and Migration strategies. Review comprehensively and prepare for AWS Solutions Architect Associate. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Learn Disaster Recovery \u0026amp; Migrations + DR strategies (Backup \u0026amp; Restore, Pilot Light, Warm Standby, Multi-Site) + AWS Backup + AWS DRS (Disaster Recovery Service) 11/17/2025 11/17/2025 https://cloudjourney.awsstudygroup.com/ 3 - Learn AWS Migration Services + AWS Application Discovery Service + AWS Migration Hub + AWS Database Migration Service (DMS) + AWS Server Migration Service (SMS) 11/18/2025 11/18/2025 https://cloudjourney.awsstudygroup.com/ 4 - Review More Solutions Architecture + Hybrid cloud architectures + Multi-region architectures + Event-driven architectures + Well-Architected Framework 11/19/2025 11/19/2025 https://cloudjourney.awsstudygroup.com/ 5 - Read AWS White Papers \u0026amp; Best Practices + AWS Well-Architected Framework + Security Best Practices + Cost Optimization + Reliability Pillar 11/20/2025 11/20/2025 https://cloudjourney.awsstudygroup.com/ 6 - Comprehensive review and practice tests: + Review all modules + Take practice exams + Complete final workshop 11/21/2025 11/21/2025 https://cloudjourney.awsstudygroup.com/ Week 12 Achievements: Mastered Disaster Recovery strategies:\nBackup \u0026amp; Restore (high RPO/RTO, low cost) Pilot Light (medium RPO/RTO) Warm Standby (low RPO/RTO) Multi-Site/Hot Site (very low RPO/RTO, high cost) AWS Backup and AWS Elastic Disaster Recovery Understood AWS Migration:\nAWS Application Discovery Service AWS Migration Hub AWS Database Migration Service (DMS) AWS Server Migration Service (SMS) AWS DataSync and Transfer Family 6 R\u0026rsquo;s of Migration (Rehost, Replatform, Repurchase, Refactor, Retire, Retain) Mastered More Solutions Architecture:\nHybrid cloud architectures Multi-region architectures Event-driven architectures Microservices patterns AWS Well-Architected Framework (5 pillars) Completed AWS learning path:\nStudied and practiced 29 modules Understood main AWS services Able to design AWS architectures Ready for AWS Solutions Architect Associate exam Completed final workshop and submitted via Drive/GitHub "
},
{
	"uri": "https://mndkhanh.github.io/my-fcj-doc/public/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://mndkhanh.github.io/my-fcj-doc/public/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]