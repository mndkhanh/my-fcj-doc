[
{
	"uri": "https://my-cloud-journey-e7994.web.app/3-blogstranslated/3.1-blog1/",
	"title": "New Courses and Certification Updates from AWS Training and Certification – September 2025",
	"tags": [],
	"description": "",
	"content": "Author: Training and Certification Blog Editor Published At: September 23, 2025 Categories: Announcements, AWS Training and Certification Permalink\nWelcome to the September edition of our monthly update highlighting newly released training and certification resources—helping you and your teams stay equipped with the latest AWS skills.\nSource: AWS Blog\nIf you missed the August course updates, you can review them here.\nThis month, we launched five new digital learning products on AWS Skill Builder, including the mobile release of AWS Card Clash (available on Apple and Android), a new way to share your AWS achievements through Skills Profile, and three new digital courses. Registration is also now open for the AWS Certified CloudOps Engineer – Associate exam, along with updated exam prep materials.\nNew Skill Builder Subscription Features AWS Skill Builder subscriptions unlock advanced AWS certification preparation and hands-on cloud training, including:\nAWS Cloud Quest AWS Industry Quest AWS Builder Labs AWS Jam Challenges Explore more at AWS Skill Builder.\nAWS Skills Profile Showcase your validated AWS Certifications, learning achievements, and digital badges using the all-new Skills Profile.\nLearn more in the announcement post:\nIntroducing Your AWS Skills Profile\nAWS Builder Labs Learn cloud skills through hands-on practice directly in the AWS Management Console.\nBrowse all labs here:\nAWS Builder Labs\nLatest advanced lab:\nLab – Design and Implement Autonomous Agents with Amazon Bedrock APIs\nStart Lab Game-Based Learning Boost your AWS skills through an interactive learning environment with AWS Card Clash, a free 3D turn-based game.\nDownload for iOS (Apple):\nAWS Card Clash on App Store\nPre-register for Android:\nAWS Card Clash on Google Play\nPaid Digital Training Intermediate Level AWS Solutions Architect Learning Plan (includes Labs) AWS Security Engineer Advanced Learning Plan Advanced Level AWS CloudOps Engineer Learning Plan (includes Labs) AWS Certification Exam Preparation and Updates AWS Certified CloudOps Engineer – Associate (SOA-C03) Registration now open:\nExam Registration\nPrepare using the official exam prep plan:\nExam Prep Plan – SOA-C03\nAWS Digital Training from AWS Training Partners Foundational Level\nAWS Cloud Practitioner Essentials – Coursera AWS Cloud Practitioner Essentials – edX "
},
{
	"uri": "https://my-cloud-journey-e7994.web.app/5-workshop/5.3-s3-vpc/5.3.1-create-gwe/",
	"title": "Create a gateway endpoint",
	"tags": [],
	"description": "",
	"content": " Open the Amazon VPC console In the navigation pane, choose Endpoints, then click Create Endpoint: You will see 6 existing VPC endpoints that support AWS Systems Manager (SSM). These endpoints were deployed automatically by the CloudFormation Templates for this workshop.\nIn the Create endpoint console: Specify name of the endpoint: s3-gwe In service category, choose AWS services In Services, type s3 in the search box and choose the service with type gateway For VPC, select VPC Cloud from the drop-down. For Configure route tables, select the route table that is already associated with two subnets (note: this is not the main route table for the VPC, but a second route table created by CloudFormation). For Policy, leave the default option, Full Access, to allow full access to the service. You will deploy a VPC endpoint policy in a later lab module to demonstrate restricting access to S3 buckets based on policies. Do not add a tag to the VPC endpoint at this time. Click Create endpoint, then click x after receiving a successful creation message. "
},
{
	"uri": "https://my-cloud-journey-e7994.web.app/",
	"title": "Internship Report",
	"tags": [],
	"description": "",
	"content": "Internship Report Student Information: Full Name: Mai Nguyễn Duy Khánh\nPhone Number: 0362718422\nEmail: mndkhanh@gmail.com\nUniversity: FPT University on Campus Ho Chi Minh City\nMajor: Software Engineering\nClass: AWS\nInternship Company: Amazon Web Services Vietnam Co., Ltd.\nInternship Position: FCJ Cloud Intern\nInternship Duration: From 06/08/2025 to 31/12/2025\nReport Content Worklog Proposal Translated Blogs Events Participated Workshop Self-evaluation Sharing and Feedback "
},
{
	"uri": "https://my-cloud-journey-e7994.web.app/5-workshop/5.1-workshop-overview/",
	"title": "Introduction",
	"tags": [],
	"description": "",
	"content": "VPC endpoints VPC endpoints are virtual devices. They are horizontally scaled, redundant, and highly available VPC components. They allow communication between your compute resources and AWS services without imposing availability risks. Compute resources running in VPC can access Amazon S3 using a Gateway endpoint. PrivateLink interface endpoints can be used by compute resources running in VPC or on-premises. Workshop overview In this workshop, you will use two VPCs.\n\u0026ldquo;VPC Cloud\u0026rdquo; is for cloud resources such as a Gateway endpoint and an EC2 instance to test with. \u0026ldquo;VPC On-Prem\u0026rdquo; simulates an on-premises environment such as a factory or corporate datacenter. An EC2 instance running strongSwan VPN software has been deployed in \u0026ldquo;VPC On-prem\u0026rdquo; and automatically configured to establish a Site-to-Site VPN tunnel with AWS Transit Gateway. This VPN simulates connectivity from an on-premises location to the AWS cloud. To minimize costs, only one VPN instance is provisioned to support this workshop. When planning VPN connectivity for your production workloads, AWS recommends using multiple VPN devices for high availability. "
},
{
	"uri": "https://my-cloud-journey-e7994.web.app/5-workshop/5.4-s3-onprem/5.4.1-prepare/",
	"title": "Prepare the environment",
	"tags": [],
	"description": "",
	"content": "To prepare for this part of the workshop you will need to:\nDeploying a CloudFormation stack Modifying a VPC route table. These components work together to simulate on-premises DNS forwarding and name resolution.\nDeploy the CloudFormation stack The CloudFormation template will create additional services to support an on-premises simulation:\nOne Route 53 Private Hosted Zone that hosts Alias records for the PrivateLink S3 endpoint One Route 53 Inbound Resolver endpoint that enables \u0026ldquo;VPC Cloud\u0026rdquo; to resolve inbound DNS resolution requests to the Private Hosted Zone One Route 53 Outbound Resolver endpoint that enables \u0026ldquo;VPC On-prem\u0026rdquo; to forward DNS requests for S3 to \u0026ldquo;VPC Cloud\u0026rdquo; Click the following link to open the AWS CloudFormation console. The required template will be pre-loaded into the menu. Accept all default and click Create stack. It may take a few minutes for stack deployment to complete. You can continue with the next step without waiting for the deployemnt to finish.\nUpdate on-premise private route table This workshop uses a strongSwan VPN running on an EC2 instance to simulate connectivty between an on-premises datacenter and the AWS cloud. Most of the required components are provisioned before your start. To finalize the VPN configuration, you will modify the \u0026ldquo;VPC On-prem\u0026rdquo; routing table to direct traffic destined for the cloud to the strongSwan VPN instance.\nOpen the Amazon EC2 console\nSelect the instance named infra-vpngw-test. From the Details tab, copy the Instance ID and paste this into your text editor\nNavigate to the VPC menu by using the Search box at the top of the browser window.\nClick on Route Tables, select the RT Private On-prem route table, select the Routes tab, and click Edit Routes.\nClick Add route. Destination: your Cloud VPC cidr range Target: ID of your infra-vpngw-test instance (you saved in your editor at step 1) Click Save changes "
},
{
	"uri": "https://my-cloud-journey-e7994.web.app/1-worklog/1.1-week1/",
	"title": "Week 1 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 1 Objectives: Connect and get acquainted with members of First Cloud Journey. Understand basic AWS services, how to use the console \u0026amp; CLI. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Get acquainted with FCJ members, mentors, and supervisors. Learned about each member\u0026rsquo;s role and responsibilities in the project team. - Read and summarized internship unit rules and regulations including working hours, attendance policy, communication channels, task reporting, and security guidelines. - Understood expectations for weekly progress reports and deliverables. 06/09/2025 13/09/2025 3 - Learned about AWS Global Infrastructure (Regions, Availability Zones, Edge Locations). - Studied key AWS Service Categories: + Compute: EC2, Lambda, Elastic Beanstalk, Auto Scaling. + Storage: S3 (standard, IA, Glacier), EBS, EFS. + Networking: VPC, Subnets, Internet Gateway, NAT Gateway, Route 53. + Database: RDS (MySQL, PostgreSQL), DynamoDB, Aurora. + Security \u0026amp; Identity: IAM (Users, Groups, Roles, Policies), KMS. + Monitoring \u0026amp; Management: CloudWatch (metrics \u0026amp; alarms), CloudTrail (logs), Trusted Advisor. - Took detailed notes of use cases, pricing considerations, and real-world examples. 06/09/2025 13/09/2025 https://cloudjourney.awsstudygroup.com/ 4 - Successfully created AWS Free Tier account, enabled MFA for root user for better security. - Configured Billing Alerts in CloudWatch to monitor cost usage. - Learned navigation of AWS Management Console, explored service categories, search bar, and pinned favorite services. - Installed and configured AWS CLI locally: + Generated Access Key \u0026amp; Secret Key from IAM. + Set Default Region and Output Format using aws configure. + Verified configuration with aws sts get-caller-identity. - Practice: Ran commands like aws s3 ls, aws ec2 describe-regions, aws ec2 describe-instances to confirm CLI works correctly. 06/09/2025 13/09/2025 https://cloudjourney.awsstudygroup.com/ 5 - Learned about Amazon EC2 core concepts: + Instance Types: General Purpose, Compute Optimized, Memory Optimized, Storage Optimized. + AMI: Choosing right image (Amazon Linux 2, Ubuntu, Windows Server). + EBS: gp3, io2, sc1, and their performance characteristics. + Key Pairs: Importance for SSH authentication. + Security Groups: Inbound and Outbound rule configuration. - Studied Elastic IP concept for static public IPs. - Learned different ways to connect to EC2: + SSH from local terminal. + Session Manager (browser-based). + EC2 Instance Connect. 06/09/2025 13/09/2025 https://cloudjourney.awsstudygroup.com/ 6 - Hands-on Practice: + Launched a t2.micro EC2 instance under Free Tier in a chosen region. + Generated key pair, downloaded .pem file, and updated permissions (chmod 400 key.pem). + Successfully connected to EC2 via SSH using terminal command ssh -i key.pem ec2-user@\u0026lt;public-ip\u0026gt;. + Created new EBS volume, attached it to instance, formatted and mounted it (mkfs -t xfs /dev/xvdf). + Verified data persistence after instance reboot. + Took screenshots for documentation and future reference. - Learned how to stop, start, and terminate EC2 instances and the difference between them. 06/09/2025 13/09/2025 https://cloudjourney.awsstudygroup.com/ Week 1 Achievements: Gained a solid understanding of AWS Cloud Computing concepts and mastered the basic service groups:\nCompute – EC2 (virtual servers), Lambda (serverless), Auto Scaling, Elastic Beanstalk. Storage – S3 (object storage), EBS (block storage), EFS (file storage), lifecycle management policies. Networking – VPC, Subnets, Internet Gateway, NAT Gateway, Route Tables, Security Groups, Route 53. Database – RDS (MySQL, PostgreSQL), DynamoDB (NoSQL), Aurora, database backup \u0026amp; restore strategies. Monitoring \u0026amp; Security – IAM (users, groups, roles), CloudWatch (metrics \u0026amp; alarms), CloudTrail (logs). Successfully created and configured an AWS Free Tier account, including:\nEnabled MFA on the root account for added security. Configured Billing Alerts to avoid unexpected charges. Set up a personal IAM user with administrator access for safer daily operations. Became familiar with the AWS Management Console:\nNavigated through service categories and pinned frequently used services. Explored EC2, S3, VPC, and IAM dashboards. Learned to locate documentation and pricing calculators from the console. Installed and configured AWS CLI on the computer, including:\nGenerated Access Key \u0026amp; Secret Key from IAM. Configured Default Region and Output Format with aws configure. Verified identity using aws sts get-caller-identity. Stored credentials securely and learned how to rotate keys if needed. Used AWS CLI to perform essential operations such as:\nRetrieve account information and CLI configuration. List available AWS regions (aws ec2 describe-regions). View EC2 instances, AMIs, and security groups. Create and manage key pairs for SSH access. Check running services and their states. Acquired the ability to combine AWS Management Console and CLI:\nLaunched resources from the Console and monitored/managed them with CLI. Practiced stopping/starting EC2 instances from CLI and verifying status in Console. Understood advantages of automation and scripting for repeatable tasks. Documented each step with screenshots and notes for easy reference and reproducibility.\nLearned about cost optimization and security best practices as part of AWS Well-Architected Framework.\nGained confidence to explore more advanced AWS services in the future such as S3 static website hosting, VPC design, and load balancing.\n"
},
{
	"uri": "https://my-cloud-journey-e7994.web.app/1-worklog/1.2-week2/",
	"title": "Week 1 Worklog",
	"tags": [],
	"description": "",
	"content": "\r⚠️ Note: The following information is for reference purposes only. Please do not copy verbatim for your own report, including this warning.\nWeek 1 Objectives: Connect and get acquainted with members of First Cloud Journey. Understand basic AWS services, how to use the console \u0026amp; CLI. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Get acquainted with FCJ members - Read and take note of internship unit rules and regulations 08/11/2025 08/11/2025 3 - Learn about AWS and its types of services + Compute + Storage + Networking + Database + \u0026hellip; 08/12/2025 08/12/2025 https://cloudjourney.awsstudygroup.com/ 4 - Create AWS Free Tier account - Learn about AWS Console \u0026amp; AWS CLI - Practice: + Create AWS account + Install \u0026amp; configure AWS CLI + How to use AWS CLI 08/13/2025 08/13/2025 https://cloudjourney.awsstudygroup.com/ 5 - Learn basic EC2: + Instance types + AMI + EBS + \u0026hellip; - SSH connection methods to EC2 - Learn about Elastic IP 08/14/2025 08/15/2025 https://cloudjourney.awsstudygroup.com/ 6 - Practice: + Launch an EC2 instance + Connect via SSH + Attach an EBS volume 08/15/2025 08/15/2025 https://cloudjourney.awsstudygroup.com/ Week 1 Achievements: Understood what AWS is and mastered the basic service groups:\nCompute Storage Networking Database \u0026hellip; Successfully created and configured an AWS Free Tier account.\nBecame familiar with the AWS Management Console and learned how to find, access, and use services via the web interface.\nInstalled and configured AWS CLI on the computer, including:\nAccess Key Secret Key Default Region \u0026hellip; Used AWS CLI to perform basic operations such as:\nCheck account \u0026amp; configuration information Retrieve the list of regions View EC2 service Create and manage key pairs Check information about running services \u0026hellip; Acquired the ability to connect between the web interface and CLI to manage AWS resources in parallel.\n\u0026hellip;\n"
},
{
	"uri": "https://my-cloud-journey-e7994.web.app/1-worklog/",
	"title": "Worklog",
	"tags": [],
	"description": "",
	"content": "Typically, and as a standard, a worklog is carried out over about 3 months (throughout the internship period) with weekly contents as follows:\nWeek 1: Getting familiar with AWS and basic AWS services\nWeek 2: Doing task A\u0026hellip;\nWeek 3: Doing task B\u0026hellip;\nWeek 4: Doing task C\u0026hellip;\nWeek 5: Doing task D\u0026hellip;\nWeek 6: Doing task E\u0026hellip;\nWeek 7: Doing task G\u0026hellip;\nWeek 8: Doing task H\u0026hellip;\nWeek 9: Doing task I\u0026hellip;\nWeek 10: Doing task L\u0026hellip;\nWeek 11: Doing task M\u0026hellip;\nWeek 12: Doing task N\u0026hellip;\n"
},
{
	"uri": "https://my-cloud-journey-e7994.web.app/4-eventparticipated/4.1-event1/",
	"title": "Kick-off AWS First Cloud Journey Workforce",
	"tags": [],
	"description": "",
	"content": "Event Objectives Celebrate the students who successfully joined the AWS First Cloud Journey – Training on the Job (OJT FALL 2025) program Mark the beginning of a structured learning journey and real-world cloud experience with Amazon Web Services (AWS) Equip participants with hands-on skills in Cloud, DevOps, Security, AI/ML, and Data \u0026amp; Analytics Connect students with the AWS Study Group community (47,000+ members) and AWS partner companies Build a strong bridge between knowledge – technology – career, empowering a new generation of AWS Builders in Vietnam Speakers Nguyen Tran Phuoc Bao – Head of Corporate Relations, FPT University Nguyen Gia Hung – Head of Solutions Architect, AWS Vietnam Do Huy Thang – DevOps Lead, VNG Danh Hoang Hieu Nghi – GenAI Engineer, Renova Bui Ho Linh Nhi – AI Engineer, SoftwareOne Pham Nguyen Hai Anh – Cloud Engineer, G-Asia Pacific Nguyen Dong Thanh Hiep – Principal Cloud Engineer, G-Asia Pacific Key Highlights Launching the AWS First Cloud Journey Workforce Program The first time I have seen such amazing people doing amazing activities in AWS HCMC. It\u0026rsquo;s such an amazing thing that I have ever witnessed.\nThe event marked the official kickoff for more than 150 students in the OJT Fall 2025 cohort.\nSince its inception in 2021, the AWS First Cloud Journey has supported 2,000+ students, with many alumni now working at leading technology companies in Vietnam and abroad.\nThroughout the kickoff, speakers shared insights on:\nThe future of Cloud Computing in Vietnam Career pathways in DevOps, Cloud, and AI/ML Workforce trends and market demands in the coming years Event Agenda Overview 8:30 – 9:00 | Check-in, Networking \u0026amp; Group Photos 9:00 – 9:15 | Opening remarks from FPT University 9:15 – 9:40 | AWS First Cloud Journey \u0026amp; Future Direction – Nguyen Gia Hung 9:40 – 10:05 | DevOps \u0026amp; Career Opportunities – Do Huy Thang 10:05 – 10:20 | Tea Break \u0026amp; Networking 10:20 – 10:40 | From FCJ to GenAI Engineer – Danh Hoang Hieu Nghi 10:40 – 11:00 | She in Tech – The FCJ Journey – Bui Ho Linh Nhi 11:00 – 11:20 | A Day in the Life of a Cloud Engineer – Pham Nguyen Hai Anh 11:20 – 11:40 | Becoming a Cloud Engineer – Nguyen Dong Thanh Hiep 11:40 – 12:00 | Q\u0026amp;A Session \u0026amp; Final Group Photos Key Takeaways Career Insights \u0026amp; Development Strategy Cloud and DevOps remain among the most in-demand technology fields Speakers emphasized essential skills: Cloud fundamentals (IAM, VPC, Compute, Storage…) CI/CD \u0026amp; DevOps mindset Analytical thinking and problem-solving A recommended learning path for students: Cloud Foundation → Hands-on Projects → DevOps Tools → Specialization (AI/ML, Security, Data) Industry \u0026amp; Alumni Perspectives AWS reaffirmed its mission to build the next generation of AWS Builders in Vietnam Tech companies highlighted hiring needs in: Cloud Engineering DevOps Engineering AI/ML Engineering Data Engineering Alumni shared how self-learning, hands-on practice, and community engagement shaped their success. Applying to Work Start building AWS fundamentals: IAM, EC2, S3, VPC Begin practicing with DevOps tools: Git, Docker, CI/CD (GitHub Actions) Develop mini-projects and write technical documentation Join AWS Study Group events, workshops, and mentoring sessions Gradually explore advanced topics: Serverless, Containers, IaC, AI/ML Event Experience As an intern of the AWS FCJ HCMC Team, attending the Kick-off AWS First Cloud Journey Workforce OJT FALL 2025 was an inspiring and motivating experience.\nWhat I learned from the event A clearer understanding of the Cloud \u0026amp; DevOps career landscape in Vietnam Valuable inspiration from FCJ alumni who have successfully built their careers Essential mindsets emphasized throughout the event: Self-learning Experimentation Embracing challenges The importance of networking and staying connected with peers and mentors Networking \u0026amp; Community Met mentors, speakers, AWS specialists, and engineers working in cloud, DevOps, and AI Built a strong network with teammates and fellow FCJ participants The kickoff event not only provided career insights and technical direction, but also fueled my motivation to begin my journey toward becoming an AWS Builder.\n"
},
{
	"uri": "https://my-cloud-journey-e7994.web.app/4-eventparticipated/4.2-event2/",
	"title": "Cloud Day AWS 2025 in HCMC",
	"tags": [],
	"description": "",
	"content": "Event Objectives Experience the plenary session live-streamed from Hanoi Featuring keynote speakers and breakthrough announcements that will shape Vietnam\u0026rsquo;s cloud future Generative AI: Explore the latest developments and practical applications Data Analytics: Transform your business through data-driven insights Migration \u0026amp; Modernization: Navigate your cloud transformation journey Speakers Eric Yeo – Country General Manager, Vietnam, Cambodia, Laos \u0026amp; Myanmar, AWS Jaime Valles – Vice President, Commercial Sales \u0026amp; Business Development APJ, AWS Jeff Johnson – Managing Director ASEAN, AWS Dr Jens Lottner – Chief Executive Officer, Techcombank Trang Phung – CEO, U2U Network Vu Van – Co-founder \u0026amp; CEO, ELSA Corp Nguyen Hoa Binh – Chairman, Nexttech Group Dieter Botha – CEO, Tymex Nguyen Van Hai – Director of Software Engineering, Techcombank Nguyen The Vinh – Co-Founder \u0026amp; CTO, Ninety Eight Nguyen Minh Ngan – AI Specialist, OCB Nguyen Manh Tuyen – Head of Data Application, LPBank Securities Key Highlights Vietnam Cloud Day 2025 – Hybrid Experience While the main event takes place in Hanoi, I was so excited to watch a seamless hybrid experience right here in Ho Chi Minh City.\nConnect with cloud innovators and industry leaders without leaving Ho Chi Minh City!\nExperience the plenary session live-streamed from Hanoi, featuring keynote speakers and breakthrough announcements that will shape Vietnam\u0026rsquo;s cloud future.\nFocus Areas \u0026amp; Interactive Sessions Ho Chi Minh City sessions will dive deep into three major themes:\nGenerative AI – Explore the latest developments and practical applications Data Analytics – Transform your business through data-driven insights Migration \u0026amp; Modernization – Navigate your cloud transformation journey Considerable Benefits Network locally: Meet and collaborate with Ho Chi Minh City\u0026rsquo;s vibrant tech community Learn from experts: Gain actionable knowledge from Vietnam’s top cloud leaders Stay ahead: Get firsthand updates on the future of cloud computing in Vietnam Key Takeaways Strategic Insights from Vietnam Cloud Day 2025 Cloud adoption momentum: Businesses across Vietnam are accelerating digital transformation Government collaboration: Opening remarks highlighted national cloud-first initiatives Customer success stories: Techcombank and U2U Network shared their journey to AWS adoption Executive leadership focus: Panel discussion emphasized aligning GenAI initiatives with business goals Technical Deep-Dive – Generative AI \u0026amp; Data Unified data foundation: Strategies for scalable, governed data pipelines on AWS GenAI adoption roadmap: Practical guidance on leveraging AWS services for AI-driven innovation AI-Driven Development Lifecycle (AI-DLC): Embedding AI throughout the software development process Security best practices: Protecting data, models, and apps with AWS’s layered security controls AI Agents: Moving beyond automation to intelligent, adaptive systems that multiply productivity Architecture \u0026amp; Operations Event-driven and modular design: Build resilient, loosely coupled systems Compute options: Choose between EC2, containers, and serverless based on workload requirements Scalability \u0026amp; observability: Design for growth with logging, monitoring, and cost controls Applying to Work Evaluate current workloads: Identify which applications can move to AWS for immediate ROI Build a data foundation: Start with ingestion, storage, and processing pipelines for analytics and AI Experiment with GenAI: Pilot use cases with Amazon Bedrock or SageMaker Strengthen security posture: Apply least-privilege IAM policies and secure network configurations Upskill teams: Encourage learning AWS AI/ML services to stay competitive Event Experience This is the first time I knew Eric Yeo - The AWS regional manager. He\u0026rsquo;s such a wonderful leader. Attending “Vietnam Cloud Day 2025: Ho Chi Minh City Connect Edition for Builders” was an insightful and impactful experience, providing a clear roadmap for modernizing applications and databases using cutting-edge approaches and tools. My key takeaways include:\nLearning from Industry Leaders Gained valuable insights from AWS experts and executives from leading technology companies. Real-world case studies deepened my understanding of applying Domain-Driven Design (DDD) and Event-Driven Architecture to enterprise-scale projects. Hands-On Technical Experience Participated in event storming workshops, visualizing how to translate business processes into domain events. Practiced breaking down systems into microservices with clearly defined bounded contexts to reduce complexity. Explored trade-offs between synchronous vs. asynchronous communication, and learned when to apply pub/sub, point-to-point, and streaming patterns. Exploring Modern Tools Discovered Amazon Q Developer, an AI-powered assistant that supports the full Software Development Lifecycle (SDLC). Learned to automate code refactoring and implement serverless architectures using AWS Lambda to improve agility and delivery speed. Networking \u0026amp; Collaboration Connected with AWS specialists, business leaders, and fellow builders, strengthening the ubiquitous language between technical and business teams. Engaged in discussions that highlighted the importance of a business-first mindset for technology decisions. Key Lessons Learned Applying DDD and event-driven patterns significantly improves scalability, resilience, and maintainability. Successful modernization requires a phased, well-planned approach with clear ROI measurement to mitigate risks. Leveraging AI tools like Amazon Q Developer can dramatically accelerate development and streamline team workflows. Some event photos Overall, the event provided not just technical knowledge but also reshaped my perspective on application design, system modernization, and effective cross-team collaboration.\n"
},
{
	"uri": "https://my-cloud-journey-e7994.web.app/5-workshop/5.4-s3-onprem/5.4.2-create-interface-enpoint/",
	"title": "Create an S3 Interface endpoint",
	"tags": [],
	"description": "",
	"content": "In this section you will create and test an S3 interface endpoint using the simulated on-premises environment deployed as part of this workshop.\nReturn to the Amazon VPC menu. In the navigation pane, choose Endpoints, then click Create Endpoint.\nIn Create endpoint console:\nName the interface endpoint In Service category, choose aws services In the Search box, type S3 and press Enter. Select the endpoint named com.amazonaws.us-east-1.s3. Ensure that the Type column indicates Interface. For VPC, select VPC Cloud from the drop-down. Make sure to choose \u0026ldquo;VPC Cloud\u0026rdquo; and not \u0026ldquo;VPC On-prem\u0026rdquo;\nExpand Additional settings and ensure that Enable DNS name is not selected (we will use this in the next part of the workshop) Select 2 subnets in the following AZs: us-east-1a and us-east-1b For Security group, choose SGforS3Endpoint: Keep the default policy - full access and click Create endpoint Congratulation on successfully creating S3 interface endpoint. In the next step, we will test the interface endpoint.\n"
},
{
	"uri": "https://my-cloud-journey-e7994.web.app/3-blogstranslated/3.2-blog2/",
	"title": "Minimize risk through defense in depth: Building a comprehensive AWS control framework",
	"tags": [],
	"description": "",
	"content": "Authors: Luis Pastor, Rodolfo Brenes, and George’son Tib\nPublished At: September 23, 2025\nCategories: AWS CloudFormation, AWS Config, AWS Control Tower, AWS Organizations, AWS Security Hub, Security, Identity \u0026amp; Compliance\nChallenges Faced by Security and Governance Teams Security and governance teams across all environments face a common challenge: translating abstract security and governance requirements into a concrete, integrated control framework. AWS services provide capabilities that organizations can use to implement controls across multiple architectural layers—from provisioning infrastructure to continuous operational monitoring.\nMany organizations deploy multi-account environments using AWS Control Tower or Landing Zone Accelerator as the foundational layer for governance and security architecture. Once the environment is set up, organizations typically add detective controls from services such as AWS Security Hub and AWS Config, based on security, compliance, and operational needs. While this progression is a strong starting point, there remains significant opportunity to implement defense-in-depth strategies that strengthen the overall security posture.\nHighly regulated industries such as fintech and financial services often serve as the gold standard for governance and security controls. While these sectors have developed robust frameworks, continuous improvement and cross-industry learning remain valuable for organizations seeking to enhance their control environments. However, many organizations struggle to move beyond a baseline compliance mindset. Based on our experience with customers across industries, this limited perspective often stems from factors such as:\nImmediate compliance pressure Limited resources Lack of understanding of control maturity roadmaps Overemphasis on detection vs. prevention Preference for technology-agnostic controls instead of leveraging AWS-integrated capabilities—leading to unnecessary complexity The good news:\nA more holistic approach—using AWS preventive, proactive, detective, and responsive controls—can dramatically reduce risk while enabling operational efficiency through automation.\nThis article presents a practical framework to help you develop a strong security and governance control strategy. We explore how your organization can advance from a detection-centric posture to a multilayered control framework, including real-world examples across the resource lifecycle—such as infrastructure-as-code testing and preventative controls like:\nService Control Policies (SCPs) Resource Control Policies (RCPs) Declarative Policies (DPs) Grounded in best practices from highly regulated industries and enhanced by modern cloud capabilities such as AWS Organizations and AWS Control Tower, we provide a structured approach for elevating your organization’s control environment beyond basic compliance.\nCustomer Challenges in Control Implementation Organizations encounter many obstacles when attempting to implement a comprehensive AWS control framework. Below are key challenges:\n1. Limited Resources and Skill Gaps Security teams often face expanding responsibilities while operating with constrained resources. They commonly adopt detective controls first because they appear easier to implement and provide immediate visibility—but this can create critical gaps in security posture.\nTeams may also lack expertise across all control types, especially preventative, proactive, and responsive controls. Pressure to demonstrate fast improvements often leads to tactical fixes instead of strategic, multi-layered security design.\n2. Analysis Paralysis Choosing which tools to prioritize is difficult. The vast array of AWS security services and third-party tooling can overwhelm teams. Converting compliance requirements into cloud-focused capabilities while maintaining visibility of emerging threats adds further complexity.\nThese challenges may delay important improvements while teams search for a “perfect solution.”\n3. Misunderstanding Defense in Depth Defense in depth is often misunderstood. Some believe that a single strong control—such as strict IAM roles or least-privilege policies—is sufficient.\nThis overlooks the importance of multiple coordinated controls across different layers. Many teams also underestimate the role of organizational-level controls like SCPs, which complement workload-level controls to create a stronger overall posture.\n4. Security Maturity Journey Challenges Many organizations remain stuck at early maturity stages, relying heavily on detection without advancing toward prevention. Controls are often applied inconsistently and lack alignment to a broader security strategy.\nMeasuring progress over time is also difficult—contributing to stalled maturity.\n5. Scale and Consistency Issues As AWS environments grow, consistent governance becomes harder. Managing exceptions and special cases across growing infrastructure introduces operational complexity. Controls may be partially implemented or implemented incorrectly—reducing their intended impact.\nStrategic Investment in Security Implementing comprehensive controls requires initial investment, but long-term benefits can significantly transform organizational operations.\nThe transformation begins with establishing baseline controls using proven starting points like:\nAWS Control Tower Customizations for AWS Control Tower These tools provide hundreds of built-in controls and guardrails for secure multi-account architectures.\nRather than manually constructing all account-level and resource-level controls, you can accelerate by using AWS-native governance frameworks and automation.\nOnce baseline controls are in place, benefits extend beyond the security team:\nDevelopment and operations teams deploy faster and more confidently Security becomes an enabler, not a blocker Guardrails ensure strong posture without slowing innovation As your organization evolves, automation and layered controls reduce operational burden and help shift security teams from reactive firefighting to proactive risk management.\nUnderstanding the Types of Security Controls and How They Work Together AWS defines four major categories of controls, all of which work together to form a comprehensive security framework. Let’s examine each type using a common requirement: preventing data leakage from public Amazon S3 buckets.\nPreventative Controls Preventative controls establish the foundational security requirements by defining policies, standards, and expectations before resources are deployed.\nAn example S3 requirement:\nAll S3 buckets must be private by default, and public access may only be granted through an approved exception process.\nPreventative controls apply across organizational and resource levels:\nOrganization Level SCPs to block creation of publicly accessible S3 buckets SCPs to prevent unsafe S3 object uploads, such as blocking SSE-C encryption unless explicitly approved { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;DenySSECEncryption\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Deny\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:PutObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;Null\u0026#34;: { \u0026#34;s3:x-amz-server-side-encryption-customer-algorithm\u0026#34;: \u0026#34;false\u0026#34; } } } ] } Resource Level "
},
{
	"uri": "https://my-cloud-journey-e7994.web.app/5-workshop/5.2-prerequiste/",
	"title": "Prerequiste",
	"tags": [],
	"description": "",
	"content": "IAM permissions Add the following IAM permission policy to your user account to deploy and cleanup this workshop.\n{\r\u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;,\r\u0026#34;Statement\u0026#34;: [\r{\r\u0026#34;Sid\u0026#34;: \u0026#34;VisualEditor0\u0026#34;,\r\u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;,\r\u0026#34;Action\u0026#34;: [\r\u0026#34;cloudformation:*\u0026#34;,\r\u0026#34;cloudwatch:*\u0026#34;,\r\u0026#34;ec2:AcceptTransitGatewayPeeringAttachment\u0026#34;,\r\u0026#34;ec2:AcceptTransitGatewayVpcAttachment\u0026#34;,\r\u0026#34;ec2:AllocateAddress\u0026#34;,\r\u0026#34;ec2:AssociateAddress\u0026#34;,\r\u0026#34;ec2:AssociateIamInstanceProfile\u0026#34;,\r\u0026#34;ec2:AssociateRouteTable\u0026#34;,\r\u0026#34;ec2:AssociateSubnetCidrBlock\u0026#34;,\r\u0026#34;ec2:AssociateTransitGatewayRouteTable\u0026#34;,\r\u0026#34;ec2:AssociateVpcCidrBlock\u0026#34;,\r\u0026#34;ec2:AttachInternetGateway\u0026#34;,\r\u0026#34;ec2:AttachNetworkInterface\u0026#34;,\r\u0026#34;ec2:AttachVolume\u0026#34;,\r\u0026#34;ec2:AttachVpnGateway\u0026#34;,\r\u0026#34;ec2:AuthorizeSecurityGroupEgress\u0026#34;,\r\u0026#34;ec2:AuthorizeSecurityGroupIngress\u0026#34;,\r\u0026#34;ec2:CreateClientVpnEndpoint\u0026#34;,\r\u0026#34;ec2:CreateClientVpnRoute\u0026#34;,\r\u0026#34;ec2:CreateCustomerGateway\u0026#34;,\r\u0026#34;ec2:CreateDhcpOptions\u0026#34;,\r\u0026#34;ec2:CreateFlowLogs\u0026#34;,\r\u0026#34;ec2:CreateInternetGateway\u0026#34;,\r\u0026#34;ec2:CreateLaunchTemplate\u0026#34;,\r\u0026#34;ec2:CreateNetworkAcl\u0026#34;,\r\u0026#34;ec2:CreateNetworkInterface\u0026#34;,\r\u0026#34;ec2:CreateNetworkInterfacePermission\u0026#34;,\r\u0026#34;ec2:CreateRoute\u0026#34;,\r\u0026#34;ec2:CreateRouteTable\u0026#34;,\r\u0026#34;ec2:CreateSecurityGroup\u0026#34;,\r\u0026#34;ec2:CreateSubnet\u0026#34;,\r\u0026#34;ec2:CreateSubnetCidrReservation\u0026#34;,\r\u0026#34;ec2:CreateTags\u0026#34;,\r\u0026#34;ec2:CreateTransitGateway\u0026#34;,\r\u0026#34;ec2:CreateTransitGatewayPeeringAttachment\u0026#34;,\r\u0026#34;ec2:CreateTransitGatewayPrefixListReference\u0026#34;,\r\u0026#34;ec2:CreateTransitGatewayRoute\u0026#34;,\r\u0026#34;ec2:CreateTransitGatewayRouteTable\u0026#34;,\r\u0026#34;ec2:CreateTransitGatewayVpcAttachment\u0026#34;,\r\u0026#34;ec2:CreateVpc\u0026#34;,\r\u0026#34;ec2:CreateVpcEndpoint\u0026#34;,\r\u0026#34;ec2:CreateVpcEndpointConnectionNotification\u0026#34;,\r\u0026#34;ec2:CreateVpcEndpointServiceConfiguration\u0026#34;,\r\u0026#34;ec2:CreateVpnConnection\u0026#34;,\r\u0026#34;ec2:CreateVpnConnectionRoute\u0026#34;,\r\u0026#34;ec2:CreateVpnGateway\u0026#34;,\r\u0026#34;ec2:DeleteCustomerGateway\u0026#34;,\r\u0026#34;ec2:DeleteFlowLogs\u0026#34;,\r\u0026#34;ec2:DeleteInternetGateway\u0026#34;,\r\u0026#34;ec2:DeleteNetworkInterface\u0026#34;,\r\u0026#34;ec2:DeleteNetworkInterfacePermission\u0026#34;,\r\u0026#34;ec2:DeleteRoute\u0026#34;,\r\u0026#34;ec2:DeleteRouteTable\u0026#34;,\r\u0026#34;ec2:DeleteSecurityGroup\u0026#34;,\r\u0026#34;ec2:DeleteSubnet\u0026#34;,\r\u0026#34;ec2:DeleteSubnetCidrReservation\u0026#34;,\r\u0026#34;ec2:DeleteTags\u0026#34;,\r\u0026#34;ec2:DeleteTransitGateway\u0026#34;,\r\u0026#34;ec2:DeleteTransitGatewayPeeringAttachment\u0026#34;,\r\u0026#34;ec2:DeleteTransitGatewayPrefixListReference\u0026#34;,\r\u0026#34;ec2:DeleteTransitGatewayRoute\u0026#34;,\r\u0026#34;ec2:DeleteTransitGatewayRouteTable\u0026#34;,\r\u0026#34;ec2:DeleteTransitGatewayVpcAttachment\u0026#34;,\r\u0026#34;ec2:DeleteVpc\u0026#34;,\r\u0026#34;ec2:DeleteVpcEndpoints\u0026#34;,\r\u0026#34;ec2:DeleteVpcEndpointServiceConfigurations\u0026#34;,\r\u0026#34;ec2:DeleteVpnConnection\u0026#34;,\r\u0026#34;ec2:DeleteVpnConnectionRoute\u0026#34;,\r\u0026#34;ec2:Describe*\u0026#34;,\r\u0026#34;ec2:DetachInternetGateway\u0026#34;,\r\u0026#34;ec2:DisassociateAddress\u0026#34;,\r\u0026#34;ec2:DisassociateRouteTable\u0026#34;,\r\u0026#34;ec2:GetLaunchTemplateData\u0026#34;,\r\u0026#34;ec2:GetTransitGatewayAttachmentPropagations\u0026#34;,\r\u0026#34;ec2:ModifyInstanceAttribute\u0026#34;,\r\u0026#34;ec2:ModifySecurityGroupRules\u0026#34;,\r\u0026#34;ec2:ModifyTransitGatewayVpcAttachment\u0026#34;,\r\u0026#34;ec2:ModifyVpcAttribute\u0026#34;,\r\u0026#34;ec2:ModifyVpcEndpoint\u0026#34;,\r\u0026#34;ec2:ReleaseAddress\u0026#34;,\r\u0026#34;ec2:ReplaceRoute\u0026#34;,\r\u0026#34;ec2:RevokeSecurityGroupEgress\u0026#34;,\r\u0026#34;ec2:RevokeSecurityGroupIngress\u0026#34;,\r\u0026#34;ec2:RunInstances\u0026#34;,\r\u0026#34;ec2:StartInstances\u0026#34;,\r\u0026#34;ec2:StopInstances\u0026#34;,\r\u0026#34;ec2:UpdateSecurityGroupRuleDescriptionsEgress\u0026#34;,\r\u0026#34;ec2:UpdateSecurityGroupRuleDescriptionsIngress\u0026#34;,\r\u0026#34;iam:AddRoleToInstanceProfile\u0026#34;,\r\u0026#34;iam:AttachRolePolicy\u0026#34;,\r\u0026#34;iam:CreateInstanceProfile\u0026#34;,\r\u0026#34;iam:CreatePolicy\u0026#34;,\r\u0026#34;iam:CreateRole\u0026#34;,\r\u0026#34;iam:DeleteInstanceProfile\u0026#34;,\r\u0026#34;iam:DeletePolicy\u0026#34;,\r\u0026#34;iam:DeleteRole\u0026#34;,\r\u0026#34;iam:DeleteRolePolicy\u0026#34;,\r\u0026#34;iam:DetachRolePolicy\u0026#34;,\r\u0026#34;iam:GetInstanceProfile\u0026#34;,\r\u0026#34;iam:GetPolicy\u0026#34;,\r\u0026#34;iam:GetRole\u0026#34;,\r\u0026#34;iam:GetRolePolicy\u0026#34;,\r\u0026#34;iam:ListPolicyVersions\u0026#34;,\r\u0026#34;iam:ListRoles\u0026#34;,\r\u0026#34;iam:PassRole\u0026#34;,\r\u0026#34;iam:PutRolePolicy\u0026#34;,\r\u0026#34;iam:RemoveRoleFromInstanceProfile\u0026#34;,\r\u0026#34;lambda:CreateFunction\u0026#34;,\r\u0026#34;lambda:DeleteFunction\u0026#34;,\r\u0026#34;lambda:DeleteLayerVersion\u0026#34;,\r\u0026#34;lambda:GetFunction\u0026#34;,\r\u0026#34;lambda:GetLayerVersion\u0026#34;,\r\u0026#34;lambda:InvokeFunction\u0026#34;,\r\u0026#34;lambda:PublishLayerVersion\u0026#34;,\r\u0026#34;logs:CreateLogGroup\u0026#34;,\r\u0026#34;logs:DeleteLogGroup\u0026#34;,\r\u0026#34;logs:DescribeLogGroups\u0026#34;,\r\u0026#34;logs:PutRetentionPolicy\u0026#34;,\r\u0026#34;route53:ChangeTagsForResource\u0026#34;,\r\u0026#34;route53:CreateHealthCheck\u0026#34;,\r\u0026#34;route53:CreateHostedZone\u0026#34;,\r\u0026#34;route53:CreateTrafficPolicy\u0026#34;,\r\u0026#34;route53:DeleteHostedZone\u0026#34;,\r\u0026#34;route53:DisassociateVPCFromHostedZone\u0026#34;,\r\u0026#34;route53:GetHostedZone\u0026#34;,\r\u0026#34;route53:ListHostedZones\u0026#34;,\r\u0026#34;route53domains:ListDomains\u0026#34;,\r\u0026#34;route53domains:ListOperations\u0026#34;,\r\u0026#34;route53domains:ListTagsForDomain\u0026#34;,\r\u0026#34;route53resolver:AssociateResolverEndpointIpAddress\u0026#34;,\r\u0026#34;route53resolver:AssociateResolverRule\u0026#34;,\r\u0026#34;route53resolver:CreateResolverEndpoint\u0026#34;,\r\u0026#34;route53resolver:CreateResolverRule\u0026#34;,\r\u0026#34;route53resolver:DeleteResolverEndpoint\u0026#34;,\r\u0026#34;route53resolver:DeleteResolverRule\u0026#34;,\r\u0026#34;route53resolver:DisassociateResolverEndpointIpAddress\u0026#34;,\r\u0026#34;route53resolver:DisassociateResolverRule\u0026#34;,\r\u0026#34;route53resolver:GetResolverEndpoint\u0026#34;,\r\u0026#34;route53resolver:GetResolverRule\u0026#34;,\r\u0026#34;route53resolver:ListResolverEndpointIpAddresses\u0026#34;,\r\u0026#34;route53resolver:ListResolverEndpoints\u0026#34;,\r\u0026#34;route53resolver:ListResolverRuleAssociations\u0026#34;,\r\u0026#34;route53resolver:ListResolverRules\u0026#34;,\r\u0026#34;route53resolver:ListTagsForResource\u0026#34;,\r\u0026#34;route53resolver:UpdateResolverEndpoint\u0026#34;,\r\u0026#34;route53resolver:UpdateResolverRule\u0026#34;,\r\u0026#34;s3:AbortMultipartUpload\u0026#34;,\r\u0026#34;s3:CreateBucket\u0026#34;,\r\u0026#34;s3:DeleteBucket\u0026#34;,\r\u0026#34;s3:DeleteObject\u0026#34;,\r\u0026#34;s3:GetAccountPublicAccessBlock\u0026#34;,\r\u0026#34;s3:GetBucketAcl\u0026#34;,\r\u0026#34;s3:GetBucketOwnershipControls\u0026#34;,\r\u0026#34;s3:GetBucketPolicy\u0026#34;,\r\u0026#34;s3:GetBucketPolicyStatus\u0026#34;,\r\u0026#34;s3:GetBucketPublicAccessBlock\u0026#34;,\r\u0026#34;s3:GetObject\u0026#34;,\r\u0026#34;s3:GetObjectVersion\u0026#34;,\r\u0026#34;s3:GetBucketVersioning\u0026#34;,\r\u0026#34;s3:ListAccessPoints\u0026#34;,\r\u0026#34;s3:ListAccessPointsForObjectLambda\u0026#34;,\r\u0026#34;s3:ListAllMyBuckets\u0026#34;,\r\u0026#34;s3:ListBucket\u0026#34;,\r\u0026#34;s3:ListBucketMultipartUploads\u0026#34;,\r\u0026#34;s3:ListBucketVersions\u0026#34;,\r\u0026#34;s3:ListJobs\u0026#34;,\r\u0026#34;s3:ListMultipartUploadParts\u0026#34;,\r\u0026#34;s3:ListMultiRegionAccessPoints\u0026#34;,\r\u0026#34;s3:ListStorageLensConfigurations\u0026#34;,\r\u0026#34;s3:PutAccountPublicAccessBlock\u0026#34;,\r\u0026#34;s3:PutBucketAcl\u0026#34;,\r\u0026#34;s3:PutBucketPolicy\u0026#34;,\r\u0026#34;s3:PutBucketPublicAccessBlock\u0026#34;,\r\u0026#34;s3:PutObject\u0026#34;,\r\u0026#34;secretsmanager:CreateSecret\u0026#34;,\r\u0026#34;secretsmanager:DeleteSecret\u0026#34;,\r\u0026#34;secretsmanager:DescribeSecret\u0026#34;,\r\u0026#34;secretsmanager:GetSecretValue\u0026#34;,\r\u0026#34;secretsmanager:ListSecrets\u0026#34;,\r\u0026#34;secretsmanager:ListSecretVersionIds\u0026#34;,\r\u0026#34;secretsmanager:PutResourcePolicy\u0026#34;,\r\u0026#34;secretsmanager:TagResource\u0026#34;,\r\u0026#34;secretsmanager:UpdateSecret\u0026#34;,\r\u0026#34;sns:ListTopics\u0026#34;,\r\u0026#34;ssm:DescribeInstanceProperties\u0026#34;,\r\u0026#34;ssm:DescribeSessions\u0026#34;,\r\u0026#34;ssm:GetConnectionStatus\u0026#34;,\r\u0026#34;ssm:GetParameters\u0026#34;,\r\u0026#34;ssm:ListAssociations\u0026#34;,\r\u0026#34;ssm:ResumeSession\u0026#34;,\r\u0026#34;ssm:StartSession\u0026#34;,\r\u0026#34;ssm:TerminateSession\u0026#34;\r],\r\u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34;\r}\r]\r} Provision resources using CloudFormation In this lab, we will use N.Virginia region (us-east-1).\nTo prepare the workshop environment, deploy this CloudFormation Template (click link): PrivateLinkWorkshop . Accept all of the defaults when deploying the template.\nTick 2 acknowledgement boxes Choose Create stack The ClouddFormation deployment requires about 15 minutes to complete.\n2 VPCs have been created 3 EC2s have been created "
},
{
	"uri": "https://my-cloud-journey-e7994.web.app/2-proposal/",
	"title": "Proposal",
	"tags": [],
	"description": "",
	"content": "In this section, you need to summarize the contents of the workshop that you plan to conduct.\nIoT Weather Platform for Lab Research A Unified AWS Serverless Solution for Real-Time Weather Monitoring 1. Executive Summary The IoT Weather Platform is designed for the ITea Lab team in Ho Chi Minh City to enhance weather data collection and analysis. It supports up to 5 weather stations, with potential scalability to 10-15, utilizing Raspberry Pi edge devices with ESP32 sensors to transmit data via MQTT. The platform leverages AWS Serverless services to deliver real-time monitoring, predictive analytics, and cost efficiency, with access restricted to 5 lab members via Amazon Cognito.\n2. Problem Statement What’s the Problem? Current weather stations require manual data collection, becoming unmanageable with multiple units. There is no centralized system for real-time data or analytics, and third-party platforms are costly and overly complex.\nThe Solution The platform uses AWS IoT Core to ingest MQTT data, AWS Lambda and API Gateway for processing, Amazon S3 for storage (including a data lake), and AWS Glue Crawlers and ETL jobs to extract, transform, and load data from the S3 data lake to another S3 bucket for analysis. AWS Amplify with Next.js provides the web interface, and Amazon Cognito ensures secure access. Similar to Thingsboard and CoreIoT, users can register new devices and manage connections, though this platform operates on a smaller scale and is designed for private use. Key features include real-time dashboards, trend analysis, and low operational costs.\nBenefits and Return on Investment The solution establishes a foundational resource for lab members to develop a larger IoT platform, serving as a study resource, and provides a data foundation for AI enthusiasts for model training or analysis. It reduces manual reporting for each station via a centralized platform, simplifying management and maintenance, and improves data reliability. Monthly costs are $0.66 USD per the AWS Pricing Calculator, with a 12-month total of $7.92 USD. All IoT equipment costs are covered by the existing weather station setup, eliminating additional development expenses. The break-even period of 6-12 months is achieved through significant time savings from reduced manual work.\n3. Solution Architecture The platform employs a serverless AWS architecture to manage data from 5 Raspberry Pi-based stations, scalable to 15. Data is ingested via AWS IoT Core, stored in an S3 data lake, and processed by AWS Glue Crawlers and ETL jobs to transform and load it into another S3 bucket for analysis. Lambda and API Gateway handle additional processing, while Amplify with Next.js hosts the dashboard, secured by Cognito. The architecture is detailed below:\nAWS Services Used AWS IoT Core: Ingests MQTT data from 5 stations, scalable to 15. AWS Lambda: Processes data and triggers Glue jobs (two functions). Amazon API Gateway: Facilitates web app communication. Amazon S3: Stores raw data in a data lake and processed outputs (two buckets). AWS Glue: Crawlers catalog data, and ETL jobs transform and load it. AWS Amplify: Hosts the Next.js web interface. Amazon Cognito: Secures access for lab users. Component Design Edge Devices: Raspberry Pi collects and filters sensor data, sending it to IoT Core. Data Ingestion: AWS IoT Core receives MQTT messages from the edge devices. Data Storage: Raw data is stored in an S3 data lake; processed data is stored in another S3 bucket. Data Processing: AWS Glue Crawlers catalog the data, and ETL jobs transform it for analysis. Web Interface: AWS Amplify hosts a Next.js app for real-time dashboards and analytics. User Management: Amazon Cognito manages user access, allowing up to 5 active accounts. 4. Technical Implementation Implementation Phases This project has two parts—setting up weather edge stations and building the weather platform—each following 4 phases:\nBuild Theory and Draw Architecture: Research Raspberry Pi setup with ESP32 sensors and design the AWS serverless architecture (1 month pre-internship) Calculate Price and Check Practicality: Use AWS Pricing Calculator to estimate costs and adjust if needed (Month 1). Fix Architecture for Cost or Solution Fit: Tweak the design (e.g., optimize Lambda with Next.js) to stay cost-effective and usable (Month 2). Develop, Test, and Deploy: Code the Raspberry Pi setup, AWS services with CDK/SDK, and Next.js app, then test and release to production (Months 2-3). Technical Requirements\nWeather Edge Station: Sensors (temperature, humidity, rainfall, wind speed), a microcontroller (ESP32), and a Raspberry Pi as the edge device. Raspberry Pi runs Raspbian, handles Docker for filtering, and sends 1 MB/day per station via MQTT over Wi-Fi. Weather Platform: Practical knowledge of AWS Amplify (hosting Next.js), Lambda (minimal use due to Next.js), AWS Glue (ETL), S3 (two buckets), IoT Core (gateway and rules), and Cognito (5 users). Use AWS CDK/SDK to code interactions (e.g., IoT Core rules to S3). Next.js reduces Lambda workload for the fullstack web app. 5. Timeline \u0026amp; Milestones Project Timeline\nPre-Internship (Month 0): 1 month for planning and old station review. Internship (Months 1-3): 3 months. Month 1: Study AWS and upgrade hardware. Month 2: Design and adjust architecture. Month 3: Implement, test, and launch. Post-Launch: Up to 1 year for research. 6. Budget Estimation You can find the budget estimation on the AWS Pricing Calculator.\nOr you can download the Budget Estimation File.\nInfrastructure Costs AWS Services: AWS Lambda: $0.00/month (1,000 requests, 512 MB storage). S3 Standard: $0.15/month (6 GB, 2,100 requests, 1 GB scanned). Data Transfer: $0.02/month (1 GB inbound, 1 GB outbound). AWS Amplify: $0.35/month (256 MB, 500 ms requests). Amazon API Gateway: $0.01/month (2,000 requests). AWS Glue ETL Jobs: $0.02/month (2 DPUs). AWS Glue Crawlers: $0.07/month (1 crawler). MQTT (IoT Core): $0.08/month (5 devices, 45,000 messages). Total: $0.7/month, $8.40/12 months\nHardware: $265 one-time (Raspberry Pi 5 and sensors). 7. Risk Assessment Risk Matrix Network Outages: Medium impact, medium probability. Sensor Failures: High impact, low probability. Cost Overruns: Medium impact, low probability. Mitigation Strategies Network: Local storage on Raspberry Pi with Docker. Sensors: Regular checks and spares. Cost: AWS budget alerts and optimization. Contingency Plans Revert to manual methods if AWS fails. Use CloudFormation for cost-related rollbacks. 8. Expected Outcomes Technical Improvements: Real-time data and analytics replace manual processes.\nScalable to 10-15 stations.\nLong-term Value 1-year data foundation for AI research.\nReusable for future projects.\n"
},
{
	"uri": "https://my-cloud-journey-e7994.web.app/5-workshop/5.3-s3-vpc/5.3.2-test-gwe/",
	"title": "Test the Gateway Endpoint",
	"tags": [],
	"description": "",
	"content": "Create S3 bucket Navigate to S3 management console In the Bucket console, choose Create bucket In the Create bucket console Name the bucket: choose a name that hasn\u0026rsquo;t been given to any bucket globally (hint: lab number and your name) Leave other fields as they are (default) Scroll down and choose Create bucket Successfully create S3 bucket. Connect to EC2 with session manager For this workshop, you will use AWS Session Manager to access several EC2 instances. Session Manager is a fully managed AWS Systems Manager capability that allows you to manage your Amazon EC2 instances and on-premises virtual machines (VMs) through an interactive one-click browser-based shell. Session Manager provides secure and auditable instance management without the need to open inbound ports, maintain bastion hosts, or manage SSH keys.\nFirst cloud journey Lab for indepth understanding of Session manager.\nIn the AWS Management Console, start typing Systems Manager in the quick search box and press Enter: From the Systems Manager menu, find Node Management in the left menu and click Session Manager: Click Start Session, and select the EC2 instance named Test-Gateway-Endpoint. This EC2 instance is already running in \u0026ldquo;VPC Cloud\u0026rdquo; and will be used to test connectivity to Amazon S3 through the Gateway endpoint you just created (s3-gwe).\nSession Manager will open a new browser tab with a shell prompt: sh-4.2 $\nYou have successfully start a session - connect to the EC2 instance in VPC cloud. In the next step, we will create a S3 bucket and a file in it.\nCreate a file and upload to s3 bucket Change to the ssm-user\u0026rsquo;s home directory by typing cd ~ in the CLI Create a new file to use for testing with the command fallocate -l 1G testfile.xyz, which will create a file of 1GB size named \u0026ldquo;testfile.xyz\u0026rdquo;. Upload file to S3 bucket with command aws s3 cp testfile.xyz s3://your-bucket-name. Replace your-bucket-name with the name of S3 bucket that you created earlier. You have successfully uploaded the file to your S3 bucket. You can now terminate the session.\nCheck object in S3 bucket Navigate to S3 console. Click the name of your s3 bucket In the Bucket console, you will see the file you have uploaded to your S3 bucket Section summary Congratulation on completing access to S3 from VPC. In this section, you created a Gateway endpoint for Amazon S3, and used the AWS CLI to upload an object. The upload worked because the Gateway endpoint allowed communication to S3, without needing an Internet Gateway attached to \u0026ldquo;VPC Cloud\u0026rdquo;. This demonstrates the functionality of the Gateway endpoint as a secure path to S3 without traversing the Public Internet.\n"
},
{
	"uri": "https://my-cloud-journey-e7994.web.app/4-eventparticipated/4.3-event3/",
	"title": "AI-Driven Development Session with Amazon Q Developer &amp; Kiro",
	"tags": [],
	"description": "",
	"content": "Event Objectives Understand how generative AI is transforming the software development lifecycle Learn how AI tools such as Amazon Q Developer and Kiro accelerate development workflows Explore how AI integrates into architecture, coding, testing, deployment, and maintenance Experience live demonstrations of AI-assisted development in real engineering scenarios Enhance productivity by automating undifferentiated heavy lifting tasks, enabling developers to focus on creativity and innovation Speakers Toan Huynh – Instructor, AWS GenAI Builder Club My Nguyen – Instructor, AWS GenAI Builder Club Coordinators Diem My – Program Coordinator Dai Truong – Event Coordinator Dinh Nguyen – Operations Coordinator Key Highlights Toan Huynh is a guy with a fire of inspiration, he instructs will whole of his heart and intellectual knowledge.\nMy Huynh was so helpful and answered each question from audiences very deeply and knowledgably.\nTransforming Software Development with Generative AI Generative AI marks a new era in software engineering, reshaping how developers learn, plan, create, deploy, and manage applications.\nThis session highlighted how AI-driven development enables:\nAutomation of repetitive engineering tasks Rapid prototyping and faster delivery cycles Improved code quality and security through AI-assisted reviews A shift toward higher-value, design-focused work for developers AI in the Software Development Lifecycle (AI-DLC) The session introduced how AI tools integrate across the entire SDLC:\nArchitecture planning Code generation and refactoring Test case creation and validation Deployment pipelines Maintenance and monitoring Through Amazon Q Developer and Kiro, participants gained clarity on how AI elevates developer capabilities.\nAgenda 2:00 PM – 2:15 PM | Welcoming \u0026amp; Introduction 2:15 PM – 3:30 PM | AI-Driven Development Lifecycle Overview \u0026amp; Amazon Q Developer Demonstration Instructor: Toan Huynh 3:30 PM – 3:45 PM | Break 3:45 PM – 4:30 PM | Kiro Demonstration Instructor: My Nguyen Key Takeaways Strategic Insights on AI-Driven Development AI accelerates software delivery by automating repetitive tasks Development teams can redirect effort into architectural design and problem-solving AI tools reduce time spent on debugging, refactoring, and documentation Organizations adopting AI-enhanced development gain measurable productivity improvements Practical Learnings – Amazon Q Developer Generating high-quality code from natural language prompts Automatically fixing errors and optimizing functions Writing unit tests and documentation with AI Enhancing DevOps workflows through AI-assisted CI/CD automation Practical Learnings – Kiro Using Kiro’s AI capabilities for system design and development Real-time suggestions for architecture, code structure, and best practices Improved code readability, maintainability, and consistency across teams Applying to Work Adopt AI tools to streamline daily development tasks Use Amazon Q Developer to prototype ideas rapidly and improve code quality Integrate Kiro into architecture design and planning processes Encourage teams to experiment with AI to enhance efficiency and reduce repetitive workload Begin exploring an AI-augmented SDLC to modernize engineering practices Event Experience Attending this AI-Driven Development session was a refreshing and inspiring experience. It showcased how generative AI is reshaping the developer workflow and unlocking new levels of productivity.\nLearning from Experts Gained deep insights from Toan Huynh and My Nguyen on practical AI adoption Understood how AI fits not only in coding, but across architecture and DevOps pipelines Hands-On AI Demonstrations Observed live flows where Amazon Q Developer refactored code, generated documentation, and produced tests instantly Experienced how Kiro assists with system planning and engineering decisions Collaboration \u0026amp; Networking Connected with members of the AWS GenAI Builder Club, sharing ideas about AI development Discussed use cases and opportunities for integrating AI into daily engineering tasks Key Lessons Learned AI-driven development dramatically boosts speed, accuracy, and productivity Developers should evolve from code writers to system designers and solution thinkers Embracing AI early provides competitive advantages in modern engineering teams Speaker - Toan Huynh\nSpeaker - My Nguyen\nOverall, the session reinforced a powerful message: AI will not replace developers, but developers who use AI will outperform those who don’t.\n"
},
{
	"uri": "https://my-cloud-journey-e7994.web.app/3-blogstranslated/3.3-blog3/",
	"title": "Accelerate AI agent development with the Nova Act IDE extension",
	"tags": [],
	"description": "",
	"content": "Getting Started with Healthcare Data Lakes: Using Microservices Data lakes can help hospitals and healthcare facilities turn data into business insights, maintain business continuity, and protect patient privacy. A data lake is a centralized, managed, and secure repository to store all your data, both in its raw and processed forms for analysis. Data lakes allow you to break down data silos and combine different types of analytics to gain insights and make better business decisions.\nThis blog post is part of a larger series on getting started with setting up a healthcare data lake. In my final post of the series, “Getting Started with Healthcare Data Lakes: Diving into Amazon Cognito”, I focused on the specifics of using Amazon Cognito and Attribute Based Access Control (ABAC) to authenticate and authorize users in the healthcare data lake solution. In this blog, I detail how the solution evolved at a foundational level, including the design decisions I made and the additional features used. You can access the code samples for the solution in this Git repo for reference.\nArchitecture Guidance The main change since the last presentation of the overall architecture is the decomposition of a single service into a set of smaller services to improve maintainability and flexibility. Integrating a large volume of diverse healthcare data often requires specialized connectors for each format; by keeping them encapsulated separately as microservices, we can add, remove, and modify each connector without affecting the others. The microservices are loosely coupled via publish/subscribe messaging centered in what I call the “pub/sub hub.”\nThis solution represents what I would consider another reasonable sprint iteration from my last post. The scope is still limited to the ingestion and basic parsing of HL7v2 messages formatted in Encoding Rules 7 (ER7) through a REST interface.\nThe solution architecture is now as follows:\nFigure 1. Overall architecture; colored boxes represent distinct services.\nWhile the term microservices has some inherent ambiguity, certain traits are common:\nSmall, autonomous, loosely coupled Reusable, communicating through well-defined interfaces Specialized to do one thing well Often implemented in an event-driven architecture When determining where to draw boundaries between microservices, consider:\nIntrinsic: technology used, performance, reliability, scalability Extrinsic: dependent functionality, rate of change, reusability Human: team ownership, managing cognitive load Technology Choices and Communication Scope Communication scope Technologies / patterns to consider Within a single microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Between microservices in a single service AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Between services Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The Pub/Sub Hub Using a hub-and-spoke architecture (or message broker) works well with a small number of tightly related microservices.\nEach microservice depends only on the hub Inter-microservice connections are limited to the contents of the published message Reduces the number of synchronous calls since pub/sub is a one-way asynchronous push Drawback: coordination and monitoring are needed to avoid microservices processing the wrong message.\nCore Microservice Provides foundational data and communication layer, including:\nAmazon S3 bucket for data Amazon DynamoDB for data catalog AWS Lambda to write messages into the data lake and catalog Amazon SNS topic as the hub Amazon S3 bucket for artifacts such as Lambda code Only allow indirect write access to the data lake through a Lambda function → ensures consistency.\nFront Door Microservice Provides an API Gateway for external REST interaction Authentication \u0026amp; authorization based on OIDC via Amazon Cognito Self-managed deduplication mechanism using DynamoDB instead of SNS FIFO because: SNS deduplication TTL is only 5 minutes SNS FIFO requires SQS FIFO Ability to proactively notify the sender that the message is a duplicate Staging ER7 Microservice Lambda “trigger” subscribed to the pub/sub hub, filtering messages by attribute Step Functions Express Workflow to convert ER7 → JSON Two Lambdas: Fix ER7 formatting (newline, carriage return) Parsing logic Result or error is pushed back into the pub/sub hub New Features in the Solution 1. AWS CloudFormation Cross-Stack References Example outputs in the core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "
},
{
	"uri": "https://my-cloud-journey-e7994.web.app/5-workshop/5.3-s3-vpc/",
	"title": "Access S3 from VPC",
	"tags": [],
	"description": "",
	"content": "Using Gateway endpoint In this section, you will create a Gateway eendpoint to access Amazon S3 from an EC2 instance. The Gateway endpoint will allow upload an object to S3 buckets without using the Public Internet. To create an endpoint, you must specify the VPC in which you want to create the endpoint, and the service (in this case, S3) to which you want to establish the connection.\nContent Create gateway endpoint Test gateway endpoint "
},
{
	"uri": "https://my-cloud-journey-e7994.web.app/5-workshop/5.4-s3-onprem/5.4.3-test-endpoint/",
	"title": "Test the Interface Endpoint",
	"tags": [],
	"description": "",
	"content": "Get the regional DNS name of S3 interface endpoint From the Amazon VPC menu, choose Endpoints.\nClick the name of newly created endpoint: s3-interface-endpoint. Click details and save the regional DNS name of the endpoint (the first one) to your text-editor for later use.\nConnect to EC2 instance in \u0026ldquo;VPC On-prem\u0026rdquo; Navigate to Session manager by typing \u0026ldquo;session manager\u0026rdquo; in the search box\nClick Start Session, and select the EC2 instance named Test-Interface-Endpoint. This EC2 instance is running in \u0026ldquo;VPC On-prem\u0026rdquo; and will be used to test connectivty to Amazon S3 through the Interface endpoint we just created. Session Manager will open a new browser tab with a shell prompt: sh-4.2 $\nChange to the ssm-user\u0026rsquo;s home directory with command \u0026ldquo;cd ~\u0026rdquo;\nCreate a file named testfile2.xyz\nfallocate -l 1G testfile2.xyz Copy file to the same S3 bucket we created in section 3.2 aws s3 cp --endpoint-url https://bucket.\u0026lt;Regional-DNS-Name\u0026gt; testfile2.xyz s3://\u0026lt;your-bucket-name\u0026gt; This command requires the \u0026ndash;endpoint-url parameter, because you need to use the endpoint-specific DNS name to access S3 using an Interface endpoint. Do not include the leading \u0026rsquo; * \u0026rsquo; when copying/pasting the regional DNS name. Provide your S3 bucket name created earlier Now the file has been added to your S3 bucket. Let check your S3 bucket in the next step.\nCheck Object in S3 bucket Navigate to S3 console Click Buckets Click the name of your bucket and you will see testfile2.xyz has been added to your bucket "
},
{
	"uri": "https://my-cloud-journey-e7994.web.app/3-blogstranslated/",
	"title": "Translated Blogs",
	"tags": [],
	"description": "",
	"content": "Blog 1 - New Courses and Certification Updates from AWS Training and Certification – September 2025 The September 2025 AWS Training \u0026amp; Certification update introduces new ways to learn cloud skills, including the AWS Card Clash mobile app, a Skills Profile to showcase credentials, new digital training courses, an advanced Bedrock autonomous-agents lab, updated learning plans for key roles, and the newly opened registration and prep materials for the AWS Certified CloudOps Engineer – Associate exam.\nBlog 2 - Minimize risk through defense in depth: Building a comprehensive AWS control framework The blog explains how organizations can strengthen their AWS security posture by using a defense-in-depth approach that layers preventative, proactive, detective, and responsive controls. It highlights common challenges security teams face, shows how AWS services like Control Tower, Organizations, Config, and Security Hub can form a comprehensive control framework, and uses S3 public-access prevention as an example of how multi-layered controls work together to reduce risk and improve operational consistency.\nBlog 3 - Accelerate AI agent development with the Nova Act IDE extension The post introduces Nova Act’s new IDE extension — a tool that lets developers build, test, and debug browser-automation AI agents directly inside popular editors (like VS Code, Kiro, Cursor), without switching between tools. With this extension you can describe workflows in natural language, auto-generate a working agent script, refine it via a notebook-style builder, and run live browser tests — which greatly speeds up creation of multi-step automation tasks (e.g. form filling, QA automation, web workflows).\n"
},
{
	"uri": "https://my-cloud-journey-e7994.web.app/4-eventparticipated/4.4-event4/",
	"title": "CMC Global TechTalk Series – Cloud &amp; Digital Transformation",
	"tags": [],
	"description": "",
	"content": "Event Objectives Explore leading technologies applied across CMC Global’s digital transformation ecosystem Learn practical Cloud Engineering and Architecture insights from experienced industry professionals Understand real-world implementation of cloud migration, modernization, and enterprise solutions Provide students and developers with direct exposure to modern cloud practices and engineering workflows Strengthen community connection between CMC Global experts and future cloud builders Speakers Lê Thanh Đức – Cloud Delivery Manager, CMC Global Dư Quốc Thành – Technical Leader, CMC Global Văn Hoàng Kha – Cloud Engineer, AWS Community Builder Key Highlights Leading Technology Insights from CMC Global The TechTalk Series introduced participants to some of the most impactful technologies used in CMC Global’s comprehensive digital transformation solutions, covering:\nCloud-native deployment strategies Enterprise-level system modernization Cloud migration best practices Infrastructure automation and operational excellence Real-world case studies delivered to large-scale customers Each speaker shared unique perspectives based on years of hands-on experience in cloud delivery, technical leadership, and AWS community building.\nExpertise and Guidance from Industry Leaders Anh Lê Thanh Đức provided insights into cloud delivery management, customer engagement, and scaling cloud teams. Anh Dư Quốc Thành shared deep technical knowledge on solution design and solving enterprise engineering challenges. Anh Văn Hoàng Kha, as an AWS Community Builder, inspired attendees with cloud best practices and the mindset required to thrive in cloud engineering. Key Takeaways Many questions were given at the end of the meeting, which makes everyone very excited. At the time, I asked Mr. Duc for \u0026ldquo;How did he start his carear as a DevOps Engineer\u0026rdquo; and now I can know more how to be a DevOps Engineer.\nStrategic Insights on Cloud \u0026amp; Modernization Cloud transformation succeeds through strong architecture, planning, and team collaboration Organizations rely heavily on automation to ensure reliability, scalability, and operational efficiency Cloud governance, cost optimization, and security must be integrated from day one Becoming a cloud engineer requires continuous learning, hands-on experimentation, and community involvement Practical Learnings from the TechTalk Understanding how large enterprises structure cloud migration projects How CMC Global applies cloud-native patterns to deliver end-to-end digital solutions The importance of Infrastructure as Code (IaC), monitoring, and DevOps pipelines Real examples of solving performance bottlenecks and reliability issues in production systems Applying to Work Start with cloud fundamentals while practicing through real projects and hands-on labs Apply cloud-native principles such as microservices, serverless, and automation Use IaC tools like Terraform or AWS CDK to manage scalable infrastructure Develop skills in observability, cost control, and secure-by-design architectures Engage with cloud communities such as AWS User Groups and AWS Community Builder programs Event Experience Attending this CMC Global TechTalk Series was an inspiring experience, offering a clearer understanding of how cloud technologies are applied in real enterprises and how engineers solve complex problems in digital transformation projects.\nLearning from Industry Professionals Gained valuable knowledge from cloud managers, technical leaders, and AWS community builders Appreciated the transparency in sharing real challenges and lessons from actual customer projects Understood the mindset required to grow as a cloud engineer in modern tech environments Hands-On Perspectives Learned practical examples of cloud deployment, automation, and system modernization Understood how teams at CMC Global collaborate to deliver high-quality cloud solutions Collaboration \u0026amp; Networking Engaged with speakers and fellow participants to discuss cloud career paths Learned about opportunities within CMC Global’s engineering and delivery teams Key Lessons Learned Cloud engineering is a continuous journey of learning and experimentation Modern enterprises rely on scalable, secure, and automated infrastructure Community involvement accelerates growth and creates opportunities Event Banner\nOverall, the session provided valuable insights into enterprise cloud engineering, modern system design, and the importance of continuous learning in the digital transformation era.\n"
},
{
	"uri": "https://my-cloud-journey-e7994.web.app/5-workshop/5.4-s3-onprem/",
	"title": "Access S3 from on-premises",
	"tags": [],
	"description": "",
	"content": "Overview In this section, you will create an Interface endpoint to access Amazon S3 from a simulated on-premises environment. The Interface endpoint will allow you to route to Amazon S3 over a VPN connection from your simulated on-premises environment.\nWhy using Interface endpoint:\nGateway endpoints only work with resources running in the VPC where they are created. Interface endpoints work with resources running in VPC, and also resources running in on-premises environments. Connectivty from your on-premises environment to the cloud can be provided by AWS Site-to-Site VPN or AWS Direct Connect. Interface endpoints allow you to connect to services powered by AWS PrivateLink. These services include some AWS services, services hosted by other AWS customers and partners in their own VPCs (referred to as PrivateLink Endpoint Services), and supported AWS Marketplace Partner services. For this workshop, we will focus on connecting to Amazon S3. "
},
{
	"uri": "https://my-cloud-journey-e7994.web.app/4-eventparticipated/",
	"title": "Events Participated",
	"tags": [],
	"description": "",
	"content": "I have been an active organizer or an event maker at my uni for recent time. But AWS in HCMC makes me so impressed due to its professional and meaningful activities. The events given below are just some of them that I have hands on with. Watch more here:\nEvent 1 Event Name: Kick-off AWS FCJ Workforce - FPTU OJT FALL 2025\nDate \u0026amp; Time: 8:30 - 12:00, September 6, 2025\nLocation: 26th Floor, Bitexco Tower, 02 Hai Trieu Street, Saigon Ward, Ho Chi Minh City\nRole: Attendee\nEvent 2 Event Name: Cloud Day AWS 2025 in HCMC\nDate \u0026amp; Time: September 18, 2025\nLocation: 26th-36th Floor, Bitexco Tower, 02 Hai Trieu Street, Saigon Ward, Ho Chi Minh City\nRole: Attendee\nEvent 3 Event Name: AI-Driven Development Life Cycle: Reimagining Software Engineering.\nDate \u0026amp; Time: October 3, 2025\nLocation: 26th Floor, Bitexco Tower, 02 Hai Trieu Street, Saigon Ward, Ho Chi Minh City\nRole: Attendee\nEvent 4 Event Name: Reinventing DevSecOps with AWS Generative AI.\nDate \u0026amp; Time: October 16, 2025\nLocation: Online Meeting\nRole: Attendee\nEvent 5 Event Name: AWS Cloud Mastery Series #1: AI/ML/GenAI on AWS\nDate \u0026amp; Time: November 15, 2025\nLocation: AWS Vietnam Office\nRole: Attendee\nEvent 6 Event Name: AWS Cloud Mastery Series #2: DevOps on AWS\nDate \u0026amp; Time: November 17, 2025\nLocation: AWS Vietnam Office\nRole: Attendee\nEvent 7 Event Name: CloundFront as Your Foundation And AWS WAF \u0026amp; Application Protection\nDate \u0026amp; Time: November 19, 2025\nLocation: AWS Vietnam Office\nRole: Attendee\nEvent 8 Event Name: Game Day - Secret Agent(ic) Unicorns\nDate \u0026amp; Time: 2pm, November 21, 2025\nLocation: 26th Floor, AWS Vietnam Office\nRole: Attendee\nEvent 9 Event Name: AWS Cloud Mastery Series #3: AWS Well-Architected Security Pillar\nDate \u0026amp; Time: 8:30 - 12:00, November 29, 2025\nLocation: 26th Floor, AWS Vietnam Office\nRole: Attendee\n"
},
{
	"uri": "https://my-cloud-journey-e7994.web.app/5-workshop/5.4-s3-onprem/5.4.4-dns-simulation/",
	"title": "On-premises DNS Simulation",
	"tags": [],
	"description": "",
	"content": "AWS PrivateLink endpoints have a fixed IP address in each Availability Zone where they are deployed, for the life of the endpoint (until it is deleted). These IP addresses are attached to Elastic Network Interfaces (ENIs). AWS recommends using DNS to resolve the IP addresses for endpoints so that downstream applications use the latest IP addresses when ENIs are added to new AZs, or deleted over time.\nIn this section, you will create a forwarding rule to send DNS resolution requests from a simulated on-premises environment to a Route 53 Private Hosted Zone. This section leverages the infrastructure deployed by CloudFormation in the Prepare the environment section.\nCreate DNS Alias Records for the Interface endpoint Navigate to the Route 53 management console (Hosted Zones section). The CloudFormation template you deployed in the Prepare the environment section created this Private Hosted Zone. Click on the name of the Private Hosted Zone, s3.us-east-1.amazonaws.com: Create a new record in the Private Hosted Zone: Record name and record type keep default options Alias Button: Click to enable Route traffic to: Alias to VPC Endpoint Region: US East (N. Virginia) [us-east-1] Choose endpoint: Paste the Regional VPC Endpoint DNS name from your text editor (you saved when doing section 4.3) Click Add another record, and add a second record using the following values. Click Create records when finished to create both records. Record name: *. Record type: keep default value (type A) Alias Button: Click to enable Route traffic to: Alias to VPC Endpoint Region: US East (N. Virginia) [us-east-1] Choose endpoint: Paste the Regional VPC Endpoint DNS name from your text editor The new records appear in the Route 53 console:\nCreate a Resolver Forwarding Rule Route 53 Resolver Forwarding Rules allow you to forward DNS queries from your VPC to other sources for name resolution. Outside of a workshop environment, you might use this feature to forward DNS queries from your VPC to DNS servers running on-premises. In this section, you will simulate an on-premises conditional forwarder by creating a forwarding rule that forwards DNS queries for Amazon S3 to a Private Hosted Zone running in \u0026ldquo;VPC Cloud\u0026rdquo; in-order to resolve the PrivateLink interface endpoint regional DNS name.\nFrom the Route 53 management console, click Inbound endpoints on the left side bar In the Inbound endpoints console, click the ID of the inbound endpoint Copy the two IP addresses listed to your text editor From the Route 53 menu, choose Resolver \u0026gt; Rules, and click Create rule: In the Create rule console: Name: myS3Rule Rule type: Forward Domain name: s3.us-east-1.amazonaws.com VPC: VPC On-prem Outbound endpoint: VPCOnpremOutboundEndpoint Target IP Addresses: Enter both IP addresses from your text editor (inbound endpoint addresses) and then click Submit You have successfully created resolver forwarding rule.\nTest the on-premises DNS Simulation Connect to Test-Interface-Endpoint EC2 instance with Session manager Test DNS resolution. The dig command will return the IP addresses assigned to the VPC Interface endpoint running in VPC Cloud (your IP\u0026rsquo;s will be different): dig +short s3.us-east-1.amazonaws.com The IP addresses returned are the VPC endpoint IP addresses, NOT the Resolver IP addresses you pasted from your text editor. The IP addresses of the Resolver endpoint and the VPC endpoint look similar because they are all from the VPC Cloud CIDR block.\nNavigate to the VPC menu (Endpoints section), select the S3 Interface endpoint. Click the Subnets tab and verify that the IP addresses returned by Dig match the VPC endpoint: Return to your shell and use the AWS CLI to test listing your S3 buckets: aws s3 ls --endpoint-url https://s3.us-east-1.amazonaws.com Terminate your Session Manager session: In this section you created an Interface endpoint for Amazon S3. This endpoint can be reached from on-premises through Site-to-Site VPN or AWS Direct Connect. Route 53 Resolver outbound endpoints simulated forwarding DNS requests from on-premises to a Private Hosted Zone running the cloud. Route 53 inbound Endpoints recieved the resolution request and returned a response containing the IP addresses of the VPC interface endpoint. Using DNS to resolve the endpoint IP addresses provides high availability in-case of an Availability Zone outage.\n"
},
{
	"uri": "https://my-cloud-journey-e7994.web.app/4-eventparticipated/4.5-event5/",
	"title": "AWS Cloud Mastery Series #1: AI/ML/GenAI on AWS",
	"tags": [],
	"description": "",
	"content": "Event Objectives Introduce participants to the fundamentals and practical applications of AWS AI/ML services Provide hands-on understanding of Amazon SageMaker for end-to-end machine learning workflows Explore the capabilities of Amazon Bedrock for building and deploying Generative AI applications Strengthen participants’ knowledge of prompt engineering, RAG architecture, and model selection Enable developers to understand industry-standard MLOps practices using AWS tools Create an opportunity for networking and collaboration among AI/ML enthusiasts Speakers AWS Vietnam AI/ML Specialist Team Guest Facilitators from AWS Training \u0026amp; Certification Key Highlights Understanding the AI/ML Landscape The workshop opened with an overview of the rapidly evolving AI and ML ecosystem in Vietnam, highlighting the increasing adoption of cloud-based AI platforms, enterprise demand for ML solutions, and the role of foundational models in modern applications.\nParticipants gained clarity on:\nThe accelerating growth of AI talent and industry needs Real-world use cases across finance, e-commerce, and digital transformation The importance of cloud platforms in scaling ML workloads Hands-On Deep Dive into AWS AI Services The workshop delivered a detailed walkthrough of the tools, frameworks, and best practices that AWS provides to accelerate ML development—from data preparation to deployment and monitoring.\nAgenda 8:30 AM – 9:00 AM | Welcome \u0026amp; Introduction\nParticipant registration and networking Workshop overview and learning objectives Ice-breaker activity Overview of Vietnam’s AI/ML landscape 9:00 AM – 10:30 AM | AWS AI/ML Services Overview\nAmazon SageMaker: End-to-end ML platform Data preparation and labeling workflows Model training, tuning, and deployment Integrated MLOps capabilities Live Demo: SageMaker Studio walkthrough 10:30 AM – 10:45 AM | Coffee Break\n10:45 AM – 12:00 PM | Generative AI with Amazon Bedrock\nFoundation Models: Claude, Llama, Titan – comparison \u0026amp; selection guide Prompt engineering: Chain-of-thought, few-shot prompting Retrieval-Augmented Generation (RAG) architecture \u0026amp; knowledge base design Bedrock Agents for multi-step workflows and tool integrations Guardrails configuration for safe and controlled AI output Live Demo: Building a Generative AI chatbot using Bedrock 12:00 PM | Lunch Break (Self-arranged)\nKey Takeaways Strategic Insights into AI/ML on AWS End-to-end ML pipelines become significantly faster with managed services like SageMaker Model deployment and monitoring require strong MLOps foundations to ensure reliability Choosing the right foundation model depends on accuracy, latency, and domain constraints Generative AI workloads demand strong governance and safety controls Practical Learnings from SageMaker Efficient data preparation through integrated labeling and processing tools Automated model optimization through hyperparameter tuning jobs Streamlined deployment with real-time endpoints and model monitoring The importance of versioning, lineage tracking, and reproducibility Practical Learnings from Bedrock How to apply prompt engineering patterns for optimal responses Understanding when to use Claude, Llama, or Titan based on workload Implementing Retrieval-Augmented Generation (RAG) to enhance model accuracy Using Bedrock Agents to orchestrate multi-step reasoning tasks Enforcing safety standards through Guardrails and output filtering Applying to Work Start experimenting with SageMaker Studio notebooks for ML model development Use Bedrock to rapidly prototype chatbots, assistants, and domain-specific AI tools Integrate RAG pipelines where accuracy and up-to-date information are critical Adopt MLOps best practices to improve reliability and scalability Continue developing AI/ML skills through workshops, labs, and AWS certifications Event Experience Attending this workshop at the AWS Vietnam Office was a highly inspiring experience. It provided a practical, hands-on view of how machine learning and generative AI systems are built and deployed at scale.\nLearning from AWS Experts Gained clear guidance on how SageMaker simplifies the ML lifecycle Learned how enterprises use Bedrock to accelerate GenAI adoption Understood how global best practices can be applied to real projects in Vietnam Hands-On Demonstrations Saw real examples of training and deploying ML models Experienced how Bedrock can build a functional chatbot in minutes Understood how RAG boosts model accuracy and practical usefulness Collaboration \u0026amp; Networking Connected with other developers, students, and cloud practitioners Exchanged insights on AI career paths and AWS learning opportunities Expanded my network within the AI/ML and cloud community in HCMC Key Lessons Learned ML and GenAI are most powerful when combined with strong engineering principles Productivity dramatically increases with managed AI services and automation Continuous experimentation is essential to mastering modern AI workloads Speaker - Presenter\nSpeaker - Hoang Anh\nSpeaker - Hieu Nghi\nOverall, the workshop provided deep insights into building real-world ML and GenAI applications, empowering participants with the knowledge and confidence to apply AWS AI services effectively in future projects.\n"
},
{
	"uri": "https://my-cloud-journey-e7994.web.app/5-workshop/5.5-policy/",
	"title": "VPC Endpoint Policies",
	"tags": [],
	"description": "",
	"content": "When you create an interface or gateway endpoint, you can attach an endpoint policy to it that controls access to the service to which you are connecting. A VPC endpoint policy is an IAM resource policy that you attach to an endpoint. If you do not attach a policy when you create an endpoint, AWS attaches a default policy for you that allows full access to the service through the endpoint.\nYou can create a policy that restricts access to specific S3 buckets only. This is useful if you only want certain S3 Buckets to be accessible through the endpoint.\nIn this section you will create a VPC endpoint policy that restricts access to the S3 bucket specified in the VPC endpoint policy.\nConnect to an EC2 instance and verify connectivity to S3 Start a new AWS Session Manager session on the instance named Test-Gateway-Endpoint. From the session, verify that you can list the contents of the bucket you created in Part 1: Access S3 from VPC: aws s3 ls s3://\\\u0026lt;your-bucket-name\\\u0026gt; The bucket contents include the two 1 GB files uploaded in earlier.\nCreate a new S3 bucket; follow the naming pattern you used in Part 1, but add a \u0026lsquo;-2\u0026rsquo; to the name. Leave other fields as default and click create Successfully create bucket\nNavigate to: Services \u0026gt; VPC \u0026gt; Endpoints, then select the Gateway VPC endpoint you created earlier. Click the Policy tab. Click Edit policy. The default policy allows access to all S3 Buckets through the VPC endpoint.\nIn Edit Policy console, copy \u0026amp; Paste the following policy, then replace yourbucketname-2 with your 2nd bucket name. This policy will allow access through the VPC endpoint to your new bucket, but not any other bucket in Amazon S3. Click Save to apply the policy. {\r\u0026#34;Id\u0026#34;: \u0026#34;Policy1631305502445\u0026#34;,\r\u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;,\r\u0026#34;Statement\u0026#34;: [\r{\r\u0026#34;Sid\u0026#34;: \u0026#34;Stmt1631305501021\u0026#34;,\r\u0026#34;Action\u0026#34;: \u0026#34;s3:*\u0026#34;,\r\u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;,\r\u0026#34;Resource\u0026#34;: [\r\u0026#34;arn:aws:s3:::yourbucketname-2\u0026#34;,\r\u0026#34;arn:aws:s3:::yourbucketname-2/*\u0026#34;\r],\r\u0026#34;Principal\u0026#34;: \u0026#34;*\u0026#34;\r}\r]\r} Successfully customize policy\nFrom your session on the Test-Gateway-Endpoint instance, test access to the S3 bucket you created in Part 1: Access S3 from VPC aws s3 ls s3://\u0026lt;yourbucketname\u0026gt; This command will return an error because access to this bucket is not permitted by your new VPC endpoint policy:\nReturn to your home directory on your EC2 instance cd~ Create a file fallocate -l 1G test-bucket2.xyz Copy file to 2nd bucket aws s3 cp test-bucket2.xyz s3://\u0026lt;your-2nd-bucket-name\u0026gt; This operation succeeds because it is permitted by the VPC endpoint policy.\nThen we test access to the first bucket by copy the file to 1st bucket aws s3 cp test-bucket2.xyz s3://\u0026lt;your-1st-bucket-name\u0026gt; This command will return an error because access to this bucket is not permitted by your new VPC endpoint policy.\nPart 3 Summary: In this section, you created a VPC endpoint policy for Amazon S3, and used the AWS CLI to test the policy. AWS CLI actions targeted to your original S3 bucket failed because you applied a policy that only allowed access to the second bucket you created. AWS CLI actions targeted for your second bucket succeeded because the policy allowed them. These policies can be useful in situations where you need to control access to resources through VPC endpoints.\n"
},
{
	"uri": "https://my-cloud-journey-e7994.web.app/5-workshop/",
	"title": "Workshop",
	"tags": [],
	"description": "",
	"content": "Secure Hybrid Access to S3 using VPC Endpoints Overview AWS PrivateLink provides private connectivity to AWS services from VPCs and your on-premises networks, without exposing your traffic to the Public Internet.\nIn this lab, you will learn how to create, configure, and test VPC endpoints that enable your workloads to reach AWS services without traversing the Public Internet.\nYou will create two types of endpoints to access Amazon S3: a Gateway VPC endpoint, and an Interface VPC endpoint. These two types of VPC endpoints offer different benefits depending on if you are accessing Amazon S3 from the cloud or your on-premises location\nGateway - Create a gateway endpoint to send traffic to Amazon S3 or DynamoDB using private IP addresses.You route traffic from your VPC to the gateway endpoint using route tables. Interface - Create an interface endpoint to send traffic to endpoint services that use a Network Load Balancer to distribute traffic. Traffic destined for the endpoint service is resolved using DNS. Content Workshop overview Prerequiste Access S3 from VPC Access S3 from On-premises VPC Endpoint Policies (Bonus) Clean up "
},
{
	"uri": "https://my-cloud-journey-e7994.web.app/4-eventparticipated/4.6-event6/",
	"title": "AWS Cloud Mastery Series #2: DevOps on AWS",
	"tags": [],
	"description": "",
	"content": "Event Objectives Introduce participants to modern DevOps principles and culture Provide practical knowledge of AWS DevOps tools across CI/CD, infrastructure, and operations Demonstrate how DevOps accelerates delivery through automation, observability, and continuous improvement Equip developers with hands-on insights into containerization, monitoring, and deployment strategies Strengthen understanding of reliability, scalability, and operational excellence on AWS Support participants in exploring DevOps career development and AWS certification pathways Speakers AWS Vietnam DevOps Specialist Team Guest Trainers from AWS Training \u0026amp; Certification Key Highlights Embracing the DevOps Mindset The workshop began with a discussion about the evolving shift toward a DevOps-centric culture. Participants were introduced to:\nThe principles of DevOps collaboration Key performance metrics (DORA metrics: Deployment Frequency, MTTR, Change Failure Rate) The importance of automation and continuous improvement How DevOps complements AI/ML workflows from previous sessions This session emphasized how a strong DevOps culture leads to faster delivery, higher reliability, and stronger engineering ownership.\nA Deep Dive into AWS DevOps Tooling Throughout the full-day workshop, participants explored AWS-native tools for CI/CD, Infrastructure as Code, container orchestration, and observability—gaining a solid understanding of how modern engineering teams build and deliver applications at scale.\nAgenda Morning Session (8:30 AM – 12:00 PM) 8:30 – 9:00 AM | Welcome \u0026amp; DevOps Mindset\nRecap of the previous AI/ML session DevOps culture and principles Benefits and key metrics (DORA, MTTR, deployment frequency) 9:00 – 10:30 AM | AWS DevOps Services – CI/CD Pipeline\nSource Control: AWS CodeCommit, GitFlow, Trunk-based development Build \u0026amp; Test: CodeBuild configuration, automated testing Deployment: CodeDeploy with Blue/Green, Canary, Rolling updates Orchestration: CodePipeline automation and workflow design Demo: Full CI/CD pipeline walkthrough 10:30 – 10:45 AM | Break\n10:45 AM – 12:00 PM | Infrastructure as Code (IaC)\nAWS CloudFormation: Templates, stacks, drift detection AWS CDK: Constructs, reusable patterns, multi-language support Demo: Deploying infrastructure using CloudFormation and CDK Discussion: How to choose between IaC tools 12:00 – 1:00 PM | Lunch Break (Self-arranged)\nAfternoon Session (1:00 PM – 5:00 PM) 1:00 – 2:30 PM | Container Services on AWS\nDocker fundamentals: Microservices and containerization Amazon ECR: Image storage, scanning, lifecycle policies Amazon ECS \u0026amp; EKS: Deployment strategies, scaling, orchestration AWS App Runner: Simplified container deployment Demo \u0026amp; Case Study: Microservices deployment comparison 2:30 – 2:45 PM | Break\n2:45 – 4:00 PM | Monitoring \u0026amp; Observability\nCloudWatch: Metrics, logs, alarms, dashboards AWS X-Ray: Distributed tracing \u0026amp; performance insights Demo: Full-stack observability setup Best practices: Alerting, dashboards, on-call processes 4:00 – 4:45 PM | DevOps Best Practices \u0026amp; Case Studies\nDeployment patterns: Feature flags, A/B testing Automated testing \u0026amp; CI/CD integration Incident management and postmortems Case studies from startups \u0026amp; large enterprises 4:45 – 5:00 PM | Q\u0026amp;A \u0026amp; Wrap-up\nDevOps career pathways AWS certification roadmap Key Takeaways Strategic Insights into DevOps on AWS DevOps accelerates delivery and enhances team collaboration through automation CI/CD pipelines reduce deployment risks and increase release frequency IaC ensures reliable, repeatable, and scalable infrastructure provisioning Containers and orchestration platforms standardize deployment environments Observability is essential for maintaining high availability and performance Practical Learnings from CI/CD AWS CodeCommit, CodeBuild, CodeDeploy, and CodePipeline work together to form fully automated pipelines Deployment strategies like Canary and Blue/Green reduce downtime and risk Git strategies such as Trunk-based development improve delivery speed Practical Learnings from IaC CloudFormation provides controlled, declarative infrastructure management CDK enables flexible, code-driven infrastructure modeling Understanding how to combine both tools effectively is key for enterprise adoption Practical Learnings from Containers \u0026amp; Observability ECS and EKS offer powerful orchestration for microservice workloads App Runner simplifies deployment for containerized applications CloudWatch + X-Ray provides unified observability across the stack Applying to Work Build CI/CD pipelines to automate code builds, testing, and deployments Use IaC tools to maintain consistent infrastructure environments Adopt containers for scalable and portable application delivery Implement observability practices to improve reliability and reduce MTTR Continue learning DevOps tools and pursue AWS certifications Event Experience This DevOps on AWS workshop provided a comprehensive and practical view of modern DevOps workflows, giving participants a strong foundation for real-world engineering challenges.\nLearning from AWS DevOps Experts Gained valuable insights into AWS-native DevOps tooling Learned how enterprise DevOps transformations are executed Understood the real role of automation and observability in production environments Hands-On Demonstrations Observed a full CI/CD pipeline in action Saw how IaC simplifies provisioning and maintenance Compared multiple container deployment strategies Built monitoring dashboards and explored distributed tracing Collaboration \u0026amp; Networking Met engineers and developers passionate about DevOps Shared career insights, resources, and certification plans Expanded professional connections within the AWS DevOps community Key Lessons Learned DevOps is a combination of culture, tools, and operational discipline Automation is the path to speed, reliability, and efficiency Observability must be built in from the start—not added later Continuous learning is essential in fast-evolving DevOps environments Overall, this session strengthened my understanding of DevOps foundations, AWS tooling, and best practices—providing me with the confidence to design, automate, and operate modern cloud-native systems.\n"
},
{
	"uri": "https://my-cloud-journey-e7994.web.app/5-workshop/5.6-cleanup/",
	"title": "Clean up",
	"tags": [],
	"description": "",
	"content": "Congratulations on completing this workshop! In this workshop, you learned architecture patterns for accessing Amazon S3 without using the Public Internet.\nBy creating a gateway endpoint, you enabled direct communication between EC2 resources and Amazon S3, without traversing an Internet Gateway. By creating an interface endpoint you extended S3 connectivity to resources running in your on-premises data center via AWS Site-to-Site VPN or Direct Connect. clean up Navigate to Hosted Zones on the left side of Route 53 console. Click the name of s3.us-east-1.amazonaws.com zone. Click Delete and confirm deletion by typing delete. Disassociate the Route 53 Resolver Rule - myS3Rule from \u0026ldquo;VPC Onprem\u0026rdquo; and Delete it. Open the CloudFormation console and delete the two CloudFormation Stacks that you created for this lab: PLOnpremSetup PLCloudSetup Delete S3 buckets Open S3 console Choose the bucket we created for the lab, click and confirm empty. Click delete and confirm delete. "
},
{
	"uri": "https://my-cloud-journey-e7994.web.app/6-self-evaluation/",
	"title": "Self-Assessment",
	"tags": [],
	"description": "",
	"content": "During my internship at AWS FCJ from 06/09/2025 to 31/12/2025, I had the opportunity to learn, practice, and apply the knowledge from AWS platform into my carear skills.\nIn terms of work ethic, I always strived to complete tasks well, complied with workplace regulations, and actively engaged with colleagues to improve work efficiency.\nTo objectively reflect on my internship period, I would like to evaluate myself based on the following criteria:\nNo. Criteria Description Good Fair Average 1 Professional knowledge \u0026amp; skills Understanding of the field, applying knowledge in practice, proficiency with tools, work quality ☐ ✅ ☐ 2 Ability to learn Ability to absorb new knowledge and learn quickly ☐ ✅ ☐ 3 Proactiveness Taking initiative, seeking out tasks without waiting for instructions ✅ ☐ ☐ 4 Sense of responsibility Completing tasks on time and ensuring quality ☐ ✅ ☐ 5 Discipline Adhering to schedules, rules, and work processes ✅ ☐ ☐ 6 Progressive mindset Willingness to receive feedback and improve oneself ☐ ✅ ☐ 7 Communication Presenting ideas and reporting work clearly ☐ ✅ ☐ 8 Teamwork Working effectively with colleagues and participating in teams ✅ ☐ ☐ 9 Professional conduct Respecting colleagues, partners, and the work environment ✅ ☐ ☐ 10 Problem-solving skills Identifying problems, proposing solutions, and showing creativity ☐ ✅ ☐ 11 Contribution to project/team Work effectiveness, innovative ideas, recognition from the team ✅ ☐ ☐ 12 Overall General evaluation of the entire internship period ✅ ☐ ☐ Needs Improvement Needs to learn more and actively Get acquainted to the project management skill more Enhance communication skills in both daily interactions and professional contexts, including handling situations effectively "
},
{
	"uri": "https://my-cloud-journey-e7994.web.app/4-eventparticipated/4.7-event7/",
	"title": "CloundFront as Your Foundation And AWS WAF &amp; Application Protection",
	"tags": [],
	"description": "",
	"content": "Event Objectives Introduce participants to the foundational concepts of Amazon CloudFront as a global CDN Provide practical understanding of how CloudFront improves performance, reliability, and cost efficiency Explore AWS WAF, Shield, and Bot Control for Layer 7 application protection Demonstrate modern security architectures for defending web applications and APIs Reinforce learning through an interactive Fun Quiz session Strengthen participants’ knowledge in building secure, scalable, and cost-optimized cloud applications Speakers Mr. Hung Gia for the CloudFront Session Mr. Julian for the WAF session Key Highlights Accelerating Applications with Amazon CloudFront The session began with an introduction to the challenges organizations face with web performance, cost unpredictability, and traffic spikes. Participants learned how Amazon CloudFront addresses these issues through:\nGlobal Edge Network with worldwide Points of Presence Multi-layer caching and Origin Shield Advanced performance techniques (HTTP/3, persistent connections, multiplexing) Origin protection via VPC Origins and Origin Access Control Built-in cost optimization features Real-world examples highlighted how CloudFront reduces latency, origin load, and operational costs while improving user experience at scale.\nStrengthening Security with AWS WAF \u0026amp; Shield The second part of the workshop focused on application security in the modern threat landscape, introducing:\nCommon attack vectors: OWASP Top 10, DDoS, bots, CVEs AWS WAF components (WebACLs, rules, rule groups, COUNT mode, rate-based rules) AWS Managed Rules for rapid protection Bot Control features and client interrogation techniques AWS Shield and the multi-layer DDoS defense system Security architectures using CloudFront + WAF + Shield for robust L7 protection Participants gained a deeper understanding of how to build secure and resilient applications using AWS edge services.\nAgenda Morning Session (CloudFront) 8:30 – 9:00 AM | Welcome \u0026amp; Introduction\nOverview of performance challenges in modern web applications Understanding CDN roles in global delivery 9:00 – 10:30 AM | Amazon CloudFront Deep Dive\nCDN caching behavior and optimization Global Edge Network overview Performance enhancements (HTTP/3, compression, persistent TCP) Origin protection strategies Multi-origin failover and routing Demo: CloudFront distribution setup and behavior analysis 10:30 – 10:45 AM | Break\nMidday Session (WAF \u0026amp; Shield) 10:45 AM – 12:00 PM | AWS WAF \u0026amp; Application Protection\nWAF rule types and best practices Rate-based rules for HTTP flood mitigation AWS Managed Rules overview Bot Control and client interrogation Shield Advanced capabilities Demo: Building a WAF WebACL for CloudFront 12:00 – 1:00 PM | Lunch Break (Self-arranged)\nAfternoon Session (Security Architecture \u0026amp; Fun Quiz) 1:00 – 2:30 PM | Security Architecture at the Edge\nCloudFront + WAF + Shield integration Origin cloaking and private VPC Origins Applying security layers for APIs \u0026amp; web apps Observability tools for security monitoring 2:30 – 2:45 PM | Break\n2:45 – 3:30 PM | Fun Quiz – CloudFront \u0026amp; WAF Challenge\nReal-world scenario questions Knowledge checks on caching, rules, and protection layers Interactive team-based quiz session 3:30 – 4:00 PM | Wrap-up \u0026amp; Q\u0026amp;A\nCareer path for AWS Edge \u0026amp; Security Specialists Learning roadmap for CloudFront, WAF, and AWS Security Key Takeaways I witness a technical guy with the humbled age at almost 60 - Mr. Julian and our amazing sifu - Mr. Hung Gia.\nStrategic Insights into Edge Performance \u0026amp; Security CloudFront significantly improves global performance through caching and optimized networking Origins can be shielded from direct public traffic using VPC Origins and OAC WAF enables precise, rule-based protection against L7 attacks Bot Control enhances detection of evasive bots through telemetry and behavioral tokens Shield provides automated DDoS mitigation with global edge protection Practical Learnings from CloudFront Multi-layer caching reduces origin cost and improves latency Failover and routing strategies enhance application resilience HTTP/3 and advanced compression deliver measurable speed improvements Practical Learnings from WAF COUNT mode is essential before enforcing blocking rules Rate-based rules effectively mitigate traffic floods Managed Rules accelerate security deployment Client interrogation helps identify sophisticated bot behavior Applying to Work Use CloudFront to minimize latency and offload origin infrastructure Protect web applications and APIs with WAF + Managed Rules Implement Shield for enhanced DDoS protection Adopt defense-in-depth strategies for edge and application layers Continuously observe user behavior and adapt rulesets proactively Event Experience This CloudFront, WAF \u0026amp; Security Essentials workshop delivered both theoretical depth and hands-on practical insights. It provided a clearer understanding of how enterprises build secure, performant, and cost-efficient applications at global scale.\nLearning from AWS Edge \u0026amp; Security Experts Understood how CloudFront optimizes performance for millions of users Learned how WAF and Shield mitigate complex real-world attacks Observed multiple architectural patterns used by enterprise customers Hands-On Demonstrations Configured CloudFront distribution behaviors Created and tested WAF rules in real scenarios Explored bot detection and telemetry-based defenses Collaboration \u0026amp; Networking Engaged with peers interested in cloud security and performance Discussed real use cases and career paths in AWS security domains Key Lessons Learned Performance and security must be designed together at the edge Proper caching strategy reduces both latency and cost Defense-in-depth with CloudFront + WAF + Shield provides strong protection Continuous learning is essential in the evolving security landscape Overall, this workshop strengthened my understanding of edge networking, security best practices, and AWS application protection tools—giving me the confidence to design secure, scalable systems with CloudFront and AWS WAF.\n"
},
{
	"uri": "https://my-cloud-journey-e7994.web.app/7-feedback/",
	"title": "Sharing and Feedback",
	"tags": [],
	"description": "",
	"content": "Overall Evaluation 1. Working Environment\nAbsolutely Cinema.\n2. Support from Mentor / Team Admin\nGreat leaders, great mentors.\n3. Relevance of Work to Academic Major\nHelped me a lot.\n4. Learning \u0026amp; Skill Development Opportunities\nDuring the internship, I learned many new skills such as teamwork skills, and professional communication in a corporate environment. The mentor also shared valuable real-world experiences that helped me better plan my career path.\n5. Company Culture \u0026amp; Team Spirit\nPositive, Heartful.\n6. Internship Policies / Benefits\nThe policies sometimes make me confused a little bit, and usually cannot catch up with notifications due to a mono chat group.\nAdditional Questions The most interesting thing impresses a lot is the bonding between people here Definitely, I would recommend my friend to join the internship here. Suggestions \u0026amp; Expectations No suggestion or expectation, absolutely cinema. "
},
{
	"uri": "https://my-cloud-journey-e7994.web.app/4-eventparticipated/4.8-event8/",
	"title": "Game Day – Secret Agent(ic) Unicorns",
	"tags": [],
	"description": "",
	"content": "Event Objectives Introduce participants to GenAI-powered problem-solving through an interactive GameDay experience Provide hands-on exposure to Amazon Bedrock, AgentCore, Knowledge Bases, Guardrails, and MCP Help players understand how AI agents collaborate with AWS services in real-world workflows Encourage teamwork across mixed skill levels to strengthen learning and problem-solving strategies Demonstrate how serverless, database, and search services integrate with GenAI applications Create a fun and engaging environment where participants earn points through missions, puzzles, and challenges AWS Services Used Amazon Bedrock (Foundation Models, Knowledge Bases, Guardrails) Amazon Bedrock AgentCore (Runtime, Memory, Code Interpreter, Observability) Strands Agents Model Context Protocol (MCP) Amazon DynamoDB Amazon OpenSearch Serverless Amazon Q Developer for CLI Target Audience Secret Agent(ic) AI GameDay is designed for a broad range of roles—including data scientists, ML practitioners, architects, developers, and operations engineers.\nParticipants should:\nBe familiar with navigating the AWS Console Benefit from teamwork across different skill levels Not require programming expertise (helpful but optional) Be encouraged to form teams mixing Beginners, Intermediates, and Experts for maximum collaboration Difficulty Each team should ideally contain 3–5 members with varied skills:\n1–2 Experts 1–2 Intermediate participants 1–2 Beginners This ensures balanced collaboration and allows players to learn from each other.\nKey Highlights GenAI-Powered Adventure The event transforms GenAI learning into an interactive mission where teams operate as Secret Agents tasked with solving challenges using AI agents, databases, knowledge retrieval, and observability tools.\nInstead of traditional lectures, participants progress through:\nMissions Time-limited puzzles Evidence analysis Incremental point-based challenges This unique format enhances both technical learning and team dynamics.\nHands-On Experience with Bedrock \u0026amp; AgentCore Players interact with several cutting-edge GenAI services:\nUsing Foundation Models for natural-language reasoning Retrieving facts and evidence with Knowledge Bases Ensuring safety and correctness with Guardrails Running multi-step agents using AgentCore Runtime \u0026amp; Memory Observing agent behavior, debugging, and tracing Storing mission data in DynamoDB Using OpenSearch Serverless for advanced retrieval These concepts mirror real-world AI workloads but are presented in a fun, gamified environment.\nTeam Collaboration \u0026amp; Strategy Success requires:\nClear communication Division of roles Shared note-taking and knowledge tracking Fast troubleshooting Adaptability Teams earn points not only for completing missions but also for efficiency, creativity, and technical accuracy.\nAgenda Intro Presentation \u0026amp; AWS Account Setup – 30 minutes\nGameDay rules and scoring Logging in to AWS accounts Overview of Bedrock, AgentCore, and supporting services Game Playtime – 120 minutes\nMissions and challenges begin Breaks included Evidence puzzles, agent tasks, and time-based scoring Teams race to accumulate the highest number of points Closing – 30 minutes\nSurvey distribution Announcing the Top 3 Winning Teams Group photo session Recap of key learning outcomes Key Takeaways Although I did not get any award, but this is a memorable event that makes me and my team be stronger and achieve more knowledge supporting for the next car\nGenAI Learning Hands-on experience using Bedrock Foundation Models Understanding how AgentCore manages memory, reasoning, and operations Observability techniques for tracing multi-step AI agent workflows Technical Skills Using Knowledge Bases and OpenSearch Serverless for retrieval Applying Guardrails for controlled and safe outputs Leveraging DynamoDB for storing mission artifacts Using Amazon Q Developer CLI for rapid development Team \u0026amp; Strategy Insights Collaboration across diverse skill levels accelerates learning Effective communication and planning improve mission success Time pressure helps simulate real-world problem-solving environments Applying to Work Apply GenAI agents to automate workplace tasks and workflows Use retrieval strategies (Knowledge Bases / OpenSearch) in real projects Adopt safe AI development practices with Guardrails Experiment with Bedrock Agents \u0026amp; AgentCore for building multi-step assistants Use Q Developer CLI to accelerate prototyping and engineering tasks Event Experience Participating in the Secret Agent(ic) Unicorns GameDay was both exciting and intellectually stimulating.\nThis wasn’t a typical workshop—it was an AI investigation adventure that required quick thinking, creative problem solving, and teamwork.\nLearning Through Play The gamified format made complex GenAI concepts easier to understand and apply.\nBy solving scenario-based missions, we learned how to:\nChain multiple AI agent steps Debug reasoning paths using observability tools Store, retrieve, and validate information Use MCP integrations and Bedrock Agents to complete challenges Collaboration \u0026amp; Team Spirit Each team member brought a unique strength—some focused on debugging, others on logic, others on navigating AWS services.\nThis diversity made the experience more engaging and productive.\nMemorable Closing Session Seeing the leaderboard, celebrating the top teams, and taking group photos made the event fun and rewarding.\nIt was a perfect blend of learning, competition, and community building.\nOverall, the GameDay was an unforgettable experience, combining GenAI learning with interactive missions that strengthened both my technical skills and collaborative mindset.\n"
},
{
	"uri": "https://my-cloud-journey-e7994.web.app/4-eventparticipated/4.9-event9/",
	"title": "AWS Cloud Mastery Series #3: Security Pillar – AWS Well-Architected",
	"tags": [],
	"description": "",
	"content": "Event Objectives Introduce participants to the AWS Well-Architected Security Pillar Provide practical understanding of identity, detection, infrastructure protection, data protection, and incident response Strengthen awareness of real-world cloud security threats in Vietnam Explore modern IAM patterns, network segmentation, encryption strategies, and automated incident response Help participants understand how to apply Zero Trust principles and Defense-in-Depth in AWS environments Build foundational knowledge for pursuing AWS Security Specialty certification Target Audience This workshop is designed for:\nCloud engineers, security engineers, architects, DevOps engineers IT administrators and operations teams managing workloads on AWS Developers interested in security best practices Anyone who wants to strengthen their cloud security fundamentals Technical expertise is not strictly required, but familiarity with AWS Console is recommended.\nKey Highlights Security Foundation – Setting the Stage The session opened with an introduction to:\nThe role of the Security Pillar in the Well-Architected Framework Core security principles: Least Privilege, Zero Trust, Defense in Depth The Shared Responsibility Model and how responsibilities shift in managed services Real cloud security threats commonly observed in Vietnam This foundation helped participants understand why security must be built-in, not bolted on.\nDeep Dive into the 5 Security Pillars The workshop was structured around the five pillars of AWS Security, each with practical guidance, demos, and real examples.\nModern IAM architecture with SSO, SCPs, and permission boundaries Detection and continuous monitoring covering CloudTrail, GuardDuty, VPC Flow Logs, EventBridge Infrastructure protection using VPC segmentation, WAF, Shield, Network Firewall Data protection using encryption (KMS), secrets lifecycle management, and guardrails Incident response automation using Lambda and Step Functions Agenda Opening Session 8:30 – 8:50 AM | Opening \u0026amp; Security Foundation Role of Security Pillar in Well-Architected Core principles: Least Privilege, Zero Trust, Defense in Depth Shared Responsibility Model Top cloud threats in Vietnam ⭐ Pillar 1 — Identity \u0026amp; Access Management 8:50 – 9:30 AM | Modern IAM Architecture IAM users, roles, policies — avoiding long-term credentials IAM Identity Center: SSO and permission sets SCPs \u0026amp; permission boundaries for multi-account setups MFA, credential rotation, Access Analyzer Mini Demo: Validate IAM policies \u0026amp; simulate access ⭐ Pillar 2 — Detection 9:30 – 9:55 AM | Detection \u0026amp; Continuous Monitoring\nCloudTrail (organization-level) GuardDuty \u0026amp; Security Hub Logging across all layers: VPC Flow Logs, ALB logs, S3 access logs Automation using EventBridge Detection-as-Code patterns 9:55 – 10:10 AM | Coffee Break\n⭐ Pillar 3 — Infrastructure Protection 10:10 – 10:40 AM | Network \u0026amp; Workload Security VPC segmentation: private vs public workloads Security Groups vs NACLs: when to use which WAF + Shield + Network Firewall Workload protection basics: EC2, ECS/EKS ⭐ Pillar 4 — Data Protection 10:40 – 11:10 AM | Encryption, Keys \u0026amp; Secrets KMS: key policies, grants, rotation best practices Encryption at rest \u0026amp; in transit: S3, EBS, RDS, DynamoDB Secrets Manager \u0026amp; Parameter Store — rotation patterns Data classification \u0026amp; access guardrails ⭐ Pillar 5 — Incident Response 11:10 – 11:40 AM | IR Playbook \u0026amp; Automation AWS Incident Response lifecycle Playbooks for: Compromised IAM credentials S3 public data exposure EC2 malware detection Isolation, snapshots, evidence collection Auto-response with Lambda / Step Functions Wrap-Up Session 11:40 – 12:00 PM | Wrap-Up \u0026amp; Q\u0026amp;A Summary of 5 Security Pillars Common pitfalls in Vietnamese enterprises Security learning roadmap (Security Specialty, SA Pro) Key Takeaways Security Mindset Security must be continuous and proactive, not reactive Least privilege, Zero Trust, and Defense in Depth are foundational Understanding shared responsibility is essential for building secure systems IAM \u0026amp; Detection SSO + permission sets simplify multi-account access management SCPs enforce organization-level guardrails Continuous monitoring is critical with CloudTrail, GuardDuty, and Flow Logs Infrastructure \u0026amp; Data Protection Proper VPC segmentation reduces blast radius Encryption should be applied everywhere—at rest, in transit, across services Secrets lifecycle management is essential for preventing breaches Incident Response Automation dramatically speeds up containment and recovery Prepared playbooks are essential for real-world scenarios Evidence collection must be done securely and systematically Applying to Work Adopt IAM Identity Center and SCPs for secure multi-account operations Enable org-level CloudTrail and GuardDuty for unified monitoring Apply encryption and secrets rotation across all workloads Use WAF and Shield to protect applications from common L7 attacks Build automated IR flows using Lambda or Step Functions Event Experience Attending the AWS Well-Architected Security Pillar Workshop gave me a deeper understanding of how security should be designed, implemented, and automated across AWS environments.\nLearning from AWS Security Experts Gained practical insights into IAM hygiene, threat detection, and incident response Understood how modern organizations structure multi-account security Learned common pitfalls and how to avoid them in real customer environments Hands-On Guidance IAM policy validation exercises helped reinforce least-privilege concepts Seeing detection pipelines with EventBridge \u0026amp; GuardDuty made monitoring clearer Walkthroughs of IR playbooks demonstrated how automation accelerates recovery Community \u0026amp; Engagement Participants shared real-world security challenges Discussions highlighted industry trends and common misconfigurations The workshop reinforced the importance of continuous learning in cloud security Overall, this workshop strengthened my understanding of cloud security foundations, giving me the confidence to design secure, resilient systems aligned with the AWS Well-Architected Framework.\n"
},
{
	"uri": "https://my-cloud-journey-e7994.web.app/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://my-cloud-journey-e7994.web.app/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]